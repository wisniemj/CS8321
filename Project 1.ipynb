{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdbbf2f2",
   "metadata": {},
   "source": [
    "# Lab 1: ConceptNet Ethics Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be6935",
   "metadata": {},
   "source": [
    "#### Henry Lambson, Alex Gregory, Mike Wisniewski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dcd7cb",
   "metadata": {},
   "source": [
    "### Part 1: Overview of Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668dc6a1",
   "metadata": {},
   "source": [
    "For our analysis of ConceptNet, our group decided to look into the potential bias of job titles pertaining to gender. An example of this being \"waitor\" vs \"waitress\". We believe that this investigation is relevant because we think that ConceptNet trained on the large, unfiltered GloVe data will be inherently biased towards male positions. We believe that the model will be biased towards male terms in general, and we want to use job titles as a way to expose this bias. If the model is distriminatory when it is not meant to be, it can affect the business using the model, as well as the the consumers who use the business. From the business perspective, businesses risk their bottom line and credibility. From a consumer perspective, consumers are at risk of being alienated due to their identity. Due to this bias, we believe that low level NPL models can be biased in a way that will hurt businesses trying to reach consumers equally.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b434dc1",
   "metadata": {},
   "source": [
    "### Part 2: Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3448ef",
   "metadata": {},
   "source": [
    "Our main research question for this project is: \"Is ConceptNet trained on the large GloVe data biased towards male job titles and biased against female job titles?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cd4d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3523f482",
   "metadata": {},
   "source": [
    "This first large section of code is grabbed from the in class example. We are using the same pre-processing that was shown and used in class. Once we have a sentiment analyzer, we will begin testing it for different biases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff32d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea29b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure how graphs will show up in this notebook\n",
    "%matplotlib inline\n",
    "seaborn.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f7ceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2196018, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "def load_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Load a DataFrame from the generalized text format used by word2vec, GloVe,\n",
    "    fastText, and ConceptNet Numberbatch. The main point where they differ is\n",
    "    whether there is an initial line with the dimensions of the matrix.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    rows = []\n",
    "    with open(filename, encoding='utf-8') as infile:\n",
    "        for i, line in enumerate(infile):\n",
    "            items = line.rstrip().split(' ')\n",
    "            if len(items) == 2:\n",
    "                # This is a header row giving the shape of the matrix\n",
    "                continue\n",
    "            labels.append(items[0])\n",
    "            values = np.array([float(x) for x in items[1:]], 'f')\n",
    "            rows.append(values)\n",
    "    \n",
    "    arr = np.vstack(rows)\n",
    "    return pd.DataFrame(arr, index=labels, dtype='f')\n",
    "\n",
    "embeddings = load_embeddings('glove.840B.300d/glove.840B.300d.txt')\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00bc87ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glove.840B.300d/positive-words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21184/998035088.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mpos_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_lexicon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'glove.840B.300d/positive-words.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mneg_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_lexicon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'glove.840B.300d/negative-words.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21184/998035088.py\u001b[0m in \u001b[0;36mload_lexicon\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m     11\u001b[0m     \u001b[0mlexicon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin-1'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glove.840B.300d/positive-words.txt'"
     ]
    }
   ],
   "source": [
    "def load_lexicon(filename):\n",
    "    \"\"\"\n",
    "    Load a file from Bing Liu's sentiment lexicon\n",
    "    (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html), containing\n",
    "    English words in Latin-1 encoding.\n",
    "    \n",
    "    One file contains a list of positive words, and the other contains\n",
    "    a list of negative words. The files contain comment lines starting\n",
    "    with ';' and blank lines, which should be skipped.\n",
    "    \"\"\"\n",
    "    lexicon = []\n",
    "    with open(filename, encoding='latin-1') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon\n",
    "\n",
    "pos_words = load_lexicon('glove.840B.300d/positive-words.txt')\n",
    "neg_words = load_lexicon('glove.840B.300d/negative-words.txt')\n",
    "\n",
    "print(len(pos_words), len(neg_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words_common = list(set(pos_words) & set(embeddings.index)) \n",
    "neg_words_common = list(set(neg_words) & set(embeddings.index)) \n",
    "\n",
    "pos_vectors = embeddings.loc[pos_words_common]\n",
    "neg_vectors = embeddings.loc[neg_words_common]\n",
    "print(pos_vectors.shape,neg_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97665dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.concat([pos_vectors, neg_vectors])\n",
    "targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index])\n",
    "labels = list(pos_vectors.index) + list(neg_vectors.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca6764",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] https://careersmart.org.uk/occupations/equality/which-jobs-do-men-and-women-do-occupational-breakdown-gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d63be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
