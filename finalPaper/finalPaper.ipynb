{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3990848b-1984-4bf0-8e3b-ef3e4ada5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, ReLU, BatchNormalization,Add, AveragePooling1D, Flatten, Dense\n",
    "from tensorflow.keras.losses import mean_squared_error, binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import Tensor\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "c790fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequential_model(df):\n",
    "    input_shape = len(df[0])\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,), kernel_initializer=\"glorot_uniform\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='tanh'),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='tanh'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(32, activation='tanh'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='linear')  # Output layer with linear activation\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=[\"mae\", \"msle\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "id": "7effb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def relu_bn(inputs: Tensor) -> Tensor:\n",
    "#     relu = ReLU()(inputs)\n",
    "#     bn = BatchNormalization()(relu)\n",
    "#     return bn\n",
    "\n",
    "# def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "#     y = Conv1D(kernel_size=kernel_size,\n",
    "#                strides= (1 if not downsample else 2),\n",
    "#                filters=filters,\n",
    "#                padding=\"same\")(x)\n",
    "#     y = relu_bn(y)\n",
    "#     y = Dropout(.6)(y)\n",
    "#     y = Conv1D(kernel_size=kernel_size,\n",
    "#                strides=1,\n",
    "#                filters=filters,\n",
    "#                padding=\"same\")(y)\n",
    "#     if downsample:\n",
    "#         x = Conv1D(kernel_size=1,\n",
    "#                    strides=2,\n",
    "#                    filters=filters,\n",
    "#                    padding=\"same\")(x)\n",
    "#     out = Add()([x, y])\n",
    "#     out = relu_bn(out)\n",
    "#     out = Dropout(.6)(out)\n",
    "    \n",
    "#     return out\n",
    "\n",
    "# def create_res_net():\n",
    "    \n",
    "#     inputs = Input(shape=(X_train.shape[1],1))\n",
    "#     num_filters = 64\n",
    "    \n",
    "#     t = BatchNormalization()(inputs)\n",
    "#     t = Conv1D(kernel_size=3,\n",
    "#                strides=1,\n",
    "#                filters=num_filters,\n",
    "#                padding=\"same\")(inputs)\n",
    "#     t = relu_bn(t)\n",
    "#     t = Dropout(.6)(t)\n",
    "    \n",
    "#     num_blocks_list = [2, 5, 5, 2]\n",
    "#     for i in range(len(num_blocks_list)):\n",
    "#         num_blocks = num_blocks_list[i]\n",
    "#         for j in range(num_blocks):\n",
    "#             t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "#         num_filters *= 2\n",
    "#     t = AveragePooling1D(3)(t)\n",
    "#     t = Flatten()(t)\n",
    "#     t = Dense(64, activation=\"relu\", kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "#     f1 = Dense(32, activation=\"relu\")(t)\n",
    "#     f2 = Dense(16, activation=\"relu\")(f1)\n",
    "#     f3 = Dense(8, activation=\"relu\")(f2)\n",
    "#     outputs = Dense(1, activation='linear')(f3)\n",
    "#     model = Model(inputs, outputs)\n",
    "#     model.compile(\n",
    "#         optimizer=Adam(learning_rate=0.0001),\n",
    "#         loss='mean_squared_error',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "#     return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "8d85b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meld_acc(df, meld_column):\n",
    "    mortality_rate = []\n",
    "\n",
    "    bracket_1_deceased = df[(df[meld_column] <= 9) & (df[\"Deceased\"] == 1)]\n",
    "    bracket_1_nondeceased = df[(df[meld_column] <= 9) & (df[\"Deceased\"] == 0)]\n",
    "\n",
    "    bracket_2_deceased = df[(df[meld_column] <= 20) & (df[meld_column] > 9) & (df[\"Deceased\"] == 1)]\n",
    "    bracket_2_nondeceased = df[(df[meld_column] <= 20) & (df[meld_column] > 9) & (df[\"Deceased\"] == 0)]\n",
    "\n",
    "    bracket_3_deceased = df[(df[meld_column] <= 30) & (df[meld_column] > 20) & (df[\"Deceased\"] == 1)]\n",
    "    bracket_3_nondeceased = df[(df[meld_column] <= 30) & (df[meld_column] > 20) & (df[\"Deceased\"] == 0)]\n",
    "\n",
    "    bracket_4_deceased = df[(df[meld_column] <= 40) & (df[meld_column] > 30) & (df[\"Deceased\"] == 1)]\n",
    "    bracket_4_nondeceased = df[(df[meld_column] <= 40) & (df[meld_column] > 30) & (df[\"Deceased\"] == 0)]\n",
    "\n",
    "    bracket_5_deceased = df[(df[meld_column] > 40) & (df[\"Deceased\"] == 1)]\n",
    "    bracket_5_nondeceased = df[(df[meld_column] > 40) & (df[\"Deceased\"] == 0)]\n",
    "\n",
    "    try:\n",
    "        bracket_1_mortality_rate = len(bracket_1_deceased) / (len(bracket_1_deceased) + len(bracket_1_nondeceased))\n",
    "    except ZeroDivisionError:\n",
    "        bracket_1_mortality_rate = 0\n",
    "    \n",
    "    try:\n",
    "        bracket_2_mortality_rate = len(bracket_2_deceased) / (len(bracket_2_deceased) + len(bracket_2_nondeceased))\n",
    "    except ZeroDivisionError:\n",
    "        bracket_2_mortality_rate = 0\n",
    "\n",
    "    try:\n",
    "        bracket_3_mortality_rate = len(bracket_3_deceased) / (len(bracket_3_deceased) + len(bracket_3_nondeceased))\n",
    "    except ZeroDivisionError:\n",
    "        bracket_3_mortality_rate = 0\n",
    "\n",
    "    try:\n",
    "        bracket_4_mortality_rate = len(bracket_4_deceased) / (len(bracket_4_deceased) + len(bracket_4_nondeceased))\n",
    "    except ZeroDivisionError:\n",
    "        bracket_4_mortality_rate = 0\n",
    "\n",
    "    try:\n",
    "        bracket_5_mortality_rate = len(bracket_5_deceased) / (len(bracket_5_deceased) + len(bracket_5_nondeceased))\n",
    "    except ZeroDivisionError:\n",
    "        bracket_5_mortality_rate = 0\n",
    "\n",
    "    mortality_rate.append(bracket_1_mortality_rate)\n",
    "    mortality_rate.append(bracket_2_mortality_rate)\n",
    "    mortality_rate.append(bracket_3_mortality_rate)\n",
    "    mortality_rate.append(bracket_4_mortality_rate)\n",
    "    mortality_rate.append(bracket_5_mortality_rate)\n",
    "\n",
    "    return mortality_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "73cfc6c2-5cd1-4c20-bd0e-0694b99aac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv(\"liverData/eldd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "e19e4300-cf4e-46a4-af7a-d3672a3110f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DaysAtRisk</th>\n",
       "      <th>Deceased</th>\n",
       "      <th>LTx</th>\n",
       "      <th>Cirrhosis</th>\n",
       "      <th>ALF</th>\n",
       "      <th>Ethyltoxic</th>\n",
       "      <th>HBV</th>\n",
       "      <th>HCV</th>\n",
       "      <th>AIH</th>\n",
       "      <th>PBC</th>\n",
       "      <th>PSC</th>\n",
       "      <th>NASH</th>\n",
       "      <th>Cryptogenic</th>\n",
       "      <th>Dialysis</th>\n",
       "      <th>GIB</th>\n",
       "      <th>HCC</th>\n",
       "      <th>SBP</th>\n",
       "      <th>ALAT_S</th>\n",
       "      <th>ALB_S</th>\n",
       "      <th>AP_S</th>\n",
       "      <th>ASAT_S</th>\n",
       "      <th>B_MPV_E</th>\n",
       "      <th>B_PLT_E</th>\n",
       "      <th>B_WBC_E</th>\n",
       "      <th>BILI_S</th>\n",
       "      <th>BILID_S</th>\n",
       "      <th>CA_S</th>\n",
       "      <th>CHE_S</th>\n",
       "      <th>CHOLG_S</th>\n",
       "      <th>CL_S</th>\n",
       "      <th>CRE_S</th>\n",
       "      <th>CRP_S</th>\n",
       "      <th>CYSC_S</th>\n",
       "      <th>GGT_S</th>\n",
       "      <th>IL6_S</th>\n",
       "      <th>INR_C</th>\n",
       "      <th>NA_S</th>\n",
       "      <th>P_S</th>\n",
       "      <th>PALB_S</th>\n",
       "      <th>PROT_S</th>\n",
       "      <th>PTH_S</th>\n",
       "      <th>VDT_OH_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>male</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.17</td>\n",
       "      <td>74.6</td>\n",
       "      <td>3.08</td>\n",
       "      <td>100.3</td>\n",
       "      <td>104</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.97</td>\n",
       "      <td>22.87</td>\n",
       "      <td>1.11</td>\n",
       "      <td>135.4</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.19</td>\n",
       "      <td>69.6</td>\n",
       "      <td>2.39</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>28.3</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>43.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.21</td>\n",
       "      <td>101.9</td>\n",
       "      <td>304</td>\n",
       "      <td>43.54</td>\n",
       "      <td>4.87</td>\n",
       "      <td>2.43</td>\n",
       "      <td>336.50</td>\n",
       "      <td>1.77</td>\n",
       "      <td>133.1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.05</td>\n",
       "      <td>62.5</td>\n",
       "      <td>19.39</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>female</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>41.7</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.33</td>\n",
       "      <td>59.5</td>\n",
       "      <td>5.02</td>\n",
       "      <td>93.8</td>\n",
       "      <td>95</td>\n",
       "      <td>9.88</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1.84</td>\n",
       "      <td>16.74</td>\n",
       "      <td>1.09</td>\n",
       "      <td>137.4</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>80.5</td>\n",
       "      <td>7.39</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>23.8</td>\n",
       "      <td>52.97</td>\n",
       "      <td>3.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.5</td>\n",
       "      <td>208.3</td>\n",
       "      <td>2.23</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.55</td>\n",
       "      <td>95.7</td>\n",
       "      <td>61</td>\n",
       "      <td>90.29</td>\n",
       "      <td>4.73</td>\n",
       "      <td>24.35</td>\n",
       "      <td>709.80</td>\n",
       "      <td>2.29</td>\n",
       "      <td>130.5</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.15</td>\n",
       "      <td>48.9</td>\n",
       "      <td>2.21</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>female</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>36.3</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1.33</td>\n",
       "      <td>13.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>37.2</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2.28</td>\n",
       "      <td>63.8</td>\n",
       "      <td>4.78</td>\n",
       "      <td>100.8</td>\n",
       "      <td>73</td>\n",
       "      <td>8.65</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.45</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.10</td>\n",
       "      <td>142.6</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>67.6</td>\n",
       "      <td>4.17</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex  DaysAtRisk  Deceased  LTx  Cirrhosis  ALF  Ethyltoxic  HBV  \\\n",
       "0   68    male         200         0    0        1.0    0           1    1   \n",
       "1   64    male           3         1    0        1.0    0           1    0   \n",
       "2   67  female         208         0    0        1.0    0           1    0   \n",
       "3   32  female          17         1    0        0.0    1           0    0   \n",
       "4   64  female         189         0    0        1.0    0           1    0   \n",
       "\n",
       "   HCV  AIH  PBC  PSC  NASH  Cryptogenic  Dialysis  GIB  HCC  SBP  ALAT_S  \\\n",
       "0    0    0    0    0     0            0       0.0    0    1  0.0    0.29   \n",
       "1    0    0    0    0     0            0       0.0    1    0  0.0    0.22   \n",
       "2    0    0    0    0     0            0       0.0    0    0  0.0    0.19   \n",
       "3    0    0    0    0     0            0       0.0    0    0  0.0    0.78   \n",
       "4    0    0    0    0     0            0       0.0    1    0  0.0    0.75   \n",
       "\n",
       "   ALB_S   AP_S  ASAT_S  B_MPV_E  B_PLT_E  B_WBC_E  BILI_S  BILID_S  CA_S  \\\n",
       "0   40.9   1.17    0.56     11.0    160.0      7.4     7.9      3.5  2.17   \n",
       "1   28.3   3.68    0.66      NaN     10.0      8.1    43.2     26.0  2.04   \n",
       "2   41.7   1.50    0.68     10.8    123.0      4.9    16.9      6.9  2.33   \n",
       "3   23.8  52.97    3.24      NaN      NaN      NaN   266.5    208.3  2.23   \n",
       "4   36.3   2.79    1.33     13.9     65.0      6.3    37.2     16.9  2.28   \n",
       "\n",
       "   CHE_S  CHOLG_S   CL_S  CRE_S  CRP_S  CYSC_S  GGT_S   IL6_S  INR_C   NA_S  \\\n",
       "0   74.6     3.08  100.3    104   8.20    1.79   1.97   22.87   1.11  135.4   \n",
       "1   14.7     2.21  101.9    304  43.54    4.87   2.43  336.50   1.77  133.1   \n",
       "2   59.5     5.02   93.8     95   9.88    2.23   1.84   16.74   1.09  137.4   \n",
       "3   15.4     4.55   95.7     61  90.29    4.73  24.35  709.80   2.29  130.5   \n",
       "4   63.8     4.78  100.8     73   8.65    1.51   2.45    7.90   1.10  142.6   \n",
       "\n",
       "    P_S  PALB_S  PROT_S  PTH_S  VDT_OH_S  \n",
       "0  1.49    0.19    69.6   2.39      12.7  \n",
       "1  0.96    0.05    62.5  19.39       5.5  \n",
       "2  1.14    0.17    80.5   7.39      18.8  \n",
       "3  1.71    0.15    48.9   2.21       4.5  \n",
       "4  1.07    0.11    67.6   4.17      34.1  "
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print length and show sample data\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "cbd85d5f-78bb-4eff-ba36-730dbfc760f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meld functions\n",
    "#https://www.mdcalc.com/calc/10437/model-end-stage-liver-disease-meld#evidence\n",
    "\n",
    "import math\n",
    "\n",
    "# TODO: check all SI values and see what needs conversion. Sodium did not, unknown after Bili but placeholder functions added\n",
    "#convert SI units to US units\n",
    "#creatinine umol/L to mg/dl\n",
    "def convertCreatinine(CRE_S):\n",
    "     return (CRE_S * 0.0230)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertBilirubin(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertCystatinC(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertIL_6(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertWBC(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertProtien(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "def convertAlbumin(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "def convertALAT(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "def convertASAT(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "\n",
    "#meld3\n",
    "#1.33*(Female) + 4.56*ln(Serum bilirubin) + 0.82*(137 - Sodium) – 0.24*(137 - Sodium)*ln(Serum bilirubin) + 9.09*ln(INR) + 11.14*ln(Serum creatinine) + 1.85*(3.5 – Serum albumin) – 1.83*(3.5 – Serum albumin)*ln(Serum creatinine) + 6,\n",
    "#rounded to the nearest integer\n",
    "#Serum bilirubin, INR, and serum creatinine values below 1.0 are set to 1.0.\n",
    "#Sodium is limited to a range of 125-137 mEq/L, and if outside of these bounds, is set to the nearest limit.\n",
    "#Serum albumin is limited to a range of 1.5-3.5 g/dL, and if outside of these bounds, is set to the nearest limit.\n",
    "#Maximum serum creatinine is 3.0 mg/dL, and if above this bound, is set to 3.0 mg/dL.\n",
    "\n",
    "def calm_meld(CRE_S, BILI_S, INR_C):\n",
    "    meld_score = (0.957*math.log(convertCreatinine(CRE_S)) + 0.378*math.log(convertBilirubin(BILI_S)) + 1.120*math.log(INR_C) + 0.643)*10\n",
    "    return int(round(meld_score))\n",
    "\n",
    "def calc_meld3(CRE_S, BILI_S, INR_C, NA_S, ALB_S, sex):\n",
    "    BILI_S = convertBilirubin(BILI_S)\n",
    "    CRE_S = convertCreatinine(CRE_S)\n",
    "    if BILI_S < 1:\n",
    "        BILI_S = 1\n",
    "    if INR_C < 1:\n",
    "        INR_C = 1\n",
    "    if CRE_S < 1:\n",
    "        CRE_S = 1\n",
    "    if CRE_S >= 3:\n",
    "        CRE_S = 3\n",
    "    if NA_S > 137:\n",
    "        NA_S = 137\n",
    "    if NA_S < 125:\n",
    "        NA_S = 125\n",
    "    if ALB_S > 3.5:\n",
    "        ALB_S = 3.5\n",
    "    if ALB_S < 1.5:\n",
    "        ALB_S = 1.5\n",
    "    if sex == 'female':\n",
    "        sex = 1\n",
    "    else:\n",
    "        sex = 0\n",
    "    \n",
    "    meld3_score = 1.33*(sex) + 4.56*math.log(BILI_S) + 0.82*(137 - NA_S) - 0.24*(137 - NA_S)*math.log(BILI_S) + 9.09*math.log(INR_C) + 11.14*math.log(CRE_S) + 1.85*(3.5 - ALB_S) - 1.83*(3.5 - ALB_S)*math.log(CRE_S) + 6\n",
    "    return int(round(meld3_score))\n",
    "\n",
    "#meld_na\n",
    "#MELD(i) = 0.957*ln(Creatinine) + 0.378*ln(Bilirubin) + 1.120*ln(INR) + 0.643\n",
    "#Then, round to the tenth decimal place and multiply by 10. \n",
    "#If MELD(i) > 11, perform additional MELD calculation as follows:\n",
    "#MELD = MELD(i) + 1.32*(137 – Na) –  [0.033*MELD(i)*(137 – Na)]\n",
    "\n",
    "def calc_meldNA(CRE_S, BILI_S, INR_C,NA_S):\n",
    "    meldNA_score = 0.957 * math.log(convertCreatinine(CRE_S)) + 0.378*math.log(convertBilirubin(BILI_S)) + 1.120*math.log(INR_C) + 0.643\n",
    "    meldNA_score = round(meldNA_score, 1) * 10\n",
    "    if meldNA_score > 11:\n",
    "        meldNA_score = meldNA_score + 1.32*(137-NA_S) - (0.033*meldNA_score*(137-NA_S))\n",
    "    return int(round(meldNA_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "id": "77649f89-81b2-4368-84ff-decae26fe351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#drop NA rows to allow for meld scores. 654 down to 638\n",
    "df = df.dropna(subset=['INR_C','NA_S','ALB_S'])\n",
    "\n",
    "#TODO: convert SI to metric as necessary\n",
    "#US hospital labs are in metric is why we're converting here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "6c59fbd9-01aa-4eb2-a0c3-635c89b3efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy(deep=True).reset_index(drop=True)\n",
    "df2['MELD'] = df2.apply(lambda row: calm_meld(row[\"CRE_S\"],row[\"BILI_S\"],row[\"INR_C\"]), axis =1)\n",
    "df2['MELD3'] = df2.apply(lambda row: calc_meld3(row[\"CRE_S\"],row[\"BILI_S\"],row[\"INR_C\"],row[\"NA_S\"],row[\"ALB_S\"],row[\"Sex\"]), axis =1)\n",
    "df2['MELDNA'] = df2.apply(lambda row: calc_meldNA(row[\"CRE_S\"],row[\"BILI_S\"],row[\"INR_C\"],row[\"NA_S\"]), axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "b87d1f1a-4956-40ff-ad7a-f1021c07b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode Sex\n",
    "col = pd.get_dummies(df2['Sex'])\n",
    "del df2['Sex']\n",
    "df2 = df2.join(col)\n",
    "\n",
    "# take out MELD score comparisons for final_df\n",
    "final_df = df2.copy(deep=True)\n",
    "\n",
    "# Assumption: all null numeric values are 0\n",
    "final_df = final_df.replace(np.NaN, 0)\n",
    "\n",
    "final_df_normalized = final_df.copy(deep=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "feature_scaler = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "non_binary_cols = [col for col in final_df.columns if len(final_df[col].unique()) > 2]\n",
    "non_binary_cols.remove(\"MELD\")\n",
    "non_binary_cols.remove(\"MELD3\")\n",
    "non_binary_cols.remove(\"MELDNA\")\n",
    "binary_cols = [col for col in final_df.columns if len(final_df[col].unique()) <= 2]\n",
    "# final_df_normalized = pd.DataFrame(scaler.fit_transform(final_df[non_binary_cols]), columns=non_binary_cols)\n",
    "# final_df_normalized = pd.concat([final_df[binary_cols], final_df_normalized], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "id": "e015c355-9cf7-4166-b8d5-8df54d6b13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Goal of improving on original meld for now. \n",
    "#Meld3 is used primarily for transplant, meldNA is used for Cirrhosis: #https://www.mdcalc.com/calc/10437/model-end-stage-liver-disease-meld#evidence\n",
    "y = final_df_normalized['MELD'].copy(deep=True)\n",
    "y = target_scaler.fit_transform(np.array(y).reshape(-1, 1))\n",
    "\n",
    "#Trim columns to use for training\n",
    "#Removing days at risk, deceased, \n",
    "#fields = ['Age','Sex','Cirrhosis','ALF','Ethyltoxic','HBV','HCV','INR_C','NA_S','P_S','','','','']\n",
    "X = final_df_normalized.copy(deep=True)\n",
    "X = X.drop([\"MELD\", \"MELD3\", \"MELDNA\"], axis=1)\n",
    "X_non_binary = pd.DataFrame(feature_scaler.fit_transform(X[non_binary_cols]), columns=non_binary_cols)\n",
    "X = pd.concat([X[binary_cols], X_non_binary], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "id": "99672d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.9328 - mae: 0.7374 - msle: 0.1565 - val_loss: 0.8887 - val_mae: 0.7198 - val_msle: 0.1733\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7138 - mae: 0.6286 - msle: 0.1166 - val_loss: 0.4532 - val_mae: 0.5045 - val_msle: 0.0599\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4567 - mae: 0.5175 - msle: 0.0744 - val_loss: 0.3336 - val_mae: 0.4412 - val_msle: 0.0443\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4091 - mae: 0.4904 - msle: 0.0631 - val_loss: 0.2795 - val_mae: 0.4021 - val_msle: 0.0326\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3488 - mae: 0.4369 - msle: 0.0495 - val_loss: 0.2308 - val_mae: 0.3682 - val_msle: 0.0256\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3116 - mae: 0.4278 - msle: 0.0439 - val_loss: 0.2077 - val_mae: 0.3504 - val_msle: 0.0241\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2669 - mae: 0.4009 - msle: 0.0367 - val_loss: 0.1794 - val_mae: 0.3262 - val_msle: 0.0211\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2487 - mae: 0.3760 - msle: 0.0337 - val_loss: 0.2045 - val_mae: 0.3539 - val_msle: 0.0320\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2400 - mae: 0.3738 - msle: 0.0300 - val_loss: 0.1768 - val_mae: 0.3258 - val_msle: 0.0257\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2527 - mae: 0.3882 - msle: 0.0336 - val_loss: 0.1776 - val_mae: 0.3279 - val_msle: 0.0261\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2262 - mae: 0.3640 - msle: 0.0302 - val_loss: 0.1915 - val_mae: 0.3415 - val_msle: 0.0327\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2210 - mae: 0.3602 - msle: 0.0302 - val_loss: 0.1704 - val_mae: 0.3193 - val_msle: 0.0278\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2361 - mae: 0.3800 - msle: 0.0323 - val_loss: 0.1608 - val_mae: 0.3111 - val_msle: 0.0256\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1829 - mae: 0.3357 - msle: 0.0215 - val_loss: 0.1521 - val_mae: 0.3066 - val_msle: 0.0242\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2086 - mae: 0.3498 - msle: 0.0266 - val_loss: 0.1517 - val_mae: 0.3066 - val_msle: 0.0253\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2144 - mae: 0.3402 - msle: 0.0286 - val_loss: 0.1464 - val_mae: 0.2938 - val_msle: 0.0221\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2012 - mae: 0.3397 - msle: 0.0270 - val_loss: 0.1551 - val_mae: 0.3015 - val_msle: 0.0244\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1914 - mae: 0.3438 - msle: 0.0244 - val_loss: 0.1432 - val_mae: 0.2915 - val_msle: 0.0219\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1970 - mae: 0.3446 - msle: 0.0244 - val_loss: 0.1370 - val_mae: 0.2873 - val_msle: 0.0221\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1917 - mae: 0.3396 - msle: 0.0251 - val_loss: 0.1327 - val_mae: 0.2828 - val_msle: 0.0215\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1723 - mae: 0.3206 - msle: 0.0234 - val_loss: 0.1318 - val_mae: 0.2816 - val_msle: 0.0214\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1689 - mae: 0.3184 - msle: 0.0208 - val_loss: 0.1247 - val_mae: 0.2763 - val_msle: 0.0191\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1647 - mae: 0.3103 - msle: 0.0213 - val_loss: 0.1238 - val_mae: 0.2788 - val_msle: 0.0193\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1658 - mae: 0.3148 - msle: 0.0178 - val_loss: 0.1254 - val_mae: 0.2776 - val_msle: 0.0211\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1673 - mae: 0.3151 - msle: 0.0206 - val_loss: 0.1217 - val_mae: 0.2730 - val_msle: 0.0193\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1628 - mae: 0.3092 - msle: 0.0208 - val_loss: 0.1321 - val_mae: 0.2900 - val_msle: 0.0254\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1673 - mae: 0.3018 - msle: 0.0201 - val_loss: 0.1176 - val_mae: 0.2695 - val_msle: 0.0206\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1531 - mae: 0.3008 - msle: 0.0195 - val_loss: 0.1268 - val_mae: 0.2779 - val_msle: 0.0235\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1523 - mae: 0.2950 - msle: 0.0189 - val_loss: 0.1117 - val_mae: 0.2632 - val_msle: 0.0175\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1678 - mae: 0.3022 - msle: 0.0206 - val_loss: 0.1123 - val_mae: 0.2645 - val_msle: 0.0205\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1548 - mae: 0.3034 - msle: 0.0190 - val_loss: 0.1098 - val_mae: 0.2592 - val_msle: 0.0196\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1541 - mae: 0.2969 - msle: 0.0202 - val_loss: 0.1109 - val_mae: 0.2581 - val_msle: 0.0199\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1488 - mae: 0.3007 - msle: 0.0181 - val_loss: 0.1243 - val_mae: 0.2795 - val_msle: 0.0226\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1507 - mae: 0.2993 - msle: 0.0159 - val_loss: 0.1042 - val_mae: 0.2536 - val_msle: 0.0164\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1546 - mae: 0.2866 - msle: 0.0185 - val_loss: 0.1309 - val_mae: 0.2866 - val_msle: 0.0270\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1438 - mae: 0.2846 - msle: 0.0194 - val_loss: 0.0964 - val_mae: 0.2442 - val_msle: 0.0151\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1540 - mae: 0.3020 - msle: 0.0209 - val_loss: 0.1012 - val_mae: 0.2527 - val_msle: 0.0169\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1197 - mae: 0.2575 - msle: 0.0151 - val_loss: 0.0992 - val_mae: 0.2492 - val_msle: 0.0162\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1385 - mae: 0.2781 - msle: 0.0157 - val_loss: 0.0909 - val_mae: 0.2320 - val_msle: 0.0120\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1397 - mae: 0.2772 - msle: 0.0171 - val_loss: 0.1091 - val_mae: 0.2603 - val_msle: 0.0210\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1350 - mae: 0.2807 - msle: 0.0163 - val_loss: 0.0989 - val_mae: 0.2510 - val_msle: 0.0138\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1269 - mae: 0.2692 - msle: 0.0167 - val_loss: 0.1004 - val_mae: 0.2497 - val_msle: 0.0178\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1042 - mae: 0.2539 - msle: 0.0116 - val_loss: 0.0950 - val_mae: 0.2408 - val_msle: 0.0149\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1176 - mae: 0.2580 - msle: 0.0135 - val_loss: 0.0935 - val_mae: 0.2380 - val_msle: 0.0135\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1264 - mae: 0.2720 - msle: 0.0163 - val_loss: 0.1069 - val_mae: 0.2568 - val_msle: 0.0191\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1328 - mae: 0.2777 - msle: 0.0173 - val_loss: 0.0959 - val_mae: 0.2422 - val_msle: 0.0128\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1264 - mae: 0.2706 - msle: 0.0155 - val_loss: 0.0902 - val_mae: 0.2337 - val_msle: 0.0154\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1099 - mae: 0.2572 - msle: 0.0135 - val_loss: 0.0871 - val_mae: 0.2266 - val_msle: 0.0137\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1054 - mae: 0.2486 - msle: 0.0168 - val_loss: 0.0954 - val_mae: 0.2357 - val_msle: 0.0167\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1182 - mae: 0.2595 - msle: 0.0154 - val_loss: 0.0937 - val_mae: 0.2325 - val_msle: 0.0169\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1048 - mae: 0.2470 - msle: 0.0142 - val_loss: 0.0899 - val_mae: 0.2285 - val_msle: 0.0150\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1115 - mae: 0.2439 - msle: 0.0123 - val_loss: 0.0886 - val_mae: 0.2296 - val_msle: 0.0149\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1083 - mae: 0.2473 - msle: 0.0142 - val_loss: 0.0817 - val_mae: 0.2137 - val_msle: 0.0125\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0987 - mae: 0.2388 - msle: 0.0144 - val_loss: 0.0845 - val_mae: 0.2229 - val_msle: 0.0138\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0907 - mae: 0.2292 - msle: 0.0117 - val_loss: 0.0832 - val_mae: 0.2213 - val_msle: 0.0148\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1024 - mae: 0.2473 - msle: 0.0123 - val_loss: 0.0834 - val_mae: 0.2243 - val_msle: 0.0150\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1059 - mae: 0.2499 - msle: 0.0132 - val_loss: 0.0842 - val_mae: 0.2262 - val_msle: 0.0147\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1119 - mae: 0.2527 - msle: 0.0155 - val_loss: 0.0791 - val_mae: 0.2229 - val_msle: 0.0126\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0985 - mae: 0.2351 - msle: 0.0135 - val_loss: 0.0782 - val_mae: 0.2195 - val_msle: 0.0132\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0920 - mae: 0.2304 - msle: 0.0101 - val_loss: 0.0793 - val_mae: 0.2201 - val_msle: 0.0140\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1029 - mae: 0.2413 - msle: 0.0122 - val_loss: 0.0752 - val_mae: 0.2131 - val_msle: 0.0134\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1009 - mae: 0.2421 - msle: 0.0143 - val_loss: 0.0874 - val_mae: 0.2341 - val_msle: 0.0187\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0916 - mae: 0.2306 - msle: 0.0130 - val_loss: 0.0654 - val_mae: 0.2013 - val_msle: 0.0110\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0914 - mae: 0.2290 - msle: 0.0127 - val_loss: 0.0719 - val_mae: 0.2136 - val_msle: 0.0111\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1046 - mae: 0.2390 - msle: 0.0131 - val_loss: 0.0850 - val_mae: 0.2316 - val_msle: 0.0169\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0893 - mae: 0.2276 - msle: 0.0118 - val_loss: 0.0695 - val_mae: 0.2038 - val_msle: 0.0115\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0957 - mae: 0.2419 - msle: 0.0136 - val_loss: 0.0641 - val_mae: 0.1976 - val_msle: 0.0102\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0804 - mae: 0.2134 - msle: 0.0102 - val_loss: 0.0729 - val_mae: 0.2084 - val_msle: 0.0128\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0948 - mae: 0.2347 - msle: 0.0117 - val_loss: 0.0660 - val_mae: 0.2001 - val_msle: 0.0119\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0969 - mae: 0.2315 - msle: 0.0114 - val_loss: 0.0617 - val_mae: 0.1924 - val_msle: 0.0090\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0867 - mae: 0.2284 - msle: 0.0117 - val_loss: 0.0650 - val_mae: 0.1980 - val_msle: 0.0106\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0720 - mae: 0.2020 - msle: 0.0088 - val_loss: 0.0636 - val_mae: 0.1985 - val_msle: 0.0102\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0724 - mae: 0.2017 - msle: 0.0086 - val_loss: 0.0649 - val_mae: 0.2008 - val_msle: 0.0118\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0944 - mae: 0.2287 - msle: 0.0121 - val_loss: 0.0657 - val_mae: 0.2005 - val_msle: 0.0095\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0890 - mae: 0.2231 - msle: 0.0107 - val_loss: 0.0746 - val_mae: 0.2115 - val_msle: 0.0119\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0944 - mae: 0.2289 - msle: 0.0126 - val_loss: 0.0566 - val_mae: 0.1822 - val_msle: 0.0077\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0812 - mae: 0.2171 - msle: 0.0096 - val_loss: 0.0772 - val_mae: 0.2178 - val_msle: 0.0121\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0851 - mae: 0.2213 - msle: 0.0103 - val_loss: 0.0684 - val_mae: 0.2038 - val_msle: 0.0094\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0842 - mae: 0.2130 - msle: 0.0108 - val_loss: 0.0656 - val_mae: 0.1963 - val_msle: 0.0099\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0816 - mae: 0.2163 - msle: 0.0088 - val_loss: 0.0671 - val_mae: 0.1989 - val_msle: 0.0105\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0828 - mae: 0.2229 - msle: 0.0100 - val_loss: 0.0706 - val_mae: 0.2072 - val_msle: 0.0107\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0990 - mae: 0.2228 - msle: 0.0111 - val_loss: 0.0623 - val_mae: 0.1893 - val_msle: 0.0084\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0726 - mae: 0.2071 - msle: 0.0091 - val_loss: 0.0655 - val_mae: 0.1966 - val_msle: 0.0103\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0733 - mae: 0.2120 - msle: 0.0084 - val_loss: 0.0682 - val_mae: 0.2005 - val_msle: 0.0113\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0787 - mae: 0.2032 - msle: 0.0103 - val_loss: 0.0641 - val_mae: 0.1946 - val_msle: 0.0085\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0756 - mae: 0.2007 - msle: 0.0090 - val_loss: 0.0635 - val_mae: 0.1951 - val_msle: 0.0094\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0644 - mae: 0.1995 - msle: 0.0085 - val_loss: 0.0575 - val_mae: 0.1856 - val_msle: 0.0084\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0709 - mae: 0.2018 - msle: 0.0091 - val_loss: 0.0589 - val_mae: 0.1851 - val_msle: 0.0087\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0742 - mae: 0.2063 - msle: 0.0099 - val_loss: 0.0609 - val_mae: 0.1907 - val_msle: 0.0092\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0699 - mae: 0.1967 - msle: 0.0099 - val_loss: 0.0571 - val_mae: 0.1852 - val_msle: 0.0076\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0836 - mae: 0.2225 - msle: 0.0116 - val_loss: 0.0983 - val_mae: 0.2359 - val_msle: 0.0147\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0732 - mae: 0.1993 - msle: 0.0097 - val_loss: 0.0606 - val_mae: 0.1895 - val_msle: 0.0083\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0691 - mae: 0.1954 - msle: 0.0078 - val_loss: 0.0652 - val_mae: 0.1993 - val_msle: 0.0106\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0656 - mae: 0.1946 - msle: 0.0090 - val_loss: 0.0549 - val_mae: 0.1866 - val_msle: 0.0084\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0777 - mae: 0.2077 - msle: 0.0112 - val_loss: 0.0697 - val_mae: 0.2059 - val_msle: 0.0079\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0705 - mae: 0.1998 - msle: 0.0083 - val_loss: 0.0518 - val_mae: 0.1798 - val_msle: 0.0068\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0683 - mae: 0.1990 - msle: 0.0090 - val_loss: 0.0693 - val_mae: 0.2034 - val_msle: 0.0117\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0774 - mae: 0.2079 - msle: 0.0104 - val_loss: 0.0575 - val_mae: 0.1857 - val_msle: 0.0080\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0750 - mae: 0.2027 - msle: 0.0094 - val_loss: 0.0562 - val_mae: 0.1851 - val_msle: 0.0082\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0728 - mae: 0.2040 - msle: 0.0085 - val_loss: 0.0600 - val_mae: 0.1942 - val_msle: 0.0086\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0656 - mae: 0.1949 - msle: 0.0090 - val_loss: 0.0551 - val_mae: 0.1860 - val_msle: 0.0084\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0702 - mae: 0.2007 - msle: 0.0090 - val_loss: 0.0589 - val_mae: 0.1875 - val_msle: 0.0087\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0642 - mae: 0.1958 - msle: 0.0068 - val_loss: 0.0615 - val_mae: 0.1953 - val_msle: 0.0103\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0665 - mae: 0.1931 - msle: 0.0083 - val_loss: 0.0564 - val_mae: 0.1882 - val_msle: 0.0088\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0609 - mae: 0.1872 - msle: 0.0077 - val_loss: 0.0669 - val_mae: 0.2036 - val_msle: 0.0100\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0701 - mae: 0.1983 - msle: 0.0085 - val_loss: 0.0645 - val_mae: 0.1993 - val_msle: 0.0101\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0786 - mae: 0.2132 - msle: 0.0095 - val_loss: 0.0592 - val_mae: 0.1911 - val_msle: 0.0093\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0639 - mae: 0.1947 - msle: 0.0084 - val_loss: 0.0658 - val_mae: 0.1991 - val_msle: 0.0107\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0584 - mae: 0.1850 - msle: 0.0073 - val_loss: 0.0568 - val_mae: 0.1856 - val_msle: 0.0091\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0625 - mae: 0.1881 - msle: 0.0082 - val_loss: 0.0612 - val_mae: 0.1913 - val_msle: 0.0101\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0625 - mae: 0.1863 - msle: 0.0074 - val_loss: 0.0728 - val_mae: 0.2079 - val_msle: 0.0092\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0674 - mae: 0.1945 - msle: 0.0089 - val_loss: 0.0529 - val_mae: 0.1806 - val_msle: 0.0072\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0733 - mae: 0.2043 - msle: 0.0093 - val_loss: 0.0614 - val_mae: 0.1944 - val_msle: 0.0093\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0641 - mae: 0.1933 - msle: 0.0078 - val_loss: 0.0601 - val_mae: 0.1910 - val_msle: 0.0086\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0672 - mae: 0.1958 - msle: 0.0079 - val_loss: 0.0655 - val_mae: 0.1984 - val_msle: 0.0091\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0697 - mae: 0.1933 - msle: 0.0085 - val_loss: 0.0644 - val_mae: 0.1925 - val_msle: 0.0066\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0653 - mae: 0.1886 - msle: 0.0070 - val_loss: 0.0558 - val_mae: 0.1774 - val_msle: 0.0069\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0610 - mae: 0.1869 - msle: 0.0072 - val_loss: 0.0648 - val_mae: 0.1949 - val_msle: 0.0104\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0634 - mae: 0.1916 - msle: 0.0083 - val_loss: 0.0620 - val_mae: 0.1910 - val_msle: 0.0093\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0582 - mae: 0.1785 - msle: 0.0068 - val_loss: 0.0611 - val_mae: 0.1888 - val_msle: 0.0075\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0591 - mae: 0.1866 - msle: 0.0075 - val_loss: 0.0618 - val_mae: 0.1904 - val_msle: 0.0085\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0526 - mae: 0.1725 - msle: 0.0063 - val_loss: 0.0518 - val_mae: 0.1765 - val_msle: 0.0073\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0538 - mae: 0.1761 - msle: 0.0065 - val_loss: 0.0760 - val_mae: 0.2090 - val_msle: 0.0107\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0643 - mae: 0.1884 - msle: 0.0088 - val_loss: 0.0552 - val_mae: 0.1844 - val_msle: 0.0074\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0634 - mae: 0.1826 - msle: 0.0082 - val_loss: 0.0725 - val_mae: 0.2059 - val_msle: 0.0107\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0471 - mae: 0.1683 - msle: 0.0060 - val_loss: 0.0578 - val_mae: 0.1828 - val_msle: 0.0071\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0587 - mae: 0.1828 - msle: 0.0082 - val_loss: 0.0593 - val_mae: 0.1910 - val_msle: 0.0083\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0554 - mae: 0.1807 - msle: 0.0074 - val_loss: 0.0561 - val_mae: 0.1847 - val_msle: 0.0074\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0578 - mae: 0.1803 - msle: 0.0074 - val_loss: 0.0523 - val_mae: 0.1786 - val_msle: 0.0066\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0561 - mae: 0.1774 - msle: 0.0069 - val_loss: 0.0551 - val_mae: 0.1880 - val_msle: 0.0078\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0567 - mae: 0.1820 - msle: 0.0068 - val_loss: 0.0540 - val_mae: 0.1841 - val_msle: 0.0069\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0588 - mae: 0.1809 - msle: 0.0072 - val_loss: 0.0711 - val_mae: 0.2071 - val_msle: 0.0100\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0514 - mae: 0.1717 - msle: 0.0067 - val_loss: 0.0566 - val_mae: 0.1873 - val_msle: 0.0077\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0517 - mae: 0.1721 - msle: 0.0067 - val_loss: 0.0562 - val_mae: 0.1858 - val_msle: 0.0077\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0536 - mae: 0.1732 - msle: 0.0070 - val_loss: 0.0640 - val_mae: 0.1969 - val_msle: 0.0073\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0628 - mae: 0.1871 - msle: 0.0076 - val_loss: 0.0657 - val_mae: 0.2005 - val_msle: 0.0095\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0575 - mae: 0.1792 - msle: 0.0069 - val_loss: 0.0541 - val_mae: 0.1787 - val_msle: 0.0068\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0595 - mae: 0.1871 - msle: 0.0072 - val_loss: 0.0695 - val_mae: 0.2055 - val_msle: 0.0087\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0495 - mae: 0.1656 - msle: 0.0056 - val_loss: 0.0712 - val_mae: 0.2066 - val_msle: 0.0099\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0629 - mae: 0.1855 - msle: 0.0078 - val_loss: 0.0528 - val_mae: 0.1800 - val_msle: 0.0069\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0459 - mae: 0.1627 - msle: 0.0065 - val_loss: 0.0619 - val_mae: 0.1960 - val_msle: 0.0094\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0547 - mae: 0.1738 - msle: 0.0081 - val_loss: 0.0573 - val_mae: 0.1877 - val_msle: 0.0083\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0515 - mae: 0.1769 - msle: 0.0070 - val_loss: 0.0607 - val_mae: 0.1919 - val_msle: 0.0078\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0513 - mae: 0.1716 - msle: 0.0069 - val_loss: 0.0635 - val_mae: 0.1953 - val_msle: 0.0091\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0597 - mae: 0.1808 - msle: 0.0073 - val_loss: 0.0618 - val_mae: 0.1897 - val_msle: 0.0081\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0547 - mae: 0.1718 - msle: 0.0066 - val_loss: 0.0609 - val_mae: 0.1897 - val_msle: 0.0071\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0474 - mae: 0.1654 - msle: 0.0056 - val_loss: 0.0731 - val_mae: 0.2080 - val_msle: 0.0095\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0508 - mae: 0.1712 - msle: 0.0076 - val_loss: 0.0608 - val_mae: 0.1899 - val_msle: 0.0077\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0549 - mae: 0.1774 - msle: 0.0076 - val_loss: 0.0771 - val_mae: 0.2115 - val_msle: 0.0108\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0627 - mae: 0.1831 - msle: 0.0077 - val_loss: 0.0762 - val_mae: 0.2123 - val_msle: 0.0108\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0570 - mae: 0.1790 - msle: 0.0081 - val_loss: 0.0758 - val_mae: 0.2109 - val_msle: 0.0120\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0530 - mae: 0.1757 - msle: 0.0077 - val_loss: 0.0679 - val_mae: 0.2003 - val_msle: 0.0102\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0499 - mae: 0.1677 - msle: 0.0065 - val_loss: 0.0651 - val_mae: 0.1921 - val_msle: 0.0087\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0555 - mae: 0.1768 - msle: 0.0056 - val_loss: 0.0605 - val_mae: 0.1881 - val_msle: 0.0089\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0501 - mae: 0.1716 - msle: 0.0060 - val_loss: 0.0600 - val_mae: 0.1854 - val_msle: 0.0080\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0588 - mae: 0.1788 - msle: 0.0064 - val_loss: 0.0681 - val_mae: 0.2006 - val_msle: 0.0094\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0475 - mae: 0.1687 - msle: 0.0065 - val_loss: 0.0806 - val_mae: 0.2023 - val_msle: 0.0087\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0508 - mae: 0.1647 - msle: 0.0056 - val_loss: 0.0853 - val_mae: 0.2162 - val_msle: 0.0113\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0498 - mae: 0.1694 - msle: 0.0068 - val_loss: 0.0648 - val_mae: 0.1931 - val_msle: 0.0084\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0436 - mae: 0.1586 - msle: 0.0042 - val_loss: 0.0616 - val_mae: 0.1902 - val_msle: 0.0083\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0408 - mae: 0.1548 - msle: 0.0057 - val_loss: 0.0543 - val_mae: 0.1786 - val_msle: 0.0076\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0511 - mae: 0.1664 - msle: 0.0065 - val_loss: 0.0784 - val_mae: 0.2112 - val_msle: 0.0109\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0445 - mae: 0.1572 - msle: 0.0051 - val_loss: 0.0646 - val_mae: 0.1985 - val_msle: 0.0089\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0554 - mae: 0.1744 - msle: 0.0066 - val_loss: 0.0591 - val_mae: 0.1890 - val_msle: 0.0082\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0487 - mae: 0.1637 - msle: 0.0054 - val_loss: 0.0801 - val_mae: 0.2106 - val_msle: 0.0103\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0503 - mae: 0.1691 - msle: 0.0063 - val_loss: 0.0583 - val_mae: 0.1858 - val_msle: 0.0075\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0506 - mae: 0.1673 - msle: 0.0066 - val_loss: 0.0736 - val_mae: 0.2100 - val_msle: 0.0102\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0424 - mae: 0.1556 - msle: 0.0055 - val_loss: 0.0516 - val_mae: 0.1749 - val_msle: 0.0067\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0468 - mae: 0.1577 - msle: 0.0067 - val_loss: 0.0655 - val_mae: 0.2005 - val_msle: 0.0105\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0414 - mae: 0.1544 - msle: 0.0055 - val_loss: 0.0816 - val_mae: 0.2073 - val_msle: 0.0100\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0512 - mae: 0.1667 - msle: 0.0062 - val_loss: 0.0548 - val_mae: 0.1782 - val_msle: 0.0071\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0499 - mae: 0.1711 - msle: 0.0067 - val_loss: 0.0795 - val_mae: 0.2197 - val_msle: 0.0113\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0504 - mae: 0.1676 - msle: 0.0063 - val_loss: 0.0949 - val_mae: 0.2163 - val_msle: 0.0104\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0487 - mae: 0.1617 - msle: 0.0055 - val_loss: 0.0639 - val_mae: 0.1954 - val_msle: 0.0102\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0482 - mae: 0.1670 - msle: 0.0059 - val_loss: 0.0635 - val_mae: 0.1917 - val_msle: 0.0085\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0409 - mae: 0.1493 - msle: 0.0049 - val_loss: 0.0751 - val_mae: 0.2073 - val_msle: 0.0102\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0470 - mae: 0.1613 - msle: 0.0056 - val_loss: 0.0534 - val_mae: 0.1755 - val_msle: 0.0070\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0431 - mae: 0.1602 - msle: 0.0050 - val_loss: 0.0740 - val_mae: 0.1981 - val_msle: 0.0093\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0481 - mae: 0.1593 - msle: 0.0065 - val_loss: 0.0517 - val_mae: 0.1724 - val_msle: 0.0074\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0571 - mae: 0.1673 - msle: 0.0073 - val_loss: 0.0588 - val_mae: 0.1822 - val_msle: 0.0072\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0573 - mae: 0.1735 - msle: 0.0070 - val_loss: 0.0619 - val_mae: 0.1904 - val_msle: 0.0084\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0487 - mae: 0.1694 - msle: 0.0063 - val_loss: 0.0628 - val_mae: 0.1869 - val_msle: 0.0077\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0512 - mae: 0.1641 - msle: 0.0064 - val_loss: 0.0600 - val_mae: 0.1856 - val_msle: 0.0075\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0417 - mae: 0.1541 - msle: 0.0048 - val_loss: 0.0903 - val_mae: 0.2162 - val_msle: 0.0106\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0476 - mae: 0.1607 - msle: 0.0057 - val_loss: 0.0749 - val_mae: 0.2082 - val_msle: 0.0089\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0480 - mae: 0.1661 - msle: 0.0061 - val_loss: 0.0677 - val_mae: 0.1947 - val_msle: 0.0086\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 0.1486 - msle: 0.0057 - val_loss: 0.0774 - val_mae: 0.1935 - val_msle: 0.0093\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0502 - mae: 0.1645 - msle: 0.0059 - val_loss: 0.0796 - val_mae: 0.1935 - val_msle: 0.0087\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0527 - mae: 0.1723 - msle: 0.0064 - val_loss: 0.0785 - val_mae: 0.1962 - val_msle: 0.0087\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0423 - mae: 0.1516 - msle: 0.0053 - val_loss: 0.0861 - val_mae: 0.2130 - val_msle: 0.0119\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0457 - mae: 0.1594 - msle: 0.0051 - val_loss: 0.0798 - val_mae: 0.1994 - val_msle: 0.0096\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 0.1552 - msle: 0.0050 - val_loss: 0.0901 - val_mae: 0.2034 - val_msle: 0.0105\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0524 - mae: 0.1654 - msle: 0.0061 - val_loss: 0.0721 - val_mae: 0.1868 - val_msle: 0.0080\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0417 - mae: 0.1496 - msle: 0.0049 - val_loss: 0.0616 - val_mae: 0.1835 - val_msle: 0.0074\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0434 - mae: 0.1565 - msle: 0.0056 - val_loss: 0.0540 - val_mae: 0.1756 - val_msle: 0.0071\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 0.1544 - msle: 0.0057 - val_loss: 0.0660 - val_mae: 0.1954 - val_msle: 0.0095\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0403 - mae: 0.1522 - msle: 0.0049 - val_loss: 0.0716 - val_mae: 0.2045 - val_msle: 0.0083\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0403 - mae: 0.1542 - msle: 0.0044 - val_loss: 0.0530 - val_mae: 0.1726 - val_msle: 0.0068\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0528 - mae: 0.1727 - msle: 0.0069 - val_loss: 0.0987 - val_mae: 0.2168 - val_msle: 0.0113\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0442 - mae: 0.1560 - msle: 0.0068 - val_loss: 0.0742 - val_mae: 0.1949 - val_msle: 0.0088\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0405 - mae: 0.1528 - msle: 0.0051 - val_loss: 0.0665 - val_mae: 0.1924 - val_msle: 0.0076\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0391 - mae: 0.1534 - msle: 0.0055 - val_loss: 0.0669 - val_mae: 0.1927 - val_msle: 0.0087\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 0.1542 - msle: 0.0054 - val_loss: 0.0751 - val_mae: 0.1976 - val_msle: 0.0087\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0420 - mae: 0.1545 - msle: 0.0051 - val_loss: 0.0746 - val_mae: 0.1955 - val_msle: 0.0089\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0420 - mae: 0.1499 - msle: 0.0049 - val_loss: 0.0572 - val_mae: 0.1809 - val_msle: 0.0080\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0417 - mae: 0.1546 - msle: 0.0054 - val_loss: 0.0995 - val_mae: 0.2119 - val_msle: 0.0107\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0418 - mae: 0.1480 - msle: 0.0051 - val_loss: 0.0771 - val_mae: 0.1941 - val_msle: 0.0081\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0425 - mae: 0.1514 - msle: 0.0051 - val_loss: 0.0837 - val_mae: 0.1978 - val_msle: 0.0096\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0397 - mae: 0.1478 - msle: 0.0046 - val_loss: 0.0909 - val_mae: 0.2090 - val_msle: 0.0107\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0390 - mae: 0.1493 - msle: 0.0052 - val_loss: 0.0782 - val_mae: 0.1986 - val_msle: 0.0090\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 0.1530 - msle: 0.0055 - val_loss: 0.0761 - val_mae: 0.1935 - val_msle: 0.0089\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 0.1525 - msle: 0.0053 - val_loss: 0.0973 - val_mae: 0.2162 - val_msle: 0.0121\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0453 - mae: 0.1542 - msle: 0.0047 - val_loss: 0.0719 - val_mae: 0.1908 - val_msle: 0.0089\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0444 - mae: 0.1548 - msle: 0.0057 - val_loss: 0.0790 - val_mae: 0.2086 - val_msle: 0.0088\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0403 - mae: 0.1462 - msle: 0.0050 - val_loss: 0.0714 - val_mae: 0.1913 - val_msle: 0.0080\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0404 - mae: 0.1514 - msle: 0.0050 - val_loss: 0.0609 - val_mae: 0.1807 - val_msle: 0.0079\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0428 - mae: 0.1544 - msle: 0.0054 - val_loss: 0.0655 - val_mae: 0.1884 - val_msle: 0.0089\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0376 - mae: 0.1470 - msle: 0.0047 - val_loss: 0.0776 - val_mae: 0.2016 - val_msle: 0.0099\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0381 - mae: 0.1435 - msle: 0.0046 - val_loss: 0.0744 - val_mae: 0.1966 - val_msle: 0.0085\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0381 - mae: 0.1456 - msle: 0.0056 - val_loss: 0.0939 - val_mae: 0.2140 - val_msle: 0.0109\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0430 - mae: 0.1535 - msle: 0.0051 - val_loss: 0.0721 - val_mae: 0.1950 - val_msle: 0.0093\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0415 - mae: 0.1505 - msle: 0.0053 - val_loss: 0.0821 - val_mae: 0.2055 - val_msle: 0.0101\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0410 - mae: 0.1540 - msle: 0.0057 - val_loss: 0.0791 - val_mae: 0.2089 - val_msle: 0.0104\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0372 - mae: 0.1453 - msle: 0.0051 - val_loss: 0.0775 - val_mae: 0.2090 - val_msle: 0.0105\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0392 - mae: 0.1512 - msle: 0.0053 - val_loss: 0.0742 - val_mae: 0.1985 - val_msle: 0.0097\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0365 - mae: 0.1465 - msle: 0.0044 - val_loss: 0.0917 - val_mae: 0.2085 - val_msle: 0.0113\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 0.1602 - msle: 0.0054 - val_loss: 0.0672 - val_mae: 0.1912 - val_msle: 0.0078\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0394 - mae: 0.1477 - msle: 0.0044 - val_loss: 0.0941 - val_mae: 0.2122 - val_msle: 0.0109\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0456 - mae: 0.1569 - msle: 0.0059 - val_loss: 0.0657 - val_mae: 0.1903 - val_msle: 0.0086\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0433 - mae: 0.1548 - msle: 0.0061 - val_loss: 0.1005 - val_mae: 0.2283 - val_msle: 0.0135\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0391 - mae: 0.1516 - msle: 0.0048 - val_loss: 0.0631 - val_mae: 0.1879 - val_msle: 0.0086\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0361 - mae: 0.1430 - msle: 0.0050 - val_loss: 0.0674 - val_mae: 0.1894 - val_msle: 0.0087\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0378 - mae: 0.1483 - msle: 0.0054 - val_loss: 0.0715 - val_mae: 0.1944 - val_msle: 0.0090\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0368 - mae: 0.1449 - msle: 0.0047 - val_loss: 0.1011 - val_mae: 0.2124 - val_msle: 0.0114\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0443 - mae: 0.1507 - msle: 0.0042 - val_loss: 0.0878 - val_mae: 0.2161 - val_msle: 0.0104\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0370 - mae: 0.1470 - msle: 0.0044 - val_loss: 0.0679 - val_mae: 0.1908 - val_msle: 0.0096\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0459 - mae: 0.1601 - msle: 0.0061 - val_loss: 0.0948 - val_mae: 0.2130 - val_msle: 0.0114\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0346 - mae: 0.1389 - msle: 0.0042 - val_loss: 0.0739 - val_mae: 0.1893 - val_msle: 0.0080\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0371 - mae: 0.1434 - msle: 0.0047 - val_loss: 0.0878 - val_mae: 0.2094 - val_msle: 0.0094\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0353 - mae: 0.1381 - msle: 0.0043 - val_loss: 0.0821 - val_mae: 0.2020 - val_msle: 0.0100\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0444 - mae: 0.1517 - msle: 0.0051 - val_loss: 0.0692 - val_mae: 0.1926 - val_msle: 0.0085\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 0.1495 - msle: 0.0046 - val_loss: 0.1000 - val_mae: 0.2160 - val_msle: 0.0123\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0404 - mae: 0.1489 - msle: 0.0055 - val_loss: 0.0561 - val_mae: 0.1783 - val_msle: 0.0072\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0383 - mae: 0.1394 - msle: 0.0044 - val_loss: 0.0825 - val_mae: 0.1983 - val_msle: 0.0099\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0376 - mae: 0.1452 - msle: 0.0048 - val_loss: 0.0809 - val_mae: 0.2035 - val_msle: 0.0103\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0373 - mae: 0.1427 - msle: 0.0051 - val_loss: 0.0921 - val_mae: 0.2087 - val_msle: 0.0109\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0397 - mae: 0.1502 - msle: 0.0057 - val_loss: 0.0866 - val_mae: 0.2110 - val_msle: 0.0107\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0363 - mae: 0.1386 - msle: 0.0049 - val_loss: 0.0796 - val_mae: 0.2043 - val_msle: 0.0096\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0396 - mae: 0.1488 - msle: 0.0045 - val_loss: 0.0815 - val_mae: 0.2093 - val_msle: 0.0108\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0369 - mae: 0.1484 - msle: 0.0047 - val_loss: 0.0706 - val_mae: 0.1880 - val_msle: 0.0088\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 0.1492 - msle: 0.0050 - val_loss: 0.1105 - val_mae: 0.2338 - val_msle: 0.0142\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0421 - mae: 0.1506 - msle: 0.0057 - val_loss: 0.0839 - val_mae: 0.1981 - val_msle: 0.0095\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0358 - mae: 0.1414 - msle: 0.0039 - val_loss: 0.0856 - val_mae: 0.1985 - val_msle: 0.0096\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0342 - mae: 0.1384 - msle: 0.0043 - val_loss: 0.0786 - val_mae: 0.1982 - val_msle: 0.0098\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0405 - mae: 0.1459 - msle: 0.0054 - val_loss: 0.0731 - val_mae: 0.1966 - val_msle: 0.0093\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0385 - mae: 0.1476 - msle: 0.0042 - val_loss: 0.0940 - val_mae: 0.2127 - val_msle: 0.0113\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0350 - mae: 0.1442 - msle: 0.0039 - val_loss: 0.0915 - val_mae: 0.2046 - val_msle: 0.0105\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0367 - mae: 0.1373 - msle: 0.0039 - val_loss: 0.0816 - val_mae: 0.1983 - val_msle: 0.0100\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0397 - mae: 0.1484 - msle: 0.0047 - val_loss: 0.1251 - val_mae: 0.2336 - val_msle: 0.0147\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0419 - mae: 0.1480 - msle: 0.0060 - val_loss: 0.0849 - val_mae: 0.2038 - val_msle: 0.0112\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0296 - mae: 0.1290 - msle: 0.0041 - val_loss: 0.0971 - val_mae: 0.2138 - val_msle: 0.0123\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0337 - mae: 0.1406 - msle: 0.0038 - val_loss: 0.0723 - val_mae: 0.1890 - val_msle: 0.0089\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0380 - mae: 0.1414 - msle: 0.0049 - val_loss: 0.0876 - val_mae: 0.2040 - val_msle: 0.0106\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0370 - mae: 0.1431 - msle: 0.0055 - val_loss: 0.0807 - val_mae: 0.1985 - val_msle: 0.0100\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0354 - mae: 0.1360 - msle: 0.0037 - val_loss: 0.1118 - val_mae: 0.2244 - val_msle: 0.0143\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0428 - mae: 0.1403 - msle: 0.0050 - val_loss: 0.0603 - val_mae: 0.1794 - val_msle: 0.0074\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0409 - mae: 0.1438 - msle: 0.0054 - val_loss: 0.0936 - val_mae: 0.2059 - val_msle: 0.0104\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0350 - mae: 0.1429 - msle: 0.0048 - val_loss: 0.0668 - val_mae: 0.1818 - val_msle: 0.0076\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0339 - mae: 0.1416 - msle: 0.0043 - val_loss: 0.0857 - val_mae: 0.2087 - val_msle: 0.0125\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0352 - mae: 0.1406 - msle: 0.0038 - val_loss: 0.0867 - val_mae: 0.2002 - val_msle: 0.0101\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0353 - mae: 0.1434 - msle: 0.0043 - val_loss: 0.0522 - val_mae: 0.1670 - val_msle: 0.0061\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0389 - mae: 0.1443 - msle: 0.0051 - val_loss: 0.0786 - val_mae: 0.1938 - val_msle: 0.0098\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0334 - mae: 0.1393 - msle: 0.0036 - val_loss: 0.0944 - val_mae: 0.2039 - val_msle: 0.0095\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0330 - mae: 0.1378 - msle: 0.0034 - val_loss: 0.0882 - val_mae: 0.1979 - val_msle: 0.0091\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1246 - msle: 0.0039 - val_loss: 0.0956 - val_mae: 0.2090 - val_msle: 0.0104\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0363 - mae: 0.1455 - msle: 0.0049 - val_loss: 0.0724 - val_mae: 0.1889 - val_msle: 0.0085\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0324 - mae: 0.1357 - msle: 0.0038 - val_loss: 0.0680 - val_mae: 0.1836 - val_msle: 0.0082\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0375 - mae: 0.1448 - msle: 0.0054 - val_loss: 0.0980 - val_mae: 0.2128 - val_msle: 0.0122\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0395 - mae: 0.1478 - msle: 0.0054 - val_loss: 0.0633 - val_mae: 0.1838 - val_msle: 0.0083\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0372 - mae: 0.1416 - msle: 0.0043 - val_loss: 0.0583 - val_mae: 0.1787 - val_msle: 0.0079\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0376 - mae: 0.1440 - msle: 0.0047 - val_loss: 0.0814 - val_mae: 0.2067 - val_msle: 0.0095\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0321 - mae: 0.1354 - msle: 0.0037 - val_loss: 0.0825 - val_mae: 0.1990 - val_msle: 0.0093\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0341 - mae: 0.1367 - msle: 0.0048 - val_loss: 0.0712 - val_mae: 0.1926 - val_msle: 0.0083\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0342 - mae: 0.1396 - msle: 0.0047 - val_loss: 0.0652 - val_mae: 0.1842 - val_msle: 0.0083\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0302 - mae: 0.1279 - msle: 0.0035 - val_loss: 0.0987 - val_mae: 0.2257 - val_msle: 0.0111\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0327 - mae: 0.1374 - msle: 0.0041 - val_loss: 0.0753 - val_mae: 0.1894 - val_msle: 0.0087\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0424 - mae: 0.1421 - msle: 0.0050 - val_loss: 0.0922 - val_mae: 0.2132 - val_msle: 0.0106\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0363 - mae: 0.1396 - msle: 0.0050 - val_loss: 0.0661 - val_mae: 0.1881 - val_msle: 0.0080\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0324 - mae: 0.1345 - msle: 0.0042 - val_loss: 0.0575 - val_mae: 0.1829 - val_msle: 0.0072\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0412 - mae: 0.1466 - msle: 0.0056 - val_loss: 0.0713 - val_mae: 0.1920 - val_msle: 0.0090\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0325 - mae: 0.1385 - msle: 0.0041 - val_loss: 0.0496 - val_mae: 0.1667 - val_msle: 0.0063\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0372 - mae: 0.1404 - msle: 0.0041 - val_loss: 0.0749 - val_mae: 0.1897 - val_msle: 0.0094\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1343 - msle: 0.0038 - val_loss: 0.0543 - val_mae: 0.1773 - val_msle: 0.0070\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1382 - msle: 0.0040 - val_loss: 0.0713 - val_mae: 0.1914 - val_msle: 0.0090\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0373 - mae: 0.1386 - msle: 0.0042 - val_loss: 0.0563 - val_mae: 0.1784 - val_msle: 0.0067\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0384 - mae: 0.1463 - msle: 0.0045 - val_loss: 0.0685 - val_mae: 0.1893 - val_msle: 0.0083\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0382 - mae: 0.1386 - msle: 0.0039 - val_loss: 0.0591 - val_mae: 0.1773 - val_msle: 0.0073\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0366 - mae: 0.1407 - msle: 0.0046 - val_loss: 0.1062 - val_mae: 0.2216 - val_msle: 0.0132\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0404 - mae: 0.1485 - msle: 0.0055 - val_loss: 0.0768 - val_mae: 0.1902 - val_msle: 0.0087\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0353 - mae: 0.1367 - msle: 0.0045 - val_loss: 0.0802 - val_mae: 0.2001 - val_msle: 0.0096\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0345 - mae: 0.1370 - msle: 0.0040 - val_loss: 0.0923 - val_mae: 0.2056 - val_msle: 0.0109\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0314 - mae: 0.1345 - msle: 0.0037 - val_loss: 0.0637 - val_mae: 0.1824 - val_msle: 0.0096\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0313 - mae: 0.1355 - msle: 0.0035 - val_loss: 0.0647 - val_mae: 0.1865 - val_msle: 0.0096\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0373 - mae: 0.1434 - msle: 0.0045 - val_loss: 0.0857 - val_mae: 0.1996 - val_msle: 0.0101\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0351 - mae: 0.1342 - msle: 0.0036 - val_loss: 0.0749 - val_mae: 0.1849 - val_msle: 0.0090\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0278 - mae: 0.1262 - msle: 0.0032 - val_loss: 0.0715 - val_mae: 0.1844 - val_msle: 0.0089\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0372 - mae: 0.1392 - msle: 0.0046 - val_loss: 0.0676 - val_mae: 0.1843 - val_msle: 0.0079\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0338 - mae: 0.1370 - msle: 0.0043 - val_loss: 0.0866 - val_mae: 0.2011 - val_msle: 0.0102\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0320 - mae: 0.1342 - msle: 0.0040 - val_loss: 0.0699 - val_mae: 0.1870 - val_msle: 0.0082\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0293 - mae: 0.1290 - msle: 0.0041 - val_loss: 0.0933 - val_mae: 0.2082 - val_msle: 0.0110\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0346 - mae: 0.1378 - msle: 0.0045 - val_loss: 0.0744 - val_mae: 0.1959 - val_msle: 0.0098\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0340 - mae: 0.1327 - msle: 0.0043 - val_loss: 0.0845 - val_mae: 0.1987 - val_msle: 0.0102\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0361 - mae: 0.1430 - msle: 0.0052 - val_loss: 0.1115 - val_mae: 0.2264 - val_msle: 0.0156\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1281 - msle: 0.0043 - val_loss: 0.0799 - val_mae: 0.1894 - val_msle: 0.0095\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0322 - mae: 0.1326 - msle: 0.0038 - val_loss: 0.0776 - val_mae: 0.1892 - val_msle: 0.0098\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0294 - mae: 0.1300 - msle: 0.0036 - val_loss: 0.0879 - val_mae: 0.1996 - val_msle: 0.0109\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0363 - mae: 0.1400 - msle: 0.0043 - val_loss: 0.0640 - val_mae: 0.1762 - val_msle: 0.0081\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0315 - mae: 0.1286 - msle: 0.0035 - val_loss: 0.0861 - val_mae: 0.2002 - val_msle: 0.0100\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0277 - mae: 0.1267 - msle: 0.0036 - val_loss: 0.0773 - val_mae: 0.1893 - val_msle: 0.0090\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1326 - msle: 0.0040 - val_loss: 0.0687 - val_mae: 0.1855 - val_msle: 0.0076\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1262 - msle: 0.0039 - val_loss: 0.0765 - val_mae: 0.1906 - val_msle: 0.0091\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1319 - msle: 0.0038 - val_loss: 0.0742 - val_mae: 0.1884 - val_msle: 0.0084\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0342 - mae: 0.1335 - msle: 0.0050 - val_loss: 0.0709 - val_mae: 0.1842 - val_msle: 0.0095\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0284 - mae: 0.1281 - msle: 0.0034 - val_loss: 0.0687 - val_mae: 0.1807 - val_msle: 0.0082\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1273 - msle: 0.0039 - val_loss: 0.0766 - val_mae: 0.1915 - val_msle: 0.0088\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0304 - mae: 0.1320 - msle: 0.0037 - val_loss: 0.0961 - val_mae: 0.2126 - val_msle: 0.0116\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0301 - mae: 0.1255 - msle: 0.0040 - val_loss: 0.0710 - val_mae: 0.1801 - val_msle: 0.0080\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1331 - msle: 0.0034 - val_loss: 0.0879 - val_mae: 0.2053 - val_msle: 0.0093\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1313 - msle: 0.0039 - val_loss: 0.0775 - val_mae: 0.1965 - val_msle: 0.0096\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1255 - msle: 0.0036 - val_loss: 0.0812 - val_mae: 0.1977 - val_msle: 0.0092\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1220 - msle: 0.0030 - val_loss: 0.0938 - val_mae: 0.2080 - val_msle: 0.0110\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0292 - mae: 0.1247 - msle: 0.0038 - val_loss: 0.0830 - val_mae: 0.1972 - val_msle: 0.0088\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0374 - mae: 0.1435 - msle: 0.0044 - val_loss: 0.0809 - val_mae: 0.1995 - val_msle: 0.0082\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0260 - mae: 0.1217 - msle: 0.0032 - val_loss: 0.0829 - val_mae: 0.1928 - val_msle: 0.0095\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0334 - mae: 0.1364 - msle: 0.0045 - val_loss: 0.0834 - val_mae: 0.2008 - val_msle: 0.0106\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0311 - mae: 0.1302 - msle: 0.0038 - val_loss: 0.0703 - val_mae: 0.1790 - val_msle: 0.0083\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0345 - mae: 0.1345 - msle: 0.0046 - val_loss: 0.0985 - val_mae: 0.2119 - val_msle: 0.0115\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0364 - mae: 0.1428 - msle: 0.0052 - val_loss: 0.0807 - val_mae: 0.1877 - val_msle: 0.0092\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0317 - mae: 0.1292 - msle: 0.0045 - val_loss: 0.0766 - val_mae: 0.1913 - val_msle: 0.0094\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0338 - mae: 0.1382 - msle: 0.0047 - val_loss: 0.0703 - val_mae: 0.1876 - val_msle: 0.0087\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0325 - mae: 0.1368 - msle: 0.0044 - val_loss: 0.1053 - val_mae: 0.2249 - val_msle: 0.0109\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0346 - mae: 0.1379 - msle: 0.0038 - val_loss: 0.0937 - val_mae: 0.2087 - val_msle: 0.0101\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0336 - mae: 0.1351 - msle: 0.0043 - val_loss: 0.0705 - val_mae: 0.1829 - val_msle: 0.0086\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0309 - mae: 0.1322 - msle: 0.0042 - val_loss: 0.1028 - val_mae: 0.2085 - val_msle: 0.0121\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1266 - msle: 0.0034 - val_loss: 0.0850 - val_mae: 0.1971 - val_msle: 0.0094\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0328 - mae: 0.1345 - msle: 0.0045 - val_loss: 0.0867 - val_mae: 0.1989 - val_msle: 0.0101\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0296 - mae: 0.1299 - msle: 0.0038 - val_loss: 0.0660 - val_mae: 0.1865 - val_msle: 0.0086\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1316 - msle: 0.0042 - val_loss: 0.0782 - val_mae: 0.1964 - val_msle: 0.0096\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0290 - mae: 0.1250 - msle: 0.0037 - val_loss: 0.0895 - val_mae: 0.2103 - val_msle: 0.0102\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0323 - mae: 0.1301 - msle: 0.0040 - val_loss: 0.0710 - val_mae: 0.1872 - val_msle: 0.0091\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0328 - mae: 0.1281 - msle: 0.0035 - val_loss: 0.0918 - val_mae: 0.2070 - val_msle: 0.0111\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0308 - mae: 0.1298 - msle: 0.0039 - val_loss: 0.0732 - val_mae: 0.1955 - val_msle: 0.0090\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1252 - msle: 0.0038 - val_loss: 0.0767 - val_mae: 0.1982 - val_msle: 0.0091\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0262 - mae: 0.1231 - msle: 0.0036 - val_loss: 0.0825 - val_mae: 0.2049 - val_msle: 0.0091\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0321 - mae: 0.1315 - msle: 0.0038 - val_loss: 0.1031 - val_mae: 0.2205 - val_msle: 0.0144\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0347 - mae: 0.1348 - msle: 0.0041 - val_loss: 0.0563 - val_mae: 0.1715 - val_msle: 0.0083\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1296 - msle: 0.0032 - val_loss: 0.0798 - val_mae: 0.1955 - val_msle: 0.0096\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1286 - msle: 0.0037 - val_loss: 0.0806 - val_mae: 0.1987 - val_msle: 0.0094\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0330 - mae: 0.1264 - msle: 0.0046 - val_loss: 0.0784 - val_mae: 0.1920 - val_msle: 0.0090\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0317 - mae: 0.1328 - msle: 0.0035 - val_loss: 0.0644 - val_mae: 0.1788 - val_msle: 0.0080\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0328 - mae: 0.1367 - msle: 0.0036 - val_loss: 0.0752 - val_mae: 0.1971 - val_msle: 0.0088\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1291 - msle: 0.0041 - val_loss: 0.0730 - val_mae: 0.1920 - val_msle: 0.0087\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0308 - mae: 0.1256 - msle: 0.0035 - val_loss: 0.0532 - val_mae: 0.1704 - val_msle: 0.0068\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0302 - mae: 0.1313 - msle: 0.0042 - val_loss: 0.0850 - val_mae: 0.2025 - val_msle: 0.0101\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1242 - msle: 0.0036 - val_loss: 0.0816 - val_mae: 0.1988 - val_msle: 0.0103\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1207 - msle: 0.0039 - val_loss: 0.0723 - val_mae: 0.1948 - val_msle: 0.0099\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0297 - mae: 0.1232 - msle: 0.0034 - val_loss: 0.0734 - val_mae: 0.1886 - val_msle: 0.0089\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0285 - mae: 0.1293 - msle: 0.0035 - val_loss: 0.0584 - val_mae: 0.1866 - val_msle: 0.0087\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - mae: 0.1274 - msle: 0.0037 - val_loss: 0.0815 - val_mae: 0.1983 - val_msle: 0.0098\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0378 - mae: 0.1365 - msle: 0.0047 - val_loss: 0.0780 - val_mae: 0.1956 - val_msle: 0.0106\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0259 - mae: 0.1220 - msle: 0.0030 - val_loss: 0.0836 - val_mae: 0.2016 - val_msle: 0.0122\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1240 - msle: 0.0036 - val_loss: 0.0812 - val_mae: 0.1982 - val_msle: 0.0111\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0327 - mae: 0.1312 - msle: 0.0045 - val_loss: 0.0828 - val_mae: 0.1918 - val_msle: 0.0099\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1236 - msle: 0.0037 - val_loss: 0.0656 - val_mae: 0.1788 - val_msle: 0.0085\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1248 - msle: 0.0035 - val_loss: 0.0775 - val_mae: 0.1900 - val_msle: 0.0095\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0273 - mae: 0.1256 - msle: 0.0033 - val_loss: 0.0871 - val_mae: 0.1986 - val_msle: 0.0106\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1263 - msle: 0.0040 - val_loss: 0.0699 - val_mae: 0.1845 - val_msle: 0.0091\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0251 - mae: 0.1187 - msle: 0.0033 - val_loss: 0.0639 - val_mae: 0.1795 - val_msle: 0.0089\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0323 - mae: 0.1347 - msle: 0.0037 - val_loss: 0.0753 - val_mae: 0.1857 - val_msle: 0.0091\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0268 - mae: 0.1202 - msle: 0.0033 - val_loss: 0.0621 - val_mae: 0.1790 - val_msle: 0.0092\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0287 - mae: 0.1250 - msle: 0.0037 - val_loss: 0.0745 - val_mae: 0.1868 - val_msle: 0.0090\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0268 - mae: 0.1187 - msle: 0.0032 - val_loss: 0.0630 - val_mae: 0.1774 - val_msle: 0.0085\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1206 - msle: 0.0031 - val_loss: 0.0743 - val_mae: 0.1935 - val_msle: 0.0100\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0265 - mae: 0.1209 - msle: 0.0038 - val_loss: 0.0689 - val_mae: 0.1888 - val_msle: 0.0095\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0263 - mae: 0.1194 - msle: 0.0028 - val_loss: 0.0812 - val_mae: 0.1970 - val_msle: 0.0102\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.1249 - msle: 0.0037 - val_loss: 0.0751 - val_mae: 0.1987 - val_msle: 0.0104\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0268 - mae: 0.1243 - msle: 0.0033 - val_loss: 0.0661 - val_mae: 0.1880 - val_msle: 0.0085\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0269 - mae: 0.1225 - msle: 0.0034 - val_loss: 0.0728 - val_mae: 0.1915 - val_msle: 0.0093\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0291 - mae: 0.1284 - msle: 0.0035 - val_loss: 0.0609 - val_mae: 0.1817 - val_msle: 0.0086\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0271 - mae: 0.1215 - msle: 0.0034 - val_loss: 0.0677 - val_mae: 0.1831 - val_msle: 0.0084\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1207 - msle: 0.0036 - val_loss: 0.0760 - val_mae: 0.1949 - val_msle: 0.0085\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0247 - mae: 0.1162 - msle: 0.0028 - val_loss: 0.0658 - val_mae: 0.1925 - val_msle: 0.0092\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0261 - mae: 0.1219 - msle: 0.0038 - val_loss: 0.0607 - val_mae: 0.1818 - val_msle: 0.0083\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - mae: 0.1208 - msle: 0.0036 - val_loss: 0.0906 - val_mae: 0.2108 - val_msle: 0.0113\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1234 - msle: 0.0034 - val_loss: 0.0733 - val_mae: 0.1932 - val_msle: 0.0094\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0248 - mae: 0.1181 - msle: 0.0033 - val_loss: 0.0816 - val_mae: 0.1989 - val_msle: 0.0108\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0262 - mae: 0.1179 - msle: 0.0028 - val_loss: 0.0845 - val_mae: 0.2037 - val_msle: 0.0117\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0248 - mae: 0.1172 - msle: 0.0031 - val_loss: 0.0717 - val_mae: 0.1907 - val_msle: 0.0105\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0266 - mae: 0.1219 - msle: 0.0036 - val_loss: 0.0736 - val_mae: 0.1896 - val_msle: 0.0103\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0269 - mae: 0.1231 - msle: 0.0030 - val_loss: 0.0845 - val_mae: 0.1986 - val_msle: 0.0115\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0261 - mae: 0.1218 - msle: 0.0043 - val_loss: 0.0787 - val_mae: 0.1948 - val_msle: 0.0104\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1207 - msle: 0.0031 - val_loss: 0.0836 - val_mae: 0.1975 - val_msle: 0.0111\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0306 - mae: 0.1265 - msle: 0.0038 - val_loss: 0.0793 - val_mae: 0.1927 - val_msle: 0.0114\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0321 - mae: 0.1256 - msle: 0.0034 - val_loss: 0.0757 - val_mae: 0.1930 - val_msle: 0.0107\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0275 - mae: 0.1238 - msle: 0.0030 - val_loss: 0.0693 - val_mae: 0.1894 - val_msle: 0.0100\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0286 - mae: 0.1245 - msle: 0.0033 - val_loss: 0.0848 - val_mae: 0.2073 - val_msle: 0.0124\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1179 - msle: 0.0032 - val_loss: 0.0827 - val_mae: 0.1985 - val_msle: 0.0112\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0255 - mae: 0.1159 - msle: 0.0036 - val_loss: 0.0656 - val_mae: 0.1793 - val_msle: 0.0089\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0286 - mae: 0.1272 - msle: 0.0042 - val_loss: 0.0824 - val_mae: 0.1930 - val_msle: 0.0109\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1271 - msle: 0.0039 - val_loss: 0.0781 - val_mae: 0.1875 - val_msle: 0.0112\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1265 - msle: 0.0037 - val_loss: 0.0653 - val_mae: 0.1792 - val_msle: 0.0093\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0341 - mae: 0.1276 - msle: 0.0045 - val_loss: 0.0805 - val_mae: 0.1962 - val_msle: 0.0115\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1271 - msle: 0.0033 - val_loss: 0.0851 - val_mae: 0.1989 - val_msle: 0.0122\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0338 - mae: 0.1320 - msle: 0.0040 - val_loss: 0.0781 - val_mae: 0.1953 - val_msle: 0.0104\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0267 - mae: 0.1227 - msle: 0.0029 - val_loss: 0.0745 - val_mae: 0.1886 - val_msle: 0.0101\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0245 - mae: 0.1178 - msle: 0.0028 - val_loss: 0.0859 - val_mae: 0.2032 - val_msle: 0.0102\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0233 - mae: 0.1150 - msle: 0.0025 - val_loss: 0.0902 - val_mae: 0.2022 - val_msle: 0.0109\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0243 - mae: 0.1142 - msle: 0.0032 - val_loss: 0.0721 - val_mae: 0.1921 - val_msle: 0.0092\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0260 - mae: 0.1199 - msle: 0.0036 - val_loss: 0.0750 - val_mae: 0.1894 - val_msle: 0.0103\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0265 - mae: 0.1226 - msle: 0.0038 - val_loss: 0.0798 - val_mae: 0.1948 - val_msle: 0.0119\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0269 - mae: 0.1190 - msle: 0.0038 - val_loss: 0.0973 - val_mae: 0.2084 - val_msle: 0.0132\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0276 - mae: 0.1243 - msle: 0.0033 - val_loss: 0.0703 - val_mae: 0.1831 - val_msle: 0.0098\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1226 - msle: 0.0032 - val_loss: 0.0775 - val_mae: 0.1913 - val_msle: 0.0105\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1249 - msle: 0.0031 - val_loss: 0.0798 - val_mae: 0.1896 - val_msle: 0.0101\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0306 - mae: 0.1281 - msle: 0.0038 - val_loss: 0.0817 - val_mae: 0.1969 - val_msle: 0.0111\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0230 - mae: 0.1167 - msle: 0.0034 - val_loss: 0.0724 - val_mae: 0.1849 - val_msle: 0.0101\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0260 - mae: 0.1183 - msle: 0.0030 - val_loss: 0.0724 - val_mae: 0.1880 - val_msle: 0.0104\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0243 - mae: 0.1137 - msle: 0.0033 - val_loss: 0.0923 - val_mae: 0.2060 - val_msle: 0.0122\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0327 - mae: 0.1275 - msle: 0.0036 - val_loss: 0.0813 - val_mae: 0.2002 - val_msle: 0.0111\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0267 - mae: 0.1151 - msle: 0.0030 - val_loss: 0.0804 - val_mae: 0.2004 - val_msle: 0.0108\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0256 - mae: 0.1196 - msle: 0.0031 - val_loss: 0.0697 - val_mae: 0.1877 - val_msle: 0.0100\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0280 - mae: 0.1236 - msle: 0.0029 - val_loss: 0.0794 - val_mae: 0.2014 - val_msle: 0.0105\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0259 - mae: 0.1188 - msle: 0.0029 - val_loss: 0.0897 - val_mae: 0.2116 - val_msle: 0.0142\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0260 - mae: 0.1183 - msle: 0.0040 - val_loss: 0.0827 - val_mae: 0.1968 - val_msle: 0.0126\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0253 - mae: 0.1174 - msle: 0.0034 - val_loss: 0.0697 - val_mae: 0.1838 - val_msle: 0.0119\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.1235 - msle: 0.0035 - val_loss: 0.0763 - val_mae: 0.1905 - val_msle: 0.0108\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0222 - mae: 0.1113 - msle: 0.0029 - val_loss: 0.0882 - val_mae: 0.2007 - val_msle: 0.0133\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0266 - mae: 0.1247 - msle: 0.0031 - val_loss: 0.0903 - val_mae: 0.2049 - val_msle: 0.0137\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0251 - mae: 0.1182 - msle: 0.0031 - val_loss: 0.0776 - val_mae: 0.1917 - val_msle: 0.0112\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0278 - mae: 0.1235 - msle: 0.0037 - val_loss: 0.0873 - val_mae: 0.2032 - val_msle: 0.0104\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0255 - mae: 0.1201 - msle: 0.0036 - val_loss: 0.0779 - val_mae: 0.1878 - val_msle: 0.0103\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0238 - mae: 0.1136 - msle: 0.0035 - val_loss: 0.0931 - val_mae: 0.1981 - val_msle: 0.0119\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0230 - mae: 0.1172 - msle: 0.0029 - val_loss: 0.0786 - val_mae: 0.1889 - val_msle: 0.0105\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0240 - mae: 0.1178 - msle: 0.0027 - val_loss: 0.0860 - val_mae: 0.2031 - val_msle: 0.0120\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0247 - mae: 0.1186 - msle: 0.0032 - val_loss: 0.0820 - val_mae: 0.2007 - val_msle: 0.0112\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0258 - mae: 0.1204 - msle: 0.0028 - val_loss: 0.0847 - val_mae: 0.2031 - val_msle: 0.0108\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0216 - mae: 0.1112 - msle: 0.0028 - val_loss: 0.0707 - val_mae: 0.1888 - val_msle: 0.0095\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0256 - mae: 0.1220 - msle: 0.0032 - val_loss: 0.0890 - val_mae: 0.2053 - val_msle: 0.0105\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1258 - msle: 0.0036 - val_loss: 0.0823 - val_mae: 0.1915 - val_msle: 0.0110\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0283 - mae: 0.1237 - msle: 0.0039 - val_loss: 0.0882 - val_mae: 0.2048 - val_msle: 0.0130\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0264 - mae: 0.1155 - msle: 0.0034 - val_loss: 0.0666 - val_mae: 0.1816 - val_msle: 0.0093\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0238 - mae: 0.1156 - msle: 0.0033 - val_loss: 0.0762 - val_mae: 0.1933 - val_msle: 0.0105\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0254 - mae: 0.1188 - msle: 0.0034 - val_loss: 0.0656 - val_mae: 0.1815 - val_msle: 0.0113\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0227 - mae: 0.1138 - msle: 0.0027 - val_loss: 0.0709 - val_mae: 0.1864 - val_msle: 0.0110\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0211 - mae: 0.1115 - msle: 0.0027 - val_loss: 0.0761 - val_mae: 0.1875 - val_msle: 0.0120\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0239 - mae: 0.1126 - msle: 0.0031 - val_loss: 0.0715 - val_mae: 0.1832 - val_msle: 0.0108\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0250 - mae: 0.1166 - msle: 0.0030 - val_loss: 0.0802 - val_mae: 0.1947 - val_msle: 0.0117\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0240 - mae: 0.1149 - msle: 0.0037 - val_loss: 0.0775 - val_mae: 0.1912 - val_msle: 0.0121\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0265 - mae: 0.1162 - msle: 0.0030 - val_loss: 0.0646 - val_mae: 0.1826 - val_msle: 0.0107\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0268 - mae: 0.1195 - msle: 0.0028 - val_loss: 0.0779 - val_mae: 0.1903 - val_msle: 0.0116\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0293 - mae: 0.1211 - msle: 0.0029 - val_loss: 0.0872 - val_mae: 0.2007 - val_msle: 0.0128\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0268 - mae: 0.1223 - msle: 0.0034 - val_loss: 0.0814 - val_mae: 0.1937 - val_msle: 0.0120\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0283 - mae: 0.1196 - msle: 0.0040 - val_loss: 0.0798 - val_mae: 0.1918 - val_msle: 0.0109\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0261 - mae: 0.1088 - msle: 0.0025 - val_loss: 0.0694 - val_mae: 0.1824 - val_msle: 0.0104\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0304 - mae: 0.1230 - msle: 0.0038 - val_loss: 0.0651 - val_mae: 0.1827 - val_msle: 0.0103\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0230 - mae: 0.1130 - msle: 0.0031 - val_loss: 0.0810 - val_mae: 0.1911 - val_msle: 0.0119\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0243 - mae: 0.1166 - msle: 0.0033 - val_loss: 0.0897 - val_mae: 0.2004 - val_msle: 0.0148\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0261 - mae: 0.1206 - msle: 0.0030 - val_loss: 0.0669 - val_mae: 0.1846 - val_msle: 0.0111\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0253 - mae: 0.1178 - msle: 0.0034 - val_loss: 0.0704 - val_mae: 0.1949 - val_msle: 0.0100\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1292 - msle: 0.0040 - val_loss: 0.0664 - val_mae: 0.1894 - val_msle: 0.0104\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0257 - mae: 0.1216 - msle: 0.0033 - val_loss: 0.0735 - val_mae: 0.1915 - val_msle: 0.0117\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0274 - mae: 0.1164 - msle: 0.0034 - val_loss: 0.0781 - val_mae: 0.1962 - val_msle: 0.0117\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0242 - mae: 0.1169 - msle: 0.0033 - val_loss: 0.0815 - val_mae: 0.2016 - val_msle: 0.0132\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0262 - mae: 0.1144 - msle: 0.0037 - val_loss: 0.0782 - val_mae: 0.1997 - val_msle: 0.0119\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0215 - mae: 0.1101 - msle: 0.0032 - val_loss: 0.0905 - val_mae: 0.2021 - val_msle: 0.0136\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0239 - mae: 0.1137 - msle: 0.0035 - val_loss: 0.0757 - val_mae: 0.1937 - val_msle: 0.0122\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0211 - mae: 0.1113 - msle: 0.0027 - val_loss: 0.0704 - val_mae: 0.1886 - val_msle: 0.0106\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0293 - mae: 0.1219 - msle: 0.0042 - val_loss: 0.0765 - val_mae: 0.1979 - val_msle: 0.0119\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0253 - mae: 0.1210 - msle: 0.0039 - val_loss: 0.0741 - val_mae: 0.1917 - val_msle: 0.0104\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0239 - mae: 0.1186 - msle: 0.0030 - val_loss: 0.0733 - val_mae: 0.1895 - val_msle: 0.0098\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0211 - mae: 0.1095 - msle: 0.0025 - val_loss: 0.0662 - val_mae: 0.1798 - val_msle: 0.0105\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0333 - mae: 0.1248 - msle: 0.0037 - val_loss: 0.0783 - val_mae: 0.1949 - val_msle: 0.0108\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0242 - mae: 0.1138 - msle: 0.0034 - val_loss: 0.0701 - val_mae: 0.1856 - val_msle: 0.0095\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0265 - mae: 0.1191 - msle: 0.0039 - val_loss: 0.0701 - val_mae: 0.1845 - val_msle: 0.0100\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0203 - mae: 0.1097 - msle: 0.0026 - val_loss: 0.0771 - val_mae: 0.1933 - val_msle: 0.0107\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0217 - mae: 0.1100 - msle: 0.0027 - val_loss: 0.0726 - val_mae: 0.1865 - val_msle: 0.0113\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0238 - mae: 0.1137 - msle: 0.0031 - val_loss: 0.0789 - val_mae: 0.1855 - val_msle: 0.0112\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0236 - mae: 0.1155 - msle: 0.0027 - val_loss: 0.0737 - val_mae: 0.1827 - val_msle: 0.0095\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0217 - mae: 0.1119 - msle: 0.0029 - val_loss: 0.0896 - val_mae: 0.1969 - val_msle: 0.0118\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0267 - mae: 0.1187 - msle: 0.0033 - val_loss: 0.0808 - val_mae: 0.1939 - val_msle: 0.0110\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0213 - mae: 0.1131 - msle: 0.0027 - val_loss: 0.0773 - val_mae: 0.1901 - val_msle: 0.0119\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0237 - mae: 0.1168 - msle: 0.0029 - val_loss: 0.0798 - val_mae: 0.1915 - val_msle: 0.0123\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0225 - mae: 0.1096 - msle: 0.0029 - val_loss: 0.0712 - val_mae: 0.1859 - val_msle: 0.0116\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0211 - mae: 0.1090 - msle: 0.0026 - val_loss: 0.0858 - val_mae: 0.2024 - val_msle: 0.0131\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1209 - msle: 0.0038 - val_loss: 0.0877 - val_mae: 0.1985 - val_msle: 0.0132\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0263 - mae: 0.1173 - msle: 0.0029 - val_loss: 0.0722 - val_mae: 0.1847 - val_msle: 0.0118\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1218 - msle: 0.0038 - val_loss: 0.0803 - val_mae: 0.1928 - val_msle: 0.0119\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0258 - mae: 0.1182 - msle: 0.0037 - val_loss: 0.0768 - val_mae: 0.1879 - val_msle: 0.0102\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0263 - mae: 0.1158 - msle: 0.0033 - val_loss: 0.0636 - val_mae: 0.1768 - val_msle: 0.0095\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0249 - mae: 0.1153 - msle: 0.0033 - val_loss: 0.0806 - val_mae: 0.1906 - val_msle: 0.0106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c3bc8af0>"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize and fit sequential model\n",
    "sequential_model = create_sequential_model(df=X_train)\n",
    "sequential_model.fit(x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "id": "a9df055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict out values\n",
    "y_pred_seq = sequential_model.predict(X_test)\n",
    "\n",
    "# reverse scaling\n",
    "y_pred_seq = np.round(target_scaler.inverse_transform(np.array(y_pred_seq)))\n",
    "y_test = np.round(target_scaler.inverse_transform(np.array(y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "f0bc7563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.,  5., 10., 17., 12., 17., 11.,  9.,  7., 11.,  3.,  9.,  4.,\n",
       "         0.,  2.,  2.,  0.,  2.,  1.,  1.]),\n",
       " array([ 3.  ,  5.35,  7.7 , 10.05, 12.4 , 14.75, 17.1 , 19.45, 21.8 ,\n",
       "        24.15, 26.5 , 28.85, 31.2 , 33.55, 35.9 , 38.25, 40.6 , 42.95,\n",
       "        45.3 , 47.65, 50.  ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(y_test), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "a40cbbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7.,  6.,  5., 12., 15.,  5., 22.,  5.,  4., 10.,  7.,  3., 10.,\n",
       "         4.,  2.,  1.,  6.,  1.,  1.,  2.]),\n",
       " array([ 6.  ,  7.65,  9.3 , 10.95, 12.6 , 14.25, 15.9 , 17.55, 19.2 ,\n",
       "        20.85, 22.5 , 24.15, 25.8 , 27.45, 29.1 , 30.75, 32.4 , 34.05,\n",
       "        35.7 , 37.35, 39.  ], dtype=float32),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_seq, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "id": "16363036",
   "metadata": {},
   "outputs": [],
   "source": [
    "meld_predictions = pd.concat([pd.DataFrame(data=np.array(X_test), columns=X.columns), pd.DataFrame(data=np.array(y_pred_seq), columns=[\"MELD_Prediction\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "id": "c3cd6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy = meld_acc(meld_predictions, meld_column=\"MELD_Prediction\")\n",
    "MELD_acc = meld_acc(final_df_normalized, meld_column=\"MELD\")\n",
    "MELD3_acc = meld_acc(final_df_normalized, meld_column=\"MELD3\")\n",
    "MELDNA_acc = meld_acc(final_df_normalized, meld_column=\"MELDNA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "4c8374d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07692307692307693,\n",
       " 0.014705882352941176,\n",
       " 0.3333333333333333,\n",
       " 0.7272727272727273,\n",
       " 0]"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_accuracy"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ce551c14",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46263cdc",
   "metadata": {},
   "source": [
    "Note: Observed Mortality % is the model prediction, Expected is the baseline to measure against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "3dc60a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "a3de8508",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=12)\n",
    "scaler = StandardScaler()\n",
    "X = final_df_normalized.copy(deep=True)\n",
    "X = X.drop([\"MELD\", \"MELD3\", \"MELDNA\"], axis=1)\n",
    "non_binary_cols_pca = [col for col in X.columns if len(X[col].unique()) > 2]\n",
    "binary_cols_pca = [col for col in X.columns if len(X[col].unique()) <= 2]\n",
    "X_non_binary_pca = pd.DataFrame(scaler.fit_transform(X[non_binary_cols_pca]), columns=non_binary_cols_pca)\n",
    "X_non_binary_pca = pd.DataFrame(pca.fit_transform(X_non_binary_pca))\n",
    "X_pca = pd.concat([X[binary_cols_pca], X_non_binary_pca], axis=1)\n",
    "# X_pca = X_pca.drop([\"MELD\", \"MELD3\", \"MELDNA\"], axis=1)\n",
    "# X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "026fe6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7943800849819396"
      ]
     },
     "execution_count": 1005,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "b3abf637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_pca[0], X_pca[1], c=y)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "id": "a0260ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=7)\n",
    "X_train_pca = tf.convert_to_tensor(X_train_pca)\n",
    "X_test_pca = tf.convert_to_tensor(X_test_pca)\n",
    "y_train_pca = tf.convert_to_tensor(y_train_pca)\n",
    "y_test_pca = tf.convert_to_tensor(y_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "id": "14cdfa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.9677 - mae: 0.7500 - msle: 0.1832 - val_loss: 1.1587 - val_mae: 0.8406 - val_msle: 0.2391\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9357 - mae: 0.7352 - msle: 0.1771 - val_loss: 1.0575 - val_mae: 0.7944 - val_msle: 0.2103\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8179 - mae: 0.6751 - msle: 0.1526 - val_loss: 0.7974 - val_mae: 0.6580 - val_msle: 0.1490\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6004 - mae: 0.5626 - msle: 0.1036 - val_loss: 0.5412 - val_mae: 0.5245 - val_msle: 0.0715\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4662 - mae: 0.5063 - msle: 0.0663 - val_loss: 0.4284 - val_mae: 0.4767 - val_msle: 0.0514\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3925 - mae: 0.4753 - msle: 0.0578 - val_loss: 0.3597 - val_mae: 0.4388 - val_msle: 0.0405\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3617 - mae: 0.4585 - msle: 0.0467 - val_loss: 0.3124 - val_mae: 0.4200 - val_msle: 0.0347\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3002 - mae: 0.4196 - msle: 0.0403 - val_loss: 0.2806 - val_mae: 0.4069 - val_msle: 0.0343\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3091 - mae: 0.4232 - msle: 0.0443 - val_loss: 0.2603 - val_mae: 0.3965 - val_msle: 0.0323\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2530 - mae: 0.3899 - msle: 0.0335 - val_loss: 0.2563 - val_mae: 0.3958 - val_msle: 0.0351\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2655 - mae: 0.3917 - msle: 0.0387 - val_loss: 0.2471 - val_mae: 0.3944 - val_msle: 0.0332\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2676 - mae: 0.3956 - msle: 0.0378 - val_loss: 0.2362 - val_mae: 0.3920 - val_msle: 0.0307\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2348 - mae: 0.3770 - msle: 0.0333 - val_loss: 0.2314 - val_mae: 0.3816 - val_msle: 0.0301\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2321 - mae: 0.3693 - msle: 0.0323 - val_loss: 0.2426 - val_mae: 0.3843 - val_msle: 0.0376\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2308 - mae: 0.3668 - msle: 0.0300 - val_loss: 0.2350 - val_mae: 0.3857 - val_msle: 0.0373\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2422 - mae: 0.3758 - msle: 0.0347 - val_loss: 0.2176 - val_mae: 0.3693 - val_msle: 0.0318\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2390 - mae: 0.3740 - msle: 0.0305 - val_loss: 0.2157 - val_mae: 0.3655 - val_msle: 0.0305\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2307 - mae: 0.3700 - msle: 0.0278 - val_loss: 0.2076 - val_mae: 0.3580 - val_msle: 0.0277\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2141 - mae: 0.3595 - msle: 0.0296 - val_loss: 0.2216 - val_mae: 0.3760 - val_msle: 0.0348\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2156 - mae: 0.3666 - msle: 0.0281 - val_loss: 0.2073 - val_mae: 0.3619 - val_msle: 0.0301\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2187 - mae: 0.3605 - msle: 0.0276 - val_loss: 0.2069 - val_mae: 0.3645 - val_msle: 0.0315\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2243 - mae: 0.3687 - msle: 0.0313 - val_loss: 0.2074 - val_mae: 0.3645 - val_msle: 0.0314\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2003 - mae: 0.3398 - msle: 0.0257 - val_loss: 0.2005 - val_mae: 0.3535 - val_msle: 0.0295\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1949 - mae: 0.3462 - msle: 0.0245 - val_loss: 0.2152 - val_mae: 0.3725 - val_msle: 0.0290\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1883 - mae: 0.3291 - msle: 0.0232 - val_loss: 0.2007 - val_mae: 0.3555 - val_msle: 0.0289\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1947 - mae: 0.3371 - msle: 0.0250 - val_loss: 0.1928 - val_mae: 0.3479 - val_msle: 0.0278\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1969 - mae: 0.3359 - msle: 0.0224 - val_loss: 0.1778 - val_mae: 0.3313 - val_msle: 0.0231\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1823 - mae: 0.3277 - msle: 0.0226 - val_loss: 0.1908 - val_mae: 0.3505 - val_msle: 0.0292\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1800 - mae: 0.3329 - msle: 0.0254 - val_loss: 0.1973 - val_mae: 0.3571 - val_msle: 0.0327\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1879 - mae: 0.3301 - msle: 0.0235 - val_loss: 0.1969 - val_mae: 0.3541 - val_msle: 0.0323\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2042 - mae: 0.3441 - msle: 0.0258 - val_loss: 0.1792 - val_mae: 0.3364 - val_msle: 0.0248\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1684 - mae: 0.3175 - msle: 0.0217 - val_loss: 0.1708 - val_mae: 0.3270 - val_msle: 0.0229\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1689 - mae: 0.3195 - msle: 0.0222 - val_loss: 0.1825 - val_mae: 0.3414 - val_msle: 0.0282\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1948 - mae: 0.3388 - msle: 0.0273 - val_loss: 0.1788 - val_mae: 0.3355 - val_msle: 0.0261\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1722 - mae: 0.3214 - msle: 0.0221 - val_loss: 0.1861 - val_mae: 0.3431 - val_msle: 0.0287\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1658 - mae: 0.3173 - msle: 0.0219 - val_loss: 0.1853 - val_mae: 0.3444 - val_msle: 0.0290\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1746 - mae: 0.3194 - msle: 0.0208 - val_loss: 0.1860 - val_mae: 0.3472 - val_msle: 0.0269\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1695 - mae: 0.3216 - msle: 0.0224 - val_loss: 0.1795 - val_mae: 0.3408 - val_msle: 0.0274\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1609 - mae: 0.3075 - msle: 0.0204 - val_loss: 0.1818 - val_mae: 0.3407 - val_msle: 0.0283\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1658 - mae: 0.3125 - msle: 0.0211 - val_loss: 0.1812 - val_mae: 0.3445 - val_msle: 0.0272\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1583 - mae: 0.3057 - msle: 0.0209 - val_loss: 0.1738 - val_mae: 0.3337 - val_msle: 0.0265\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1709 - mae: 0.3150 - msle: 0.0238 - val_loss: 0.1670 - val_mae: 0.3275 - val_msle: 0.0241\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1629 - mae: 0.3041 - msle: 0.0198 - val_loss: 0.1712 - val_mae: 0.3311 - val_msle: 0.0263\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1643 - mae: 0.3117 - msle: 0.0210 - val_loss: 0.1623 - val_mae: 0.3155 - val_msle: 0.0227\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1532 - mae: 0.3048 - msle: 0.0205 - val_loss: 0.1682 - val_mae: 0.3302 - val_msle: 0.0269\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1630 - mae: 0.3111 - msle: 0.0193 - val_loss: 0.1701 - val_mae: 0.3272 - val_msle: 0.0252\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1427 - mae: 0.2907 - msle: 0.0186 - val_loss: 0.1623 - val_mae: 0.3228 - val_msle: 0.0243\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1742 - mae: 0.3168 - msle: 0.0226 - val_loss: 0.1655 - val_mae: 0.3212 - val_msle: 0.0252\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1568 - mae: 0.3047 - msle: 0.0206 - val_loss: 0.1631 - val_mae: 0.3250 - val_msle: 0.0250\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1375 - mae: 0.2880 - msle: 0.0174 - val_loss: 0.1568 - val_mae: 0.3164 - val_msle: 0.0254\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1547 - mae: 0.3074 - msle: 0.0203 - val_loss: 0.1642 - val_mae: 0.3279 - val_msle: 0.0288\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1456 - mae: 0.2981 - msle: 0.0183 - val_loss: 0.1495 - val_mae: 0.3103 - val_msle: 0.0228\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1584 - mae: 0.3016 - msle: 0.0191 - val_loss: 0.1539 - val_mae: 0.3183 - val_msle: 0.0240\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1358 - mae: 0.2817 - msle: 0.0182 - val_loss: 0.1399 - val_mae: 0.2956 - val_msle: 0.0200\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1611 - mae: 0.3015 - msle: 0.0214 - val_loss: 0.1500 - val_mae: 0.3149 - val_msle: 0.0250\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1382 - mae: 0.2852 - msle: 0.0185 - val_loss: 0.1463 - val_mae: 0.3084 - val_msle: 0.0225\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1363 - mae: 0.2859 - msle: 0.0186 - val_loss: 0.1510 - val_mae: 0.3154 - val_msle: 0.0234\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1383 - mae: 0.2880 - msle: 0.0192 - val_loss: 0.1437 - val_mae: 0.3070 - val_msle: 0.0249\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1279 - mae: 0.2821 - msle: 0.0170 - val_loss: 0.1483 - val_mae: 0.3073 - val_msle: 0.0219\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1347 - mae: 0.2862 - msle: 0.0169 - val_loss: 0.1428 - val_mae: 0.3065 - val_msle: 0.0222\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1572 - mae: 0.2915 - msle: 0.0207 - val_loss: 0.1406 - val_mae: 0.2928 - val_msle: 0.0209\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1303 - mae: 0.2740 - msle: 0.0180 - val_loss: 0.1557 - val_mae: 0.3232 - val_msle: 0.0262\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1389 - mae: 0.2846 - msle: 0.0184 - val_loss: 0.1430 - val_mae: 0.2933 - val_msle: 0.0197\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1426 - mae: 0.2901 - msle: 0.0202 - val_loss: 0.1450 - val_mae: 0.3103 - val_msle: 0.0230\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1313 - mae: 0.2775 - msle: 0.0170 - val_loss: 0.1292 - val_mae: 0.2861 - val_msle: 0.0183\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1415 - mae: 0.2883 - msle: 0.0170 - val_loss: 0.1535 - val_mae: 0.3150 - val_msle: 0.0232\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1296 - mae: 0.2810 - msle: 0.0168 - val_loss: 0.1442 - val_mae: 0.3056 - val_msle: 0.0234\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1387 - mae: 0.2839 - msle: 0.0180 - val_loss: 0.1366 - val_mae: 0.2973 - val_msle: 0.0193\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1214 - mae: 0.2678 - msle: 0.0147 - val_loss: 0.1451 - val_mae: 0.3066 - val_msle: 0.0208\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1309 - mae: 0.2736 - msle: 0.0167 - val_loss: 0.1466 - val_mae: 0.3090 - val_msle: 0.0209\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1231 - mae: 0.2666 - msle: 0.0162 - val_loss: 0.1431 - val_mae: 0.3047 - val_msle: 0.0211\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1329 - mae: 0.2699 - msle: 0.0172 - val_loss: 0.1483 - val_mae: 0.3132 - val_msle: 0.0231\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1246 - mae: 0.2614 - msle: 0.0147 - val_loss: 0.1379 - val_mae: 0.2963 - val_msle: 0.0195\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1479 - mae: 0.2934 - msle: 0.0185 - val_loss: 0.1391 - val_mae: 0.3008 - val_msle: 0.0195\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1171 - mae: 0.2607 - msle: 0.0151 - val_loss: 0.1397 - val_mae: 0.3046 - val_msle: 0.0213\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1216 - mae: 0.2658 - msle: 0.0154 - val_loss: 0.1450 - val_mae: 0.3046 - val_msle: 0.0207\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1225 - mae: 0.2715 - msle: 0.0165 - val_loss: 0.1510 - val_mae: 0.3153 - val_msle: 0.0218\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1270 - mae: 0.2612 - msle: 0.0153 - val_loss: 0.1449 - val_mae: 0.3069 - val_msle: 0.0219\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1167 - mae: 0.2589 - msle: 0.0144 - val_loss: 0.1433 - val_mae: 0.3059 - val_msle: 0.0230\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1136 - mae: 0.2630 - msle: 0.0132 - val_loss: 0.1387 - val_mae: 0.3000 - val_msle: 0.0208\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1116 - mae: 0.2557 - msle: 0.0149 - val_loss: 0.1443 - val_mae: 0.3090 - val_msle: 0.0217\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1238 - mae: 0.2685 - msle: 0.0174 - val_loss: 0.1434 - val_mae: 0.3096 - val_msle: 0.0224\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1001 - mae: 0.2453 - msle: 0.0112 - val_loss: 0.1434 - val_mae: 0.3054 - val_msle: 0.0202\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1150 - mae: 0.2554 - msle: 0.0152 - val_loss: 0.1409 - val_mae: 0.3044 - val_msle: 0.0229\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1258 - mae: 0.2650 - msle: 0.0164 - val_loss: 0.1436 - val_mae: 0.3011 - val_msle: 0.0194\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1162 - mae: 0.2576 - msle: 0.0143 - val_loss: 0.1398 - val_mae: 0.3012 - val_msle: 0.0225\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1125 - mae: 0.2446 - msle: 0.0120 - val_loss: 0.1453 - val_mae: 0.3035 - val_msle: 0.0208\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1088 - mae: 0.2554 - msle: 0.0138 - val_loss: 0.1378 - val_mae: 0.2976 - val_msle: 0.0219\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1032 - mae: 0.2451 - msle: 0.0138 - val_loss: 0.1358 - val_mae: 0.2931 - val_msle: 0.0201\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1086 - mae: 0.2564 - msle: 0.0135 - val_loss: 0.1381 - val_mae: 0.2976 - val_msle: 0.0210\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1152 - mae: 0.2578 - msle: 0.0147 - val_loss: 0.1445 - val_mae: 0.3061 - val_msle: 0.0245\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1100 - mae: 0.2519 - msle: 0.0131 - val_loss: 0.1399 - val_mae: 0.2981 - val_msle: 0.0233\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1096 - mae: 0.2564 - msle: 0.0148 - val_loss: 0.1425 - val_mae: 0.2979 - val_msle: 0.0247\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1079 - mae: 0.2490 - msle: 0.0148 - val_loss: 0.1450 - val_mae: 0.3078 - val_msle: 0.0238\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1099 - mae: 0.2508 - msle: 0.0150 - val_loss: 0.1431 - val_mae: 0.3005 - val_msle: 0.0201\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1074 - mae: 0.2506 - msle: 0.0141 - val_loss: 0.1438 - val_mae: 0.3045 - val_msle: 0.0228\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1108 - mae: 0.2530 - msle: 0.0125 - val_loss: 0.1384 - val_mae: 0.2987 - val_msle: 0.0236\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0999 - mae: 0.2405 - msle: 0.0131 - val_loss: 0.1385 - val_mae: 0.2972 - val_msle: 0.0228\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1026 - mae: 0.2429 - msle: 0.0130 - val_loss: 0.1452 - val_mae: 0.3057 - val_msle: 0.0238\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1011 - mae: 0.2412 - msle: 0.0127 - val_loss: 0.1381 - val_mae: 0.2960 - val_msle: 0.0206\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0998 - mae: 0.2444 - msle: 0.0139 - val_loss: 0.1429 - val_mae: 0.3033 - val_msle: 0.0242\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0895 - mae: 0.2313 - msle: 0.0115 - val_loss: 0.1454 - val_mae: 0.2997 - val_msle: 0.0208\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1053 - mae: 0.2486 - msle: 0.0135 - val_loss: 0.1439 - val_mae: 0.3061 - val_msle: 0.0227\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1035 - mae: 0.2413 - msle: 0.0139 - val_loss: 0.1308 - val_mae: 0.2865 - val_msle: 0.0201\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1002 - mae: 0.2296 - msle: 0.0125 - val_loss: 0.1356 - val_mae: 0.2925 - val_msle: 0.0188\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0929 - mae: 0.2337 - msle: 0.0129 - val_loss: 0.1359 - val_mae: 0.2931 - val_msle: 0.0227\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1052 - mae: 0.2436 - msle: 0.0138 - val_loss: 0.1449 - val_mae: 0.3031 - val_msle: 0.0214\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.1038 - mae: 0.2464 - msle: 0.0135 - val_loss: 0.1360 - val_mae: 0.2929 - val_msle: 0.0220\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0950 - mae: 0.2381 - msle: 0.0123 - val_loss: 0.1395 - val_mae: 0.2976 - val_msle: 0.0226\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0930 - mae: 0.2323 - msle: 0.0108 - val_loss: 0.1614 - val_mae: 0.3170 - val_msle: 0.0247\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1127 - mae: 0.2524 - msle: 0.0141 - val_loss: 0.1383 - val_mae: 0.2960 - val_msle: 0.0216\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1009 - mae: 0.2466 - msle: 0.0135 - val_loss: 0.1387 - val_mae: 0.2944 - val_msle: 0.0208\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0917 - mae: 0.2331 - msle: 0.0113 - val_loss: 0.1501 - val_mae: 0.3107 - val_msle: 0.0240\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1155 - mae: 0.2524 - msle: 0.0136 - val_loss: 0.1455 - val_mae: 0.3037 - val_msle: 0.0262\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0837 - mae: 0.2262 - msle: 0.0119 - val_loss: 0.1492 - val_mae: 0.3092 - val_msle: 0.0222\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0907 - mae: 0.2309 - msle: 0.0126 - val_loss: 0.1386 - val_mae: 0.2990 - val_msle: 0.0223\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0859 - mae: 0.2184 - msle: 0.0108 - val_loss: 0.1491 - val_mae: 0.3040 - val_msle: 0.0218\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0934 - mae: 0.2312 - msle: 0.0109 - val_loss: 0.1476 - val_mae: 0.3080 - val_msle: 0.0250\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0960 - mae: 0.2385 - msle: 0.0122 - val_loss: 0.1500 - val_mae: 0.3086 - val_msle: 0.0246\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0929 - mae: 0.2238 - msle: 0.0108 - val_loss: 0.1460 - val_mae: 0.3038 - val_msle: 0.0240\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0843 - mae: 0.2240 - msle: 0.0115 - val_loss: 0.1448 - val_mae: 0.3048 - val_msle: 0.0245\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0978 - mae: 0.2373 - msle: 0.0138 - val_loss: 0.1375 - val_mae: 0.2973 - val_msle: 0.0226\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0934 - mae: 0.2360 - msle: 0.0123 - val_loss: 0.1454 - val_mae: 0.3050 - val_msle: 0.0229\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0875 - mae: 0.2258 - msle: 0.0097 - val_loss: 0.1395 - val_mae: 0.2983 - val_msle: 0.0222\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0842 - mae: 0.2204 - msle: 0.0105 - val_loss: 0.1588 - val_mae: 0.3191 - val_msle: 0.0256\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0932 - mae: 0.2247 - msle: 0.0109 - val_loss: 0.1410 - val_mae: 0.3019 - val_msle: 0.0245\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0812 - mae: 0.2209 - msle: 0.0119 - val_loss: 0.1436 - val_mae: 0.2984 - val_msle: 0.0242\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0825 - mae: 0.2234 - msle: 0.0096 - val_loss: 0.1385 - val_mae: 0.2973 - val_msle: 0.0222\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0934 - mae: 0.2342 - msle: 0.0103 - val_loss: 0.1328 - val_mae: 0.2869 - val_msle: 0.0195\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0885 - mae: 0.2223 - msle: 0.0111 - val_loss: 0.1470 - val_mae: 0.3062 - val_msle: 0.0275\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0874 - mae: 0.2291 - msle: 0.0126 - val_loss: 0.1483 - val_mae: 0.3051 - val_msle: 0.0274\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0842 - mae: 0.2290 - msle: 0.0113 - val_loss: 0.1424 - val_mae: 0.2999 - val_msle: 0.0257\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0891 - mae: 0.2332 - msle: 0.0120 - val_loss: 0.1289 - val_mae: 0.2809 - val_msle: 0.0200\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0867 - mae: 0.2222 - msle: 0.0130 - val_loss: 0.1485 - val_mae: 0.3083 - val_msle: 0.0268\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0874 - mae: 0.2258 - msle: 0.0114 - val_loss: 0.1408 - val_mae: 0.2924 - val_msle: 0.0217\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0886 - mae: 0.2230 - msle: 0.0100 - val_loss: 0.1432 - val_mae: 0.3006 - val_msle: 0.0264\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0879 - mae: 0.2277 - msle: 0.0113 - val_loss: 0.1493 - val_mae: 0.3073 - val_msle: 0.0269\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0807 - mae: 0.2151 - msle: 0.0114 - val_loss: 0.1572 - val_mae: 0.3153 - val_msle: 0.0260\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0828 - mae: 0.2187 - msle: 0.0099 - val_loss: 0.1455 - val_mae: 0.2997 - val_msle: 0.0251\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0893 - mae: 0.2306 - msle: 0.0104 - val_loss: 0.1505 - val_mae: 0.3058 - val_msle: 0.0299\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0802 - mae: 0.2196 - msle: 0.0095 - val_loss: 0.1524 - val_mae: 0.3104 - val_msle: 0.0261\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0745 - mae: 0.2086 - msle: 0.0084 - val_loss: 0.1491 - val_mae: 0.3046 - val_msle: 0.0255\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0804 - mae: 0.2162 - msle: 0.0099 - val_loss: 0.1447 - val_mae: 0.3042 - val_msle: 0.0257\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0835 - mae: 0.2189 - msle: 0.0099 - val_loss: 0.1408 - val_mae: 0.2992 - val_msle: 0.0244\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0737 - mae: 0.2131 - msle: 0.0095 - val_loss: 0.1555 - val_mae: 0.3106 - val_msle: 0.0268\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0910 - mae: 0.2348 - msle: 0.0129 - val_loss: 0.1488 - val_mae: 0.3115 - val_msle: 0.0248\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0878 - mae: 0.2219 - msle: 0.0105 - val_loss: 0.1409 - val_mae: 0.2947 - val_msle: 0.0203\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0796 - mae: 0.2189 - msle: 0.0111 - val_loss: 0.1398 - val_mae: 0.3012 - val_msle: 0.0233\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.2027 - msle: 0.0085 - val_loss: 0.1500 - val_mae: 0.3100 - val_msle: 0.0232\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0869 - mae: 0.2214 - msle: 0.0097 - val_loss: 0.1434 - val_mae: 0.2999 - val_msle: 0.0251\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0756 - mae: 0.2161 - msle: 0.0105 - val_loss: 0.1519 - val_mae: 0.3117 - val_msle: 0.0293\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0725 - mae: 0.2044 - msle: 0.0098 - val_loss: 0.1447 - val_mae: 0.3009 - val_msle: 0.0253\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0822 - mae: 0.2145 - msle: 0.0100 - val_loss: 0.1483 - val_mae: 0.3099 - val_msle: 0.0265\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0692 - mae: 0.2046 - msle: 0.0088 - val_loss: 0.1474 - val_mae: 0.3104 - val_msle: 0.0269\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0863 - mae: 0.2269 - msle: 0.0100 - val_loss: 0.1525 - val_mae: 0.3087 - val_msle: 0.0236\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0878 - mae: 0.2228 - msle: 0.0088 - val_loss: 0.1471 - val_mae: 0.3112 - val_msle: 0.0275\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0837 - mae: 0.2174 - msle: 0.0104 - val_loss: 0.1392 - val_mae: 0.2956 - val_msle: 0.0225\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0751 - mae: 0.2105 - msle: 0.0093 - val_loss: 0.1472 - val_mae: 0.3064 - val_msle: 0.0247\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0784 - mae: 0.2059 - msle: 0.0093 - val_loss: 0.1377 - val_mae: 0.3008 - val_msle: 0.0212\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0779 - mae: 0.2108 - msle: 0.0099 - val_loss: 0.1396 - val_mae: 0.2993 - val_msle: 0.0222\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0753 - mae: 0.2057 - msle: 0.0098 - val_loss: 0.1427 - val_mae: 0.3008 - val_msle: 0.0204\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0825 - mae: 0.2197 - msle: 0.0102 - val_loss: 0.1441 - val_mae: 0.3073 - val_msle: 0.0241\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0885 - mae: 0.2213 - msle: 0.0109 - val_loss: 0.1522 - val_mae: 0.3131 - val_msle: 0.0248\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0746 - mae: 0.2100 - msle: 0.0102 - val_loss: 0.1518 - val_mae: 0.3139 - val_msle: 0.0248\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0791 - mae: 0.2138 - msle: 0.0097 - val_loss: 0.1448 - val_mae: 0.3034 - val_msle: 0.0221\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0834 - mae: 0.2202 - msle: 0.0102 - val_loss: 0.1421 - val_mae: 0.3034 - val_msle: 0.0237\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0746 - mae: 0.2055 - msle: 0.0094 - val_loss: 0.1407 - val_mae: 0.2966 - val_msle: 0.0217\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0708 - mae: 0.2060 - msle: 0.0090 - val_loss: 0.1453 - val_mae: 0.3073 - val_msle: 0.0238\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0803 - mae: 0.2051 - msle: 0.0092 - val_loss: 0.1444 - val_mae: 0.3056 - val_msle: 0.0234\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0712 - mae: 0.2029 - msle: 0.0096 - val_loss: 0.1457 - val_mae: 0.3059 - val_msle: 0.0241\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0837 - mae: 0.2190 - msle: 0.0106 - val_loss: 0.1373 - val_mae: 0.2967 - val_msle: 0.0202\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0590 - mae: 0.1875 - msle: 0.0080 - val_loss: 0.1449 - val_mae: 0.3069 - val_msle: 0.0230\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0700 - mae: 0.2014 - msle: 0.0087 - val_loss: 0.1478 - val_mae: 0.3073 - val_msle: 0.0248\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0693 - mae: 0.1996 - msle: 0.0087 - val_loss: 0.1470 - val_mae: 0.3069 - val_msle: 0.0249\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0690 - mae: 0.2008 - msle: 0.0088 - val_loss: 0.1568 - val_mae: 0.3212 - val_msle: 0.0267\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0800 - mae: 0.2195 - msle: 0.0102 - val_loss: 0.1446 - val_mae: 0.3049 - val_msle: 0.0230\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0695 - mae: 0.1992 - msle: 0.0087 - val_loss: 0.1493 - val_mae: 0.3091 - val_msle: 0.0237\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0683 - mae: 0.1978 - msle: 0.0087 - val_loss: 0.1455 - val_mae: 0.3045 - val_msle: 0.0250\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0663 - mae: 0.1950 - msle: 0.0072 - val_loss: 0.1490 - val_mae: 0.3092 - val_msle: 0.0247\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0772 - mae: 0.2132 - msle: 0.0105 - val_loss: 0.1653 - val_mae: 0.3226 - val_msle: 0.0265\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0749 - mae: 0.2060 - msle: 0.0100 - val_loss: 0.1477 - val_mae: 0.3088 - val_msle: 0.0243\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0774 - mae: 0.2112 - msle: 0.0093 - val_loss: 0.1442 - val_mae: 0.3007 - val_msle: 0.0223\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0665 - mae: 0.1983 - msle: 0.0082 - val_loss: 0.1565 - val_mae: 0.3149 - val_msle: 0.0263\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0675 - mae: 0.2012 - msle: 0.0090 - val_loss: 0.1458 - val_mae: 0.2983 - val_msle: 0.0205\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0753 - mae: 0.2075 - msle: 0.0089 - val_loss: 0.1420 - val_mae: 0.3007 - val_msle: 0.0231\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0708 - mae: 0.2044 - msle: 0.0091 - val_loss: 0.1510 - val_mae: 0.3109 - val_msle: 0.0260\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0699 - mae: 0.2021 - msle: 0.0085 - val_loss: 0.1384 - val_mae: 0.2962 - val_msle: 0.0212\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0691 - mae: 0.1989 - msle: 0.0090 - val_loss: 0.1438 - val_mae: 0.3024 - val_msle: 0.0224\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0702 - mae: 0.1987 - msle: 0.0095 - val_loss: 0.1382 - val_mae: 0.2953 - val_msle: 0.0215\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0816 - mae: 0.2062 - msle: 0.0103 - val_loss: 0.1411 - val_mae: 0.2976 - val_msle: 0.0236\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0711 - mae: 0.1983 - msle: 0.0084 - val_loss: 0.1403 - val_mae: 0.2999 - val_msle: 0.0214\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0642 - mae: 0.1954 - msle: 0.0083 - val_loss: 0.1345 - val_mae: 0.2952 - val_msle: 0.0210\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0813 - mae: 0.2034 - msle: 0.0091 - val_loss: 0.1460 - val_mae: 0.3058 - val_msle: 0.0236\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0667 - mae: 0.1959 - msle: 0.0095 - val_loss: 0.1364 - val_mae: 0.2946 - val_msle: 0.0205\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0710 - mae: 0.2056 - msle: 0.0096 - val_loss: 0.1388 - val_mae: 0.2979 - val_msle: 0.0216\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0676 - mae: 0.2026 - msle: 0.0084 - val_loss: 0.1421 - val_mae: 0.3016 - val_msle: 0.0216\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0687 - mae: 0.1996 - msle: 0.0081 - val_loss: 0.1347 - val_mae: 0.2888 - val_msle: 0.0209\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0798 - mae: 0.2116 - msle: 0.0097 - val_loss: 0.1417 - val_mae: 0.3007 - val_msle: 0.0211\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0743 - mae: 0.2110 - msle: 0.0107 - val_loss: 0.1473 - val_mae: 0.3060 - val_msle: 0.0219\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0761 - mae: 0.2030 - msle: 0.0088 - val_loss: 0.1419 - val_mae: 0.3008 - val_msle: 0.0214\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0604 - mae: 0.1893 - msle: 0.0075 - val_loss: 0.1387 - val_mae: 0.2972 - val_msle: 0.0219\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0659 - mae: 0.1968 - msle: 0.0088 - val_loss: 0.1419 - val_mae: 0.3007 - val_msle: 0.0213\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0655 - mae: 0.1973 - msle: 0.0082 - val_loss: 0.1340 - val_mae: 0.2932 - val_msle: 0.0201\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0644 - mae: 0.1910 - msle: 0.0081 - val_loss: 0.1483 - val_mae: 0.3116 - val_msle: 0.0236\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0715 - mae: 0.1970 - msle: 0.0076 - val_loss: 0.1424 - val_mae: 0.3017 - val_msle: 0.0224\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0663 - mae: 0.1918 - msle: 0.0070 - val_loss: 0.1466 - val_mae: 0.3065 - val_msle: 0.0222\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0672 - mae: 0.1988 - msle: 0.0095 - val_loss: 0.1408 - val_mae: 0.3009 - val_msle: 0.0237\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0631 - mae: 0.1948 - msle: 0.0083 - val_loss: 0.1490 - val_mae: 0.3112 - val_msle: 0.0268\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0708 - mae: 0.1966 - msle: 0.0094 - val_loss: 0.1492 - val_mae: 0.3068 - val_msle: 0.0241\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0810 - mae: 0.2108 - msle: 0.0105 - val_loss: 0.1636 - val_mae: 0.3216 - val_msle: 0.0335\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0686 - mae: 0.1974 - msle: 0.0091 - val_loss: 0.1491 - val_mae: 0.3063 - val_msle: 0.0249\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0763 - mae: 0.2009 - msle: 0.0092 - val_loss: 0.1496 - val_mae: 0.3057 - val_msle: 0.0248\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0663 - mae: 0.1964 - msle: 0.0081 - val_loss: 0.1605 - val_mae: 0.3210 - val_msle: 0.0260\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0619 - mae: 0.1883 - msle: 0.0083 - val_loss: 0.1570 - val_mae: 0.3160 - val_msle: 0.0231\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0664 - mae: 0.1969 - msle: 0.0088 - val_loss: 0.1531 - val_mae: 0.3107 - val_msle: 0.0264\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0661 - mae: 0.1955 - msle: 0.0073 - val_loss: 0.1471 - val_mae: 0.3020 - val_msle: 0.0253\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0681 - mae: 0.1928 - msle: 0.0090 - val_loss: 0.1511 - val_mae: 0.3096 - val_msle: 0.0269\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0644 - mae: 0.1947 - msle: 0.0082 - val_loss: 0.1498 - val_mae: 0.3113 - val_msle: 0.0252\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0702 - mae: 0.2002 - msle: 0.0096 - val_loss: 0.1452 - val_mae: 0.3047 - val_msle: 0.0246\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0745 - mae: 0.2004 - msle: 0.0089 - val_loss: 0.1469 - val_mae: 0.3048 - val_msle: 0.0233\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0636 - mae: 0.1880 - msle: 0.0073 - val_loss: 0.1435 - val_mae: 0.3042 - val_msle: 0.0233\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0602 - mae: 0.1822 - msle: 0.0078 - val_loss: 0.1505 - val_mae: 0.3131 - val_msle: 0.0258\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0662 - mae: 0.1980 - msle: 0.0091 - val_loss: 0.1628 - val_mae: 0.3234 - val_msle: 0.0258\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0703 - mae: 0.2007 - msle: 0.0096 - val_loss: 0.1432 - val_mae: 0.3003 - val_msle: 0.0221\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0616 - mae: 0.1906 - msle: 0.0075 - val_loss: 0.1401 - val_mae: 0.2964 - val_msle: 0.0221\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.2011 - msle: 0.0077 - val_loss: 0.1401 - val_mae: 0.2983 - val_msle: 0.0226\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0664 - mae: 0.1937 - msle: 0.0091 - val_loss: 0.1445 - val_mae: 0.3043 - val_msle: 0.0236\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0624 - mae: 0.1891 - msle: 0.0082 - val_loss: 0.1500 - val_mae: 0.3108 - val_msle: 0.0251\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0578 - mae: 0.1855 - msle: 0.0073 - val_loss: 0.1516 - val_mae: 0.3139 - val_msle: 0.0253\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0644 - mae: 0.1895 - msle: 0.0075 - val_loss: 0.1480 - val_mae: 0.3068 - val_msle: 0.0240\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0574 - mae: 0.1825 - msle: 0.0066 - val_loss: 0.1555 - val_mae: 0.3133 - val_msle: 0.0266\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0588 - mae: 0.1851 - msle: 0.0072 - val_loss: 0.1515 - val_mae: 0.3114 - val_msle: 0.0261\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0579 - mae: 0.1895 - msle: 0.0074 - val_loss: 0.1553 - val_mae: 0.3159 - val_msle: 0.0271\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0743 - mae: 0.1988 - msle: 0.0091 - val_loss: 0.1481 - val_mae: 0.3071 - val_msle: 0.0249\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0692 - mae: 0.1980 - msle: 0.0070 - val_loss: 0.1536 - val_mae: 0.3168 - val_msle: 0.0239\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0575 - mae: 0.1839 - msle: 0.0069 - val_loss: 0.1593 - val_mae: 0.3203 - val_msle: 0.0256\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0600 - mae: 0.1857 - msle: 0.0064 - val_loss: 0.1526 - val_mae: 0.3105 - val_msle: 0.0255\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0799 - mae: 0.2057 - msle: 0.0086 - val_loss: 0.1479 - val_mae: 0.3056 - val_msle: 0.0246\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0604 - mae: 0.1849 - msle: 0.0086 - val_loss: 0.1561 - val_mae: 0.3160 - val_msle: 0.0231\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0647 - mae: 0.1887 - msle: 0.0085 - val_loss: 0.1538 - val_mae: 0.3108 - val_msle: 0.0267\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0697 - mae: 0.1944 - msle: 0.0084 - val_loss: 0.1546 - val_mae: 0.3127 - val_msle: 0.0270\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0609 - mae: 0.1853 - msle: 0.0080 - val_loss: 0.1489 - val_mae: 0.3043 - val_msle: 0.0237\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0594 - mae: 0.1796 - msle: 0.0063 - val_loss: 0.1442 - val_mae: 0.3054 - val_msle: 0.0238\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0572 - mae: 0.1847 - msle: 0.0076 - val_loss: 0.1471 - val_mae: 0.3042 - val_msle: 0.0237\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0613 - mae: 0.1814 - msle: 0.0073 - val_loss: 0.1440 - val_mae: 0.3001 - val_msle: 0.0246\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0552 - mae: 0.1840 - msle: 0.0073 - val_loss: 0.1545 - val_mae: 0.3157 - val_msle: 0.0280\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0581 - mae: 0.1858 - msle: 0.0079 - val_loss: 0.1503 - val_mae: 0.3071 - val_msle: 0.0259\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0637 - mae: 0.1931 - msle: 0.0082 - val_loss: 0.1636 - val_mae: 0.3221 - val_msle: 0.0268\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0552 - mae: 0.1825 - msle: 0.0069 - val_loss: 0.1473 - val_mae: 0.3060 - val_msle: 0.0240\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0567 - mae: 0.1786 - msle: 0.0067 - val_loss: 0.1472 - val_mae: 0.3033 - val_msle: 0.0245\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0638 - mae: 0.1975 - msle: 0.0081 - val_loss: 0.1537 - val_mae: 0.3135 - val_msle: 0.0281\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0565 - mae: 0.1742 - msle: 0.0067 - val_loss: 0.1584 - val_mae: 0.3121 - val_msle: 0.0271\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0569 - mae: 0.1855 - msle: 0.0068 - val_loss: 0.1584 - val_mae: 0.3213 - val_msle: 0.0262\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0618 - mae: 0.1875 - msle: 0.0073 - val_loss: 0.1478 - val_mae: 0.3026 - val_msle: 0.0248\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.1906 - msle: 0.0092 - val_loss: 0.1536 - val_mae: 0.3124 - val_msle: 0.0292\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0607 - mae: 0.1827 - msle: 0.0068 - val_loss: 0.1536 - val_mae: 0.3129 - val_msle: 0.0275\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0541 - mae: 0.1748 - msle: 0.0060 - val_loss: 0.1545 - val_mae: 0.3150 - val_msle: 0.0290\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0572 - mae: 0.1827 - msle: 0.0067 - val_loss: 0.1479 - val_mae: 0.3055 - val_msle: 0.0266\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0502 - mae: 0.1766 - msle: 0.0067 - val_loss: 0.1485 - val_mae: 0.3087 - val_msle: 0.0257\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0715 - mae: 0.1949 - msle: 0.0091 - val_loss: 0.1442 - val_mae: 0.3062 - val_msle: 0.0224\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0577 - mae: 0.1817 - msle: 0.0070 - val_loss: 0.1435 - val_mae: 0.3051 - val_msle: 0.0227\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0601 - mae: 0.1869 - msle: 0.0082 - val_loss: 0.1561 - val_mae: 0.3166 - val_msle: 0.0270\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0645 - mae: 0.1881 - msle: 0.0092 - val_loss: 0.1468 - val_mae: 0.3030 - val_msle: 0.0210\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0566 - mae: 0.1850 - msle: 0.0064 - val_loss: 0.1551 - val_mae: 0.3143 - val_msle: 0.0252\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0583 - mae: 0.1850 - msle: 0.0074 - val_loss: 0.1468 - val_mae: 0.3074 - val_msle: 0.0230\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0582 - mae: 0.1837 - msle: 0.0070 - val_loss: 0.1573 - val_mae: 0.3200 - val_msle: 0.0260\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0610 - mae: 0.1893 - msle: 0.0080 - val_loss: 0.1483 - val_mae: 0.3050 - val_msle: 0.0235\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0631 - mae: 0.1835 - msle: 0.0074 - val_loss: 0.1472 - val_mae: 0.3091 - val_msle: 0.0235\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0529 - mae: 0.1766 - msle: 0.0070 - val_loss: 0.1440 - val_mae: 0.3078 - val_msle: 0.0222\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0561 - mae: 0.1788 - msle: 0.0061 - val_loss: 0.1490 - val_mae: 0.3097 - val_msle: 0.0247\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0568 - mae: 0.1814 - msle: 0.0057 - val_loss: 0.1532 - val_mae: 0.3157 - val_msle: 0.0251\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0578 - mae: 0.1817 - msle: 0.0073 - val_loss: 0.1523 - val_mae: 0.3119 - val_msle: 0.0251\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0572 - mae: 0.1801 - msle: 0.0075 - val_loss: 0.1530 - val_mae: 0.3136 - val_msle: 0.0251\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0586 - mae: 0.1867 - msle: 0.0076 - val_loss: 0.1516 - val_mae: 0.3093 - val_msle: 0.0274\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0543 - mae: 0.1838 - msle: 0.0066 - val_loss: 0.1526 - val_mae: 0.3105 - val_msle: 0.0280\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0624 - mae: 0.1879 - msle: 0.0075 - val_loss: 0.1510 - val_mae: 0.3098 - val_msle: 0.0244\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0549 - mae: 0.1782 - msle: 0.0068 - val_loss: 0.1506 - val_mae: 0.3101 - val_msle: 0.0262\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0623 - mae: 0.1845 - msle: 0.0077 - val_loss: 0.1562 - val_mae: 0.3151 - val_msle: 0.0257\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0600 - mae: 0.1857 - msle: 0.0071 - val_loss: 0.1480 - val_mae: 0.3022 - val_msle: 0.0224\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0621 - mae: 0.1826 - msle: 0.0091 - val_loss: 0.1475 - val_mae: 0.3048 - val_msle: 0.0223\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0651 - mae: 0.1787 - msle: 0.0062 - val_loss: 0.1449 - val_mae: 0.3032 - val_msle: 0.0237\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0563 - mae: 0.1767 - msle: 0.0070 - val_loss: 0.1545 - val_mae: 0.3160 - val_msle: 0.0259\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0598 - mae: 0.1847 - msle: 0.0081 - val_loss: 0.1556 - val_mae: 0.3155 - val_msle: 0.0249\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0569 - mae: 0.1812 - msle: 0.0079 - val_loss: 0.1536 - val_mae: 0.3120 - val_msle: 0.0252\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0674 - mae: 0.1959 - msle: 0.0083 - val_loss: 0.1591 - val_mae: 0.3174 - val_msle: 0.0270\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0546 - mae: 0.1717 - msle: 0.0062 - val_loss: 0.1599 - val_mae: 0.3185 - val_msle: 0.0291\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0561 - mae: 0.1860 - msle: 0.0072 - val_loss: 0.1598 - val_mae: 0.3188 - val_msle: 0.0283\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0551 - mae: 0.1780 - msle: 0.0066 - val_loss: 0.1509 - val_mae: 0.3058 - val_msle: 0.0256\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0630 - mae: 0.1899 - msle: 0.0075 - val_loss: 0.1465 - val_mae: 0.3043 - val_msle: 0.0242\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0511 - mae: 0.1756 - msle: 0.0061 - val_loss: 0.1478 - val_mae: 0.3067 - val_msle: 0.0258\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0535 - mae: 0.1753 - msle: 0.0057 - val_loss: 0.1536 - val_mae: 0.3103 - val_msle: 0.0267\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0495 - mae: 0.1719 - msle: 0.0062 - val_loss: 0.1454 - val_mae: 0.2963 - val_msle: 0.0235\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0523 - mae: 0.1714 - msle: 0.0066 - val_loss: 0.1520 - val_mae: 0.3057 - val_msle: 0.0259\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0550 - mae: 0.1739 - msle: 0.0075 - val_loss: 0.1480 - val_mae: 0.2999 - val_msle: 0.0223\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0528 - mae: 0.1761 - msle: 0.0069 - val_loss: 0.1504 - val_mae: 0.3020 - val_msle: 0.0248\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0578 - mae: 0.1872 - msle: 0.0065 - val_loss: 0.1538 - val_mae: 0.3091 - val_msle: 0.0253\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0569 - mae: 0.1763 - msle: 0.0064 - val_loss: 0.1491 - val_mae: 0.3021 - val_msle: 0.0238\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0514 - mae: 0.1703 - msle: 0.0063 - val_loss: 0.1574 - val_mae: 0.3125 - val_msle: 0.0273\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0540 - mae: 0.1841 - msle: 0.0072 - val_loss: 0.1523 - val_mae: 0.3075 - val_msle: 0.0252\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0550 - mae: 0.1761 - msle: 0.0068 - val_loss: 0.1499 - val_mae: 0.3046 - val_msle: 0.0248\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0561 - mae: 0.1791 - msle: 0.0072 - val_loss: 0.1541 - val_mae: 0.3095 - val_msle: 0.0240\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0555 - mae: 0.1752 - msle: 0.0066 - val_loss: 0.1551 - val_mae: 0.3105 - val_msle: 0.0261\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0473 - mae: 0.1613 - msle: 0.0062 - val_loss: 0.1551 - val_mae: 0.3098 - val_msle: 0.0258\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0582 - mae: 0.1813 - msle: 0.0068 - val_loss: 0.1484 - val_mae: 0.3029 - val_msle: 0.0252\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0647 - mae: 0.1839 - msle: 0.0082 - val_loss: 0.1430 - val_mae: 0.2980 - val_msle: 0.0229\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0500 - mae: 0.1695 - msle: 0.0066 - val_loss: 0.1394 - val_mae: 0.2935 - val_msle: 0.0218\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0583 - mae: 0.1766 - msle: 0.0075 - val_loss: 0.1474 - val_mae: 0.3028 - val_msle: 0.0238\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0550 - mae: 0.1803 - msle: 0.0062 - val_loss: 0.1449 - val_mae: 0.2992 - val_msle: 0.0229\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0593 - mae: 0.1872 - msle: 0.0070 - val_loss: 0.1465 - val_mae: 0.3014 - val_msle: 0.0227\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0514 - mae: 0.1705 - msle: 0.0073 - val_loss: 0.1397 - val_mae: 0.2920 - val_msle: 0.0207\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0580 - mae: 0.1816 - msle: 0.0066 - val_loss: 0.1458 - val_mae: 0.3005 - val_msle: 0.0226\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0507 - mae: 0.1692 - msle: 0.0065 - val_loss: 0.1492 - val_mae: 0.3052 - val_msle: 0.0250\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0556 - mae: 0.1784 - msle: 0.0068 - val_loss: 0.1484 - val_mae: 0.3041 - val_msle: 0.0233\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0590 - mae: 0.1826 - msle: 0.0067 - val_loss: 0.1611 - val_mae: 0.3181 - val_msle: 0.0272\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0531 - mae: 0.1676 - msle: 0.0069 - val_loss: 0.1510 - val_mae: 0.3103 - val_msle: 0.0256\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0533 - mae: 0.1746 - msle: 0.0065 - val_loss: 0.1484 - val_mae: 0.3048 - val_msle: 0.0234\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0543 - mae: 0.1711 - msle: 0.0064 - val_loss: 0.1535 - val_mae: 0.3130 - val_msle: 0.0252\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0593 - mae: 0.1847 - msle: 0.0072 - val_loss: 0.1528 - val_mae: 0.3108 - val_msle: 0.0255\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0514 - mae: 0.1711 - msle: 0.0060 - val_loss: 0.1572 - val_mae: 0.3160 - val_msle: 0.0267\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0549 - mae: 0.1773 - msle: 0.0078 - val_loss: 0.1482 - val_mae: 0.3038 - val_msle: 0.0232\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0492 - mae: 0.1701 - msle: 0.0054 - val_loss: 0.1535 - val_mae: 0.3132 - val_msle: 0.0233\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0531 - mae: 0.1742 - msle: 0.0071 - val_loss: 0.1535 - val_mae: 0.3136 - val_msle: 0.0244\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0557 - mae: 0.1787 - msle: 0.0066 - val_loss: 0.1436 - val_mae: 0.3002 - val_msle: 0.0223\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0503 - mae: 0.1663 - msle: 0.0064 - val_loss: 0.1482 - val_mae: 0.3059 - val_msle: 0.0228\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0515 - mae: 0.1754 - msle: 0.0058 - val_loss: 0.1444 - val_mae: 0.2997 - val_msle: 0.0212\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0532 - mae: 0.1739 - msle: 0.0078 - val_loss: 0.1552 - val_mae: 0.3116 - val_msle: 0.0255\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0535 - mae: 0.1775 - msle: 0.0063 - val_loss: 0.1489 - val_mae: 0.3035 - val_msle: 0.0237\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0472 - mae: 0.1656 - msle: 0.0057 - val_loss: 0.1530 - val_mae: 0.3098 - val_msle: 0.0269\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0584 - mae: 0.1782 - msle: 0.0066 - val_loss: 0.1472 - val_mae: 0.3003 - val_msle: 0.0225\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0486 - mae: 0.1647 - msle: 0.0064 - val_loss: 0.1561 - val_mae: 0.3102 - val_msle: 0.0243\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0527 - mae: 0.1777 - msle: 0.0069 - val_loss: 0.1526 - val_mae: 0.3041 - val_msle: 0.0244\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0581 - mae: 0.1811 - msle: 0.0067 - val_loss: 0.1651 - val_mae: 0.3210 - val_msle: 0.0297\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0612 - mae: 0.1837 - msle: 0.0073 - val_loss: 0.1573 - val_mae: 0.3158 - val_msle: 0.0264\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0600 - mae: 0.1814 - msle: 0.0071 - val_loss: 0.1570 - val_mae: 0.3102 - val_msle: 0.0261\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0575 - mae: 0.1771 - msle: 0.0068 - val_loss: 0.1530 - val_mae: 0.3038 - val_msle: 0.0250\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0528 - mae: 0.1756 - msle: 0.0071 - val_loss: 0.1560 - val_mae: 0.3111 - val_msle: 0.0261\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0554 - mae: 0.1726 - msle: 0.0062 - val_loss: 0.1659 - val_mae: 0.3244 - val_msle: 0.0282\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0473 - mae: 0.1615 - msle: 0.0052 - val_loss: 0.1529 - val_mae: 0.3059 - val_msle: 0.0230\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0502 - mae: 0.1694 - msle: 0.0075 - val_loss: 0.1519 - val_mae: 0.3090 - val_msle: 0.0217\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0539 - mae: 0.1729 - msle: 0.0065 - val_loss: 0.1521 - val_mae: 0.3130 - val_msle: 0.0239\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0522 - mae: 0.1736 - msle: 0.0070 - val_loss: 0.1468 - val_mae: 0.3000 - val_msle: 0.0234\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0480 - mae: 0.1681 - msle: 0.0062 - val_loss: 0.1546 - val_mae: 0.3109 - val_msle: 0.0249\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0529 - mae: 0.1790 - msle: 0.0068 - val_loss: 0.1513 - val_mae: 0.3051 - val_msle: 0.0227\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0520 - mae: 0.1779 - msle: 0.0068 - val_loss: 0.1501 - val_mae: 0.3064 - val_msle: 0.0210\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0594 - mae: 0.1764 - msle: 0.0062 - val_loss: 0.1567 - val_mae: 0.3116 - val_msle: 0.0216\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0555 - mae: 0.1842 - msle: 0.0069 - val_loss: 0.1651 - val_mae: 0.3180 - val_msle: 0.0257\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0550 - mae: 0.1789 - msle: 0.0066 - val_loss: 0.1509 - val_mae: 0.3031 - val_msle: 0.0217\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0512 - mae: 0.1715 - msle: 0.0060 - val_loss: 0.1541 - val_mae: 0.3067 - val_msle: 0.0228\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0493 - mae: 0.1702 - msle: 0.0064 - val_loss: 0.1503 - val_mae: 0.3000 - val_msle: 0.0227\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0505 - mae: 0.1702 - msle: 0.0064 - val_loss: 0.1573 - val_mae: 0.3092 - val_msle: 0.0271\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0505 - mae: 0.1683 - msle: 0.0066 - val_loss: 0.1588 - val_mae: 0.3067 - val_msle: 0.0261\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0475 - mae: 0.1654 - msle: 0.0053 - val_loss: 0.1605 - val_mae: 0.3120 - val_msle: 0.0280\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0527 - mae: 0.1744 - msle: 0.0069 - val_loss: 0.1600 - val_mae: 0.3122 - val_msle: 0.0254\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0516 - mae: 0.1718 - msle: 0.0054 - val_loss: 0.1594 - val_mae: 0.3111 - val_msle: 0.0235\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0515 - mae: 0.1675 - msle: 0.0051 - val_loss: 0.1539 - val_mae: 0.3098 - val_msle: 0.0236\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0537 - mae: 0.1773 - msle: 0.0069 - val_loss: 0.1540 - val_mae: 0.3091 - val_msle: 0.0223\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0549 - mae: 0.1719 - msle: 0.0059 - val_loss: 0.1583 - val_mae: 0.3109 - val_msle: 0.0225\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0526 - mae: 0.1767 - msle: 0.0070 - val_loss: 0.1590 - val_mae: 0.3164 - val_msle: 0.0264\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0477 - mae: 0.1632 - msle: 0.0063 - val_loss: 0.1714 - val_mae: 0.3273 - val_msle: 0.0263\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0502 - mae: 0.1705 - msle: 0.0064 - val_loss: 0.1569 - val_mae: 0.3111 - val_msle: 0.0260\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0469 - mae: 0.1639 - msle: 0.0068 - val_loss: 0.1625 - val_mae: 0.3181 - val_msle: 0.0285\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0496 - mae: 0.1659 - msle: 0.0062 - val_loss: 0.1593 - val_mae: 0.3136 - val_msle: 0.0267\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0488 - mae: 0.1654 - msle: 0.0059 - val_loss: 0.1557 - val_mae: 0.3095 - val_msle: 0.0254\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0462 - mae: 0.1615 - msle: 0.0054 - val_loss: 0.1622 - val_mae: 0.3171 - val_msle: 0.0281\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0573 - mae: 0.1749 - msle: 0.0066 - val_loss: 0.1465 - val_mae: 0.2964 - val_msle: 0.0226\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0482 - mae: 0.1663 - msle: 0.0057 - val_loss: 0.1607 - val_mae: 0.3142 - val_msle: 0.0281\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0496 - mae: 0.1679 - msle: 0.0057 - val_loss: 0.1447 - val_mae: 0.2936 - val_msle: 0.0207\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0537 - mae: 0.1767 - msle: 0.0071 - val_loss: 0.1533 - val_mae: 0.3071 - val_msle: 0.0209\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0631 - mae: 0.1848 - msle: 0.0074 - val_loss: 0.1564 - val_mae: 0.3132 - val_msle: 0.0241\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0492 - mae: 0.1695 - msle: 0.0056 - val_loss: 0.1552 - val_mae: 0.3125 - val_msle: 0.0243\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0493 - mae: 0.1671 - msle: 0.0061 - val_loss: 0.1481 - val_mae: 0.3009 - val_msle: 0.0230\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0432 - mae: 0.1620 - msle: 0.0054 - val_loss: 0.1532 - val_mae: 0.3074 - val_msle: 0.0240\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0473 - mae: 0.1666 - msle: 0.0054 - val_loss: 0.1533 - val_mae: 0.3064 - val_msle: 0.0249\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0487 - mae: 0.1652 - msle: 0.0056 - val_loss: 0.1510 - val_mae: 0.3040 - val_msle: 0.0234\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0509 - mae: 0.1673 - msle: 0.0064 - val_loss: 0.1533 - val_mae: 0.3060 - val_msle: 0.0233\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0495 - mae: 0.1672 - msle: 0.0063 - val_loss: 0.1490 - val_mae: 0.3032 - val_msle: 0.0224\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0423 - mae: 0.1606 - msle: 0.0051 - val_loss: 0.1509 - val_mae: 0.3077 - val_msle: 0.0216\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0475 - mae: 0.1610 - msle: 0.0046 - val_loss: 0.1420 - val_mae: 0.2980 - val_msle: 0.0206\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0519 - mae: 0.1680 - msle: 0.0065 - val_loss: 0.1606 - val_mae: 0.3203 - val_msle: 0.0258\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0534 - mae: 0.1736 - msle: 0.0073 - val_loss: 0.1453 - val_mae: 0.2941 - val_msle: 0.0224\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0480 - mae: 0.1703 - msle: 0.0068 - val_loss: 0.1455 - val_mae: 0.3005 - val_msle: 0.0223\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0502 - mae: 0.1693 - msle: 0.0063 - val_loss: 0.1448 - val_mae: 0.2991 - val_msle: 0.0235\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0455 - mae: 0.1634 - msle: 0.0055 - val_loss: 0.1483 - val_mae: 0.3026 - val_msle: 0.0233\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0562 - mae: 0.1711 - msle: 0.0059 - val_loss: 0.1441 - val_mae: 0.2918 - val_msle: 0.0214\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0535 - mae: 0.1709 - msle: 0.0061 - val_loss: 0.1500 - val_mae: 0.3046 - val_msle: 0.0237\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0495 - mae: 0.1674 - msle: 0.0059 - val_loss: 0.1625 - val_mae: 0.3113 - val_msle: 0.0273\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0578 - mae: 0.1790 - msle: 0.0076 - val_loss: 0.1702 - val_mae: 0.3247 - val_msle: 0.0299\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 0.1609 - msle: 0.0051 - val_loss: 0.1544 - val_mae: 0.3079 - val_msle: 0.0234\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0495 - mae: 0.1699 - msle: 0.0057 - val_loss: 0.1610 - val_mae: 0.3131 - val_msle: 0.0258\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0408 - mae: 0.1552 - msle: 0.0047 - val_loss: 0.1537 - val_mae: 0.3039 - val_msle: 0.0238\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0444 - mae: 0.1579 - msle: 0.0052 - val_loss: 0.1566 - val_mae: 0.3087 - val_msle: 0.0243\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0464 - mae: 0.1620 - msle: 0.0052 - val_loss: 0.1516 - val_mae: 0.3024 - val_msle: 0.0234\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0423 - mae: 0.1589 - msle: 0.0057 - val_loss: 0.1517 - val_mae: 0.3020 - val_msle: 0.0230\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0493 - mae: 0.1727 - msle: 0.0064 - val_loss: 0.1599 - val_mae: 0.3164 - val_msle: 0.0277\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0459 - mae: 0.1595 - msle: 0.0054 - val_loss: 0.1540 - val_mae: 0.3054 - val_msle: 0.0248\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0458 - mae: 0.1619 - msle: 0.0063 - val_loss: 0.1575 - val_mae: 0.3109 - val_msle: 0.0257\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0493 - mae: 0.1677 - msle: 0.0062 - val_loss: 0.1593 - val_mae: 0.3120 - val_msle: 0.0235\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0521 - mae: 0.1738 - msle: 0.0068 - val_loss: 0.1563 - val_mae: 0.3119 - val_msle: 0.0232\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0442 - mae: 0.1623 - msle: 0.0050 - val_loss: 0.1561 - val_mae: 0.3124 - val_msle: 0.0235\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0434 - mae: 0.1575 - msle: 0.0049 - val_loss: 0.1491 - val_mae: 0.3036 - val_msle: 0.0221\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0454 - mae: 0.1591 - msle: 0.0063 - val_loss: 0.1565 - val_mae: 0.3108 - val_msle: 0.0238\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0458 - mae: 0.1598 - msle: 0.0050 - val_loss: 0.1536 - val_mae: 0.3032 - val_msle: 0.0229\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0425 - mae: 0.1572 - msle: 0.0055 - val_loss: 0.1529 - val_mae: 0.3018 - val_msle: 0.0218\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0501 - mae: 0.1686 - msle: 0.0064 - val_loss: 0.1577 - val_mae: 0.3095 - val_msle: 0.0243\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0481 - mae: 0.1665 - msle: 0.0064 - val_loss: 0.1635 - val_mae: 0.3198 - val_msle: 0.0240\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0458 - mae: 0.1643 - msle: 0.0063 - val_loss: 0.1598 - val_mae: 0.3170 - val_msle: 0.0222\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0378 - mae: 0.1500 - msle: 0.0048 - val_loss: 0.1509 - val_mae: 0.3059 - val_msle: 0.0226\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0495 - mae: 0.1631 - msle: 0.0045 - val_loss: 0.1559 - val_mae: 0.3087 - val_msle: 0.0221\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0459 - mae: 0.1641 - msle: 0.0060 - val_loss: 0.1591 - val_mae: 0.3135 - val_msle: 0.0242\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0446 - mae: 0.1534 - msle: 0.0045 - val_loss: 0.1592 - val_mae: 0.3103 - val_msle: 0.0222\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0514 - mae: 0.1673 - msle: 0.0057 - val_loss: 0.1596 - val_mae: 0.3127 - val_msle: 0.0235\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0431 - mae: 0.1581 - msle: 0.0058 - val_loss: 0.1522 - val_mae: 0.3026 - val_msle: 0.0203\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0521 - mae: 0.1713 - msle: 0.0067 - val_loss: 0.1603 - val_mae: 0.3171 - val_msle: 0.0242\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0462 - mae: 0.1578 - msle: 0.0051 - val_loss: 0.1587 - val_mae: 0.3161 - val_msle: 0.0232\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0416 - mae: 0.1566 - msle: 0.0055 - val_loss: 0.1529 - val_mae: 0.3078 - val_msle: 0.0216\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0484 - mae: 0.1650 - msle: 0.0068 - val_loss: 0.1547 - val_mae: 0.3124 - val_msle: 0.0220\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0501 - mae: 0.1710 - msle: 0.0078 - val_loss: 0.1574 - val_mae: 0.3116 - val_msle: 0.0230\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0498 - mae: 0.1655 - msle: 0.0064 - val_loss: 0.1585 - val_mae: 0.3147 - val_msle: 0.0242\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0449 - mae: 0.1577 - msle: 0.0050 - val_loss: 0.1510 - val_mae: 0.3021 - val_msle: 0.0225\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0438 - mae: 0.1537 - msle: 0.0057 - val_loss: 0.1580 - val_mae: 0.3127 - val_msle: 0.0228\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0461 - mae: 0.1641 - msle: 0.0051 - val_loss: 0.1535 - val_mae: 0.3100 - val_msle: 0.0236\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0508 - mae: 0.1656 - msle: 0.0059 - val_loss: 0.1496 - val_mae: 0.3022 - val_msle: 0.0212\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0407 - mae: 0.1564 - msle: 0.0048 - val_loss: 0.1525 - val_mae: 0.3090 - val_msle: 0.0228\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0464 - mae: 0.1633 - msle: 0.0062 - val_loss: 0.1491 - val_mae: 0.3002 - val_msle: 0.0189\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0484 - mae: 0.1628 - msle: 0.0062 - val_loss: 0.1599 - val_mae: 0.3140 - val_msle: 0.0226\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0535 - mae: 0.1673 - msle: 0.0061 - val_loss: 0.1528 - val_mae: 0.3056 - val_msle: 0.0231\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 0.1591 - msle: 0.0060 - val_loss: 0.1572 - val_mae: 0.3123 - val_msle: 0.0246\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0475 - mae: 0.1701 - msle: 0.0065 - val_loss: 0.1535 - val_mae: 0.3026 - val_msle: 0.0196\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0490 - mae: 0.1682 - msle: 0.0066 - val_loss: 0.1570 - val_mae: 0.3002 - val_msle: 0.0197\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0446 - mae: 0.1601 - msle: 0.0056 - val_loss: 0.1625 - val_mae: 0.3114 - val_msle: 0.0207\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0472 - mae: 0.1626 - msle: 0.0059 - val_loss: 0.1494 - val_mae: 0.2981 - val_msle: 0.0200\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0437 - mae: 0.1636 - msle: 0.0062 - val_loss: 0.1499 - val_mae: 0.3077 - val_msle: 0.0218\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0466 - mae: 0.1675 - msle: 0.0060 - val_loss: 0.1524 - val_mae: 0.3087 - val_msle: 0.0196\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0438 - mae: 0.1562 - msle: 0.0052 - val_loss: 0.1603 - val_mae: 0.3162 - val_msle: 0.0242\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0402 - mae: 0.1523 - msle: 0.0057 - val_loss: 0.1534 - val_mae: 0.3087 - val_msle: 0.0222\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0441 - mae: 0.1583 - msle: 0.0052 - val_loss: 0.1544 - val_mae: 0.3060 - val_msle: 0.0238\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0443 - mae: 0.1603 - msle: 0.0060 - val_loss: 0.1520 - val_mae: 0.3036 - val_msle: 0.0220\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0515 - mae: 0.1679 - msle: 0.0065 - val_loss: 0.1519 - val_mae: 0.3038 - val_msle: 0.0228\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0468 - mae: 0.1617 - msle: 0.0062 - val_loss: 0.1745 - val_mae: 0.3261 - val_msle: 0.0250\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0449 - mae: 0.1628 - msle: 0.0055 - val_loss: 0.1524 - val_mae: 0.3068 - val_msle: 0.0227\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0448 - mae: 0.1598 - msle: 0.0051 - val_loss: 0.1546 - val_mae: 0.3109 - val_msle: 0.0239\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0504 - mae: 0.1724 - msle: 0.0063 - val_loss: 0.1571 - val_mae: 0.3122 - val_msle: 0.0241\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0438 - mae: 0.1586 - msle: 0.0054 - val_loss: 0.1523 - val_mae: 0.3052 - val_msle: 0.0234\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0513 - mae: 0.1664 - msle: 0.0070 - val_loss: 0.1502 - val_mae: 0.3038 - val_msle: 0.0230\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0368 - mae: 0.1493 - msle: 0.0047 - val_loss: 0.1510 - val_mae: 0.3050 - val_msle: 0.0227\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0429 - mae: 0.1621 - msle: 0.0062 - val_loss: 0.1510 - val_mae: 0.3058 - val_msle: 0.0231\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0425 - mae: 0.1590 - msle: 0.0051 - val_loss: 0.1503 - val_mae: 0.3019 - val_msle: 0.0221\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0412 - mae: 0.1532 - msle: 0.0050 - val_loss: 0.1572 - val_mae: 0.3148 - val_msle: 0.0251\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0462 - mae: 0.1628 - msle: 0.0059 - val_loss: 0.1493 - val_mae: 0.3034 - val_msle: 0.0228\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0387 - mae: 0.1509 - msle: 0.0052 - val_loss: 0.1468 - val_mae: 0.3011 - val_msle: 0.0210\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0399 - mae: 0.1481 - msle: 0.0045 - val_loss: 0.1515 - val_mae: 0.3014 - val_msle: 0.0223\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0408 - mae: 0.1543 - msle: 0.0053 - val_loss: 0.1605 - val_mae: 0.3153 - val_msle: 0.0244\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0495 - mae: 0.1653 - msle: 0.0067 - val_loss: 0.1499 - val_mae: 0.2929 - val_msle: 0.0221\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0451 - mae: 0.1622 - msle: 0.0051 - val_loss: 0.1519 - val_mae: 0.3066 - val_msle: 0.0238\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0441 - mae: 0.1615 - msle: 0.0054 - val_loss: 0.1449 - val_mae: 0.3005 - val_msle: 0.0217\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0447 - mae: 0.1608 - msle: 0.0054 - val_loss: 0.1429 - val_mae: 0.2922 - val_msle: 0.0225\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0437 - mae: 0.1638 - msle: 0.0053 - val_loss: 0.1537 - val_mae: 0.3080 - val_msle: 0.0236\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0396 - mae: 0.1489 - msle: 0.0055 - val_loss: 0.1506 - val_mae: 0.3084 - val_msle: 0.0238\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0455 - mae: 0.1534 - msle: 0.0061 - val_loss: 0.1540 - val_mae: 0.3115 - val_msle: 0.0245\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0491 - mae: 0.1652 - msle: 0.0054 - val_loss: 0.1550 - val_mae: 0.3112 - val_msle: 0.0238\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0486 - mae: 0.1642 - msle: 0.0061 - val_loss: 0.1485 - val_mae: 0.2997 - val_msle: 0.0221\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0469 - mae: 0.1646 - msle: 0.0053 - val_loss: 0.1560 - val_mae: 0.3090 - val_msle: 0.0217\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0379 - mae: 0.1493 - msle: 0.0050 - val_loss: 0.1549 - val_mae: 0.3095 - val_msle: 0.0232\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0388 - mae: 0.1507 - msle: 0.0047 - val_loss: 0.1541 - val_mae: 0.3059 - val_msle: 0.0226\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0453 - mae: 0.1614 - msle: 0.0059 - val_loss: 0.1485 - val_mae: 0.2996 - val_msle: 0.0200\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0437 - mae: 0.1624 - msle: 0.0061 - val_loss: 0.1504 - val_mae: 0.3074 - val_msle: 0.0211\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 0.1498 - msle: 0.0048 - val_loss: 0.1486 - val_mae: 0.3026 - val_msle: 0.0208\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0452 - mae: 0.1638 - msle: 0.0052 - val_loss: 0.1545 - val_mae: 0.3107 - val_msle: 0.0234\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0465 - mae: 0.1630 - msle: 0.0064 - val_loss: 0.1558 - val_mae: 0.3099 - val_msle: 0.0247\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0410 - mae: 0.1534 - msle: 0.0050 - val_loss: 0.1528 - val_mae: 0.3070 - val_msle: 0.0230\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0475 - mae: 0.1636 - msle: 0.0062 - val_loss: 0.1494 - val_mae: 0.3083 - val_msle: 0.0225\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0463 - mae: 0.1602 - msle: 0.0061 - val_loss: 0.1451 - val_mae: 0.3022 - val_msle: 0.0218\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0514 - mae: 0.1651 - msle: 0.0070 - val_loss: 0.1468 - val_mae: 0.3071 - val_msle: 0.0210\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0441 - mae: 0.1609 - msle: 0.0053 - val_loss: 0.1559 - val_mae: 0.3129 - val_msle: 0.0229\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0387 - mae: 0.1559 - msle: 0.0054 - val_loss: 0.1530 - val_mae: 0.3088 - val_msle: 0.0231\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0405 - mae: 0.1542 - msle: 0.0047 - val_loss: 0.1477 - val_mae: 0.3017 - val_msle: 0.0225\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0451 - mae: 0.1614 - msle: 0.0058 - val_loss: 0.1519 - val_mae: 0.3083 - val_msle: 0.0225\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0435 - mae: 0.1619 - msle: 0.0057 - val_loss: 0.1625 - val_mae: 0.3155 - val_msle: 0.0231\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0408 - mae: 0.1543 - msle: 0.0043 - val_loss: 0.1595 - val_mae: 0.3206 - val_msle: 0.0259\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0442 - mae: 0.1590 - msle: 0.0064 - val_loss: 0.1420 - val_mae: 0.2943 - val_msle: 0.0232\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0490 - mae: 0.1639 - msle: 0.0055 - val_loss: 0.1532 - val_mae: 0.3125 - val_msle: 0.0246\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0429 - mae: 0.1591 - msle: 0.0054 - val_loss: 0.1473 - val_mae: 0.3014 - val_msle: 0.0214\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0425 - mae: 0.1592 - msle: 0.0052 - val_loss: 0.1386 - val_mae: 0.2913 - val_msle: 0.0207\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0385 - mae: 0.1469 - msle: 0.0044 - val_loss: 0.1545 - val_mae: 0.3110 - val_msle: 0.0239\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0401 - mae: 0.1532 - msle: 0.0052 - val_loss: 0.1501 - val_mae: 0.3028 - val_msle: 0.0225\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0352 - mae: 0.1440 - msle: 0.0044 - val_loss: 0.1485 - val_mae: 0.3012 - val_msle: 0.0225\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0424 - mae: 0.1585 - msle: 0.0058 - val_loss: 0.1531 - val_mae: 0.3042 - val_msle: 0.0217\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0418 - mae: 0.1531 - msle: 0.0055 - val_loss: 0.1570 - val_mae: 0.3098 - val_msle: 0.0240\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0403 - mae: 0.1472 - msle: 0.0048 - val_loss: 0.1499 - val_mae: 0.2999 - val_msle: 0.0216\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0415 - mae: 0.1516 - msle: 0.0052 - val_loss: 0.1515 - val_mae: 0.3014 - val_msle: 0.0211\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0424 - mae: 0.1551 - msle: 0.0049 - val_loss: 0.1554 - val_mae: 0.2995 - val_msle: 0.0219\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0390 - mae: 0.1504 - msle: 0.0048 - val_loss: 0.1579 - val_mae: 0.3054 - val_msle: 0.0231\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0455 - mae: 0.1610 - msle: 0.0056 - val_loss: 0.1528 - val_mae: 0.3088 - val_msle: 0.0242\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0439 - mae: 0.1563 - msle: 0.0057 - val_loss: 0.1418 - val_mae: 0.2928 - val_msle: 0.0205\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0408 - mae: 0.1556 - msle: 0.0050 - val_loss: 0.1506 - val_mae: 0.3050 - val_msle: 0.0221\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0428 - mae: 0.1550 - msle: 0.0050 - val_loss: 0.1487 - val_mae: 0.2966 - val_msle: 0.0230\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0378 - mae: 0.1507 - msle: 0.0053 - val_loss: 0.1473 - val_mae: 0.2990 - val_msle: 0.0233\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0436 - mae: 0.1564 - msle: 0.0058 - val_loss: 0.1438 - val_mae: 0.2920 - val_msle: 0.0204\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0453 - mae: 0.1560 - msle: 0.0054 - val_loss: 0.1557 - val_mae: 0.3112 - val_msle: 0.0227\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0444 - mae: 0.1585 - msle: 0.0051 - val_loss: 0.1478 - val_mae: 0.2983 - val_msle: 0.0206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4ca313940>"
      ]
     },
     "execution_count": 1008,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize and fit sequential model\n",
    "sequential_model_pca = create_sequential_model(df=X_train_pca)\n",
    "sequential_model_pca.fit(x=X_train_pca,\n",
    "    y=y_train_pca,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test_pca, y_test_pca),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "id": "c8c14cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict out values\n",
    "y_pred_seq_pca = sequential_model_pca.predict(X_test_pca)\n",
    "\n",
    "# reverse scaling\n",
    "y_pred_seq_pca = np.round(target_scaler.inverse_transform(np.array(y_pred_seq_pca)))\n",
    "y_test_pca = np.round(target_scaler.inverse_transform(np.array(y_test_pca)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "c2282bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.,  5., 10., 17., 12., 17., 11.,  9.,  7., 11.,  3.,  9.,  4.,\n",
       "         0.,  2.,  2.,  0.,  2.,  1.,  1.]),\n",
       " array([ 3.  ,  5.35,  7.7 , 10.05, 12.4 , 14.75, 17.1 , 19.45, 21.8 ,\n",
       "        24.15, 26.5 , 28.85, 31.2 , 33.55, 35.9 , 38.25, 40.6 , 42.95,\n",
       "        45.3 , 47.65, 50.  ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 1010,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(y_test_pca), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "id": "ae1c5a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15.,  9., 12., 17., 15.,  9., 12.,  9., 10.,  3.,  3.,  1.,  4.,\n",
       "         2.,  1.,  2.,  1.,  1.,  1.,  1.]),\n",
       " array([ 7.  ,  9.05, 11.1 , 13.15, 15.2 , 17.25, 19.3 , 21.35, 23.4 ,\n",
       "        25.45, 27.5 , 29.55, 31.6 , 33.65, 35.7 , 37.75, 39.8 , 41.85,\n",
       "        43.9 , 45.95, 48.  ], dtype=float32),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 1011,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_seq_pca, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "id": "e686fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "meld_predictions_pca = pd.concat([pd.DataFrame(data=np.array(X_test_pca), columns=X_pca.columns), pd.DataFrame(data=np.array(y_pred_seq_pca), columns=[\"MELD_Prediction_PCA\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "0017824f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.029850746268656716, 0.3125, 0.7, 0.75]"
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_accuracy_pca = meld_acc(meld_predictions_pca, meld_column=\"MELD_Prediction_PCA\")\n",
    "prediction_accuracy_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "id": "a129fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap_scaler = umap.UMAP(n_neighbors=10, min_dist=0.1, random_state=7)\n",
    "# embedding = umap_scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = final_df_normalized.copy(deep=True)\n",
    "X = X.drop([\"MELD\", \"MELD3\", \"MELDNA\"], axis=1)\n",
    "non_binary_cols_umap = [col for col in X.columns if len(X[col].unique()) > 2]\n",
    "binary_cols_umap = [col for col in X.columns if len(X[col].unique()) <= 2]\n",
    "X_non_binary_umap = pd.DataFrame(scaler.fit_transform(X[non_binary_cols_umap]), columns=non_binary_cols_umap)\n",
    "X_non_binary_umap = pd.DataFrame(umap_scaler.fit_transform(X_non_binary_umap))\n",
    "X_umap = pd.concat([X[binary_cols_umap], X_non_binary_umap], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "id": "98b9b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_umap, X_test_umap, y_train_umap, y_test_umap = train_test_split(X_umap, y, test_size=0.2, random_state=7)\n",
    "X_train_umap = tf.convert_to_tensor(X_train_umap)\n",
    "X_test_umap = tf.convert_to_tensor(X_test_umap)\n",
    "y_train_umap = tf.convert_to_tensor(y_train_umap)\n",
    "y_test_umap = tf.convert_to_tensor(y_test_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "f9cbd2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 0.9985 - mae: 0.7710 - msle: 0.1660 - val_loss: 1.1738 - val_mae: 0.8458 - val_msle: 0.2393\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9462 - mae: 0.7553 - msle: 0.1641 - val_loss: 1.1151 - val_mae: 0.8195 - val_msle: 0.2254\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.9134 - mae: 0.7397 - msle: 0.1594 - val_loss: 1.0019 - val_mae: 0.7745 - val_msle: 0.1886\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8419 - mae: 0.7063 - msle: 0.1374 - val_loss: 0.6648 - val_mae: 0.6143 - val_msle: 0.0913\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7408 - mae: 0.6535 - msle: 0.1181 - val_loss: 0.5967 - val_mae: 0.5663 - val_msle: 0.0819\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7104 - mae: 0.6386 - msle: 0.1088 - val_loss: 0.5888 - val_mae: 0.5675 - val_msle: 0.0901\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6433 - mae: 0.6132 - msle: 0.1033 - val_loss: 0.5707 - val_mae: 0.5648 - val_msle: 0.0800\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6614 - mae: 0.6257 - msle: 0.1053 - val_loss: 0.5621 - val_mae: 0.5673 - val_msle: 0.0795\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6053 - mae: 0.6068 - msle: 0.0927 - val_loss: 0.5720 - val_mae: 0.5628 - val_msle: 0.0869\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6456 - mae: 0.6015 - msle: 0.1039 - val_loss: 0.5487 - val_mae: 0.5529 - val_msle: 0.0807\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6185 - mae: 0.6052 - msle: 0.0918 - val_loss: 0.5386 - val_mae: 0.5507 - val_msle: 0.0801\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5889 - mae: 0.5827 - msle: 0.0936 - val_loss: 0.5498 - val_mae: 0.5516 - val_msle: 0.0814\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5704 - mae: 0.5798 - msle: 0.0881 - val_loss: 0.5401 - val_mae: 0.5513 - val_msle: 0.0800\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5860 - mae: 0.5808 - msle: 0.0947 - val_loss: 0.5543 - val_mae: 0.5588 - val_msle: 0.0841\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5964 - mae: 0.5717 - msle: 0.0925 - val_loss: 0.5391 - val_mae: 0.5520 - val_msle: 0.0789\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5852 - mae: 0.5759 - msle: 0.0883 - val_loss: 0.5456 - val_mae: 0.5476 - val_msle: 0.0803\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5888 - mae: 0.5621 - msle: 0.0920 - val_loss: 0.5474 - val_mae: 0.5476 - val_msle: 0.0801\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5882 - mae: 0.5826 - msle: 0.0908 - val_loss: 0.5409 - val_mae: 0.5543 - val_msle: 0.0785\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5587 - mae: 0.5698 - msle: 0.0878 - val_loss: 0.5507 - val_mae: 0.5501 - val_msle: 0.0828\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5603 - mae: 0.5652 - msle: 0.0875 - val_loss: 0.5479 - val_mae: 0.5543 - val_msle: 0.0783\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5624 - mae: 0.5665 - msle: 0.0854 - val_loss: 0.5517 - val_mae: 0.5481 - val_msle: 0.0766\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4992 - mae: 0.5415 - msle: 0.0714 - val_loss: 0.5299 - val_mae: 0.5458 - val_msle: 0.0756\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5697 - mae: 0.5715 - msle: 0.0903 - val_loss: 0.5043 - val_mae: 0.5267 - val_msle: 0.0707\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5166 - mae: 0.5418 - msle: 0.0782 - val_loss: 0.5014 - val_mae: 0.5289 - val_msle: 0.0722\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5329 - mae: 0.5537 - msle: 0.0853 - val_loss: 0.5053 - val_mae: 0.5217 - val_msle: 0.0688\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5223 - mae: 0.5461 - msle: 0.0804 - val_loss: 0.4901 - val_mae: 0.5183 - val_msle: 0.0680\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4998 - mae: 0.5282 - msle: 0.0751 - val_loss: 0.4852 - val_mae: 0.5126 - val_msle: 0.0652\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5106 - mae: 0.5459 - msle: 0.0781 - val_loss: 0.4775 - val_mae: 0.5085 - val_msle: 0.0641\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5170 - mae: 0.5460 - msle: 0.0807 - val_loss: 0.4616 - val_mae: 0.5018 - val_msle: 0.0614\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4713 - mae: 0.5071 - msle: 0.0661 - val_loss: 0.4505 - val_mae: 0.5014 - val_msle: 0.0609\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4716 - mae: 0.5142 - msle: 0.0728 - val_loss: 0.4668 - val_mae: 0.5120 - val_msle: 0.0646\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4964 - mae: 0.5445 - msle: 0.0781 - val_loss: 0.4679 - val_mae: 0.5144 - val_msle: 0.0673\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5131 - mae: 0.5443 - msle: 0.0791 - val_loss: 0.4426 - val_mae: 0.5027 - val_msle: 0.0604\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4315 - mae: 0.4992 - msle: 0.0602 - val_loss: 0.4352 - val_mae: 0.4981 - val_msle: 0.0607\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4503 - mae: 0.5081 - msle: 0.0695 - val_loss: 0.4440 - val_mae: 0.5084 - val_msle: 0.0661\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4548 - mae: 0.5202 - msle: 0.0678 - val_loss: 0.5096 - val_mae: 0.5551 - val_msle: 0.0879\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4467 - mae: 0.5138 - msle: 0.0724 - val_loss: 0.4402 - val_mae: 0.5097 - val_msle: 0.0658\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4509 - mae: 0.5077 - msle: 0.0708 - val_loss: 0.4453 - val_mae: 0.5142 - val_msle: 0.0655\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4792 - mae: 0.5267 - msle: 0.0708 - val_loss: 0.4544 - val_mae: 0.5165 - val_msle: 0.0643\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3999 - mae: 0.4916 - msle: 0.0607 - val_loss: 0.4282 - val_mae: 0.5012 - val_msle: 0.0593\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4382 - mae: 0.5007 - msle: 0.0658 - val_loss: 0.4528 - val_mae: 0.5194 - val_msle: 0.0658\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4303 - mae: 0.5014 - msle: 0.0666 - val_loss: 0.4145 - val_mae: 0.5042 - val_msle: 0.0606\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4000 - mae: 0.4932 - msle: 0.0634 - val_loss: 0.4158 - val_mae: 0.4964 - val_msle: 0.0596\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4571 - mae: 0.5110 - msle: 0.0718 - val_loss: 0.4330 - val_mae: 0.4994 - val_msle: 0.0591\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4029 - mae: 0.4830 - msle: 0.0600 - val_loss: 0.4156 - val_mae: 0.4959 - val_msle: 0.0607\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3952 - mae: 0.4849 - msle: 0.0602 - val_loss: 0.4353 - val_mae: 0.5042 - val_msle: 0.0645\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4058 - mae: 0.4889 - msle: 0.0623 - val_loss: 0.4206 - val_mae: 0.5028 - val_msle: 0.0601\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3977 - mae: 0.4800 - msle: 0.0579 - val_loss: 0.4209 - val_mae: 0.5027 - val_msle: 0.0613\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4034 - mae: 0.4925 - msle: 0.0634 - val_loss: 0.4379 - val_mae: 0.5212 - val_msle: 0.0681\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4215 - mae: 0.5077 - msle: 0.0695 - val_loss: 0.4177 - val_mae: 0.5096 - val_msle: 0.0576\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4002 - mae: 0.4893 - msle: 0.0615 - val_loss: 0.4356 - val_mae: 0.5146 - val_msle: 0.0658\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3910 - mae: 0.4843 - msle: 0.0577 - val_loss: 0.4344 - val_mae: 0.5159 - val_msle: 0.0620\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3944 - mae: 0.4798 - msle: 0.0551 - val_loss: 0.4278 - val_mae: 0.5102 - val_msle: 0.0622\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3751 - mae: 0.4814 - msle: 0.0547 - val_loss: 0.4347 - val_mae: 0.5209 - val_msle: 0.0637\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3791 - mae: 0.4779 - msle: 0.0527 - val_loss: 0.4183 - val_mae: 0.5161 - val_msle: 0.0595\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4073 - mae: 0.4909 - msle: 0.0620 - val_loss: 0.4271 - val_mae: 0.5149 - val_msle: 0.0592\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3761 - mae: 0.4706 - msle: 0.0553 - val_loss: 0.4398 - val_mae: 0.5243 - val_msle: 0.0659\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3879 - mae: 0.4880 - msle: 0.0543 - val_loss: 0.4359 - val_mae: 0.5237 - val_msle: 0.0653\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4142 - mae: 0.4958 - msle: 0.0625 - val_loss: 0.4254 - val_mae: 0.5096 - val_msle: 0.0609\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3703 - mae: 0.4759 - msle: 0.0550 - val_loss: 0.4305 - val_mae: 0.5088 - val_msle: 0.0617\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3688 - mae: 0.4662 - msle: 0.0520 - val_loss: 0.4334 - val_mae: 0.5200 - val_msle: 0.0609\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3784 - mae: 0.4767 - msle: 0.0574 - val_loss: 0.4490 - val_mae: 0.5241 - val_msle: 0.0663\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3860 - mae: 0.4740 - msle: 0.0607 - val_loss: 0.4345 - val_mae: 0.5180 - val_msle: 0.0593\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3833 - mae: 0.4877 - msle: 0.0528 - val_loss: 0.4342 - val_mae: 0.5154 - val_msle: 0.0622\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3696 - mae: 0.4732 - msle: 0.0560 - val_loss: 0.4191 - val_mae: 0.5114 - val_msle: 0.0589\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3623 - mae: 0.4580 - msle: 0.0538 - val_loss: 0.4446 - val_mae: 0.5293 - val_msle: 0.0664\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3581 - mae: 0.4593 - msle: 0.0520 - val_loss: 0.4027 - val_mae: 0.5034 - val_msle: 0.0561\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3645 - mae: 0.4662 - msle: 0.0526 - val_loss: 0.4612 - val_mae: 0.5335 - val_msle: 0.0695\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3821 - mae: 0.4752 - msle: 0.0594 - val_loss: 0.4342 - val_mae: 0.5181 - val_msle: 0.0600\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3597 - mae: 0.4666 - msle: 0.0528 - val_loss: 0.4268 - val_mae: 0.5099 - val_msle: 0.0595\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3482 - mae: 0.4606 - msle: 0.0525 - val_loss: 0.4183 - val_mae: 0.5062 - val_msle: 0.0618\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3596 - mae: 0.4642 - msle: 0.0542 - val_loss: 0.4480 - val_mae: 0.5334 - val_msle: 0.0684\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3500 - mae: 0.4579 - msle: 0.0523 - val_loss: 0.4344 - val_mae: 0.5146 - val_msle: 0.0648\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3763 - mae: 0.4732 - msle: 0.0582 - val_loss: 0.4657 - val_mae: 0.5425 - val_msle: 0.0679\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3642 - mae: 0.4706 - msle: 0.0502 - val_loss: 0.4104 - val_mae: 0.5058 - val_msle: 0.0604\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3503 - mae: 0.4621 - msle: 0.0535 - val_loss: 0.4445 - val_mae: 0.5211 - val_msle: 0.0649\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3879 - mae: 0.4824 - msle: 0.0550 - val_loss: 0.4364 - val_mae: 0.5106 - val_msle: 0.0621\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3499 - mae: 0.4595 - msle: 0.0525 - val_loss: 0.4082 - val_mae: 0.5046 - val_msle: 0.0569\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3599 - mae: 0.4666 - msle: 0.0520 - val_loss: 0.4819 - val_mae: 0.5398 - val_msle: 0.0744\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3397 - mae: 0.4499 - msle: 0.0498 - val_loss: 0.4277 - val_mae: 0.5153 - val_msle: 0.0619\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3319 - mae: 0.4467 - msle: 0.0466 - val_loss: 0.4509 - val_mae: 0.5274 - val_msle: 0.0671\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3502 - mae: 0.4576 - msle: 0.0515 - val_loss: 0.4371 - val_mae: 0.5204 - val_msle: 0.0646\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3616 - mae: 0.4650 - msle: 0.0516 - val_loss: 0.4500 - val_mae: 0.5215 - val_msle: 0.0685\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3620 - mae: 0.4557 - msle: 0.0515 - val_loss: 0.4435 - val_mae: 0.5244 - val_msle: 0.0637\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3427 - mae: 0.4454 - msle: 0.0493 - val_loss: 0.4330 - val_mae: 0.5207 - val_msle: 0.0615\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3471 - mae: 0.4574 - msle: 0.0512 - val_loss: 0.4881 - val_mae: 0.5497 - val_msle: 0.0743\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3277 - mae: 0.4404 - msle: 0.0508 - val_loss: 0.4401 - val_mae: 0.5194 - val_msle: 0.0630\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3423 - mae: 0.4539 - msle: 0.0529 - val_loss: 0.4624 - val_mae: 0.5350 - val_msle: 0.0683\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3404 - mae: 0.4638 - msle: 0.0507 - val_loss: 0.4470 - val_mae: 0.5280 - val_msle: 0.0638\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3551 - mae: 0.4600 - msle: 0.0526 - val_loss: 0.4535 - val_mae: 0.5357 - val_msle: 0.0673\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3343 - mae: 0.4443 - msle: 0.0504 - val_loss: 0.4412 - val_mae: 0.5262 - val_msle: 0.0660\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3182 - mae: 0.4367 - msle: 0.0491 - val_loss: 0.4543 - val_mae: 0.5262 - val_msle: 0.0706\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3397 - mae: 0.4493 - msle: 0.0475 - val_loss: 0.4311 - val_mae: 0.5205 - val_msle: 0.0633\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3355 - mae: 0.4433 - msle: 0.0452 - val_loss: 0.4602 - val_mae: 0.5362 - val_msle: 0.0701\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3434 - mae: 0.4465 - msle: 0.0503 - val_loss: 0.4641 - val_mae: 0.5453 - val_msle: 0.0693\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3720 - mae: 0.4673 - msle: 0.0566 - val_loss: 0.4473 - val_mae: 0.5250 - val_msle: 0.0644\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3259 - mae: 0.4374 - msle: 0.0478 - val_loss: 0.4528 - val_mae: 0.5268 - val_msle: 0.0635\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3365 - mae: 0.4526 - msle: 0.0470 - val_loss: 0.4512 - val_mae: 0.5303 - val_msle: 0.0668\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3228 - mae: 0.4459 - msle: 0.0478 - val_loss: 0.4745 - val_mae: 0.5498 - val_msle: 0.0681\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3307 - mae: 0.4399 - msle: 0.0493 - val_loss: 0.4326 - val_mae: 0.5199 - val_msle: 0.0612\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3403 - mae: 0.4432 - msle: 0.0524 - val_loss: 0.4834 - val_mae: 0.5503 - val_msle: 0.0737\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3427 - mae: 0.4453 - msle: 0.0498 - val_loss: 0.4638 - val_mae: 0.5344 - val_msle: 0.0672\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3342 - mae: 0.4410 - msle: 0.0496 - val_loss: 0.4558 - val_mae: 0.5273 - val_msle: 0.0655\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3060 - mae: 0.4279 - msle: 0.0440 - val_loss: 0.4784 - val_mae: 0.5436 - val_msle: 0.0668\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3276 - mae: 0.4443 - msle: 0.0469 - val_loss: 0.4651 - val_mae: 0.5308 - val_msle: 0.0668\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3272 - mae: 0.4436 - msle: 0.0466 - val_loss: 0.4814 - val_mae: 0.5398 - val_msle: 0.0695\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3369 - mae: 0.4456 - msle: 0.0472 - val_loss: 0.4530 - val_mae: 0.5303 - val_msle: 0.0644\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3229 - mae: 0.4411 - msle: 0.0475 - val_loss: 0.4327 - val_mae: 0.5044 - val_msle: 0.0625\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3193 - mae: 0.4308 - msle: 0.0474 - val_loss: 0.4487 - val_mae: 0.5293 - val_msle: 0.0644\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3020 - mae: 0.4321 - msle: 0.0449 - val_loss: 0.4473 - val_mae: 0.5345 - val_msle: 0.0632\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3311 - mae: 0.4450 - msle: 0.0471 - val_loss: 0.4741 - val_mae: 0.5396 - val_msle: 0.0708\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3256 - mae: 0.4371 - msle: 0.0472 - val_loss: 0.4662 - val_mae: 0.5437 - val_msle: 0.0670\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3003 - mae: 0.4186 - msle: 0.0436 - val_loss: 0.4527 - val_mae: 0.5258 - val_msle: 0.0650\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3081 - mae: 0.4366 - msle: 0.0451 - val_loss: 0.4475 - val_mae: 0.5185 - val_msle: 0.0650\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3083 - mae: 0.4293 - msle: 0.0435 - val_loss: 0.4573 - val_mae: 0.5353 - val_msle: 0.0647\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3157 - mae: 0.4389 - msle: 0.0469 - val_loss: 0.4529 - val_mae: 0.5265 - val_msle: 0.0653\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3149 - mae: 0.4344 - msle: 0.0444 - val_loss: 0.4514 - val_mae: 0.5244 - val_msle: 0.0654\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3085 - mae: 0.4272 - msle: 0.0448 - val_loss: 0.4560 - val_mae: 0.5312 - val_msle: 0.0657\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3086 - mae: 0.4246 - msle: 0.0450 - val_loss: 0.4510 - val_mae: 0.5256 - val_msle: 0.0649\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3085 - mae: 0.4319 - msle: 0.0440 - val_loss: 0.4881 - val_mae: 0.5497 - val_msle: 0.0727\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3091 - mae: 0.4245 - msle: 0.0439 - val_loss: 0.4559 - val_mae: 0.5249 - val_msle: 0.0670\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3245 - mae: 0.4369 - msle: 0.0460 - val_loss: 0.4433 - val_mae: 0.5308 - val_msle: 0.0643\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3207 - mae: 0.4299 - msle: 0.0470 - val_loss: 0.4386 - val_mae: 0.5250 - val_msle: 0.0629\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3104 - mae: 0.4302 - msle: 0.0451 - val_loss: 0.4923 - val_mae: 0.5514 - val_msle: 0.0722\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3017 - mae: 0.4284 - msle: 0.0417 - val_loss: 0.4513 - val_mae: 0.5211 - val_msle: 0.0653\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3114 - mae: 0.4317 - msle: 0.0462 - val_loss: 0.4584 - val_mae: 0.5341 - val_msle: 0.0658\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3117 - mae: 0.4249 - msle: 0.0467 - val_loss: 0.4673 - val_mae: 0.5382 - val_msle: 0.0692\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3013 - mae: 0.4173 - msle: 0.0443 - val_loss: 0.4629 - val_mae: 0.5377 - val_msle: 0.0700\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3291 - mae: 0.4391 - msle: 0.0473 - val_loss: 0.4450 - val_mae: 0.5224 - val_msle: 0.0660\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3019 - mae: 0.4221 - msle: 0.0430 - val_loss: 0.4548 - val_mae: 0.5439 - val_msle: 0.0647\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3040 - mae: 0.4192 - msle: 0.0435 - val_loss: 0.4411 - val_mae: 0.5274 - val_msle: 0.0655\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2998 - mae: 0.4189 - msle: 0.0458 - val_loss: 0.4587 - val_mae: 0.5331 - val_msle: 0.0685\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3083 - mae: 0.4280 - msle: 0.0433 - val_loss: 0.4449 - val_mae: 0.5257 - val_msle: 0.0665\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3020 - mae: 0.4238 - msle: 0.0425 - val_loss: 0.4536 - val_mae: 0.5235 - val_msle: 0.0664\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3108 - mae: 0.4275 - msle: 0.0450 - val_loss: 0.4654 - val_mae: 0.5307 - val_msle: 0.0684\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2970 - mae: 0.4120 - msle: 0.0423 - val_loss: 0.4431 - val_mae: 0.5277 - val_msle: 0.0644\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2750 - mae: 0.4063 - msle: 0.0425 - val_loss: 0.4738 - val_mae: 0.5465 - val_msle: 0.0715\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3008 - mae: 0.4264 - msle: 0.0440 - val_loss: 0.4641 - val_mae: 0.5332 - val_msle: 0.0687\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3008 - mae: 0.4200 - msle: 0.0412 - val_loss: 0.4693 - val_mae: 0.5333 - val_msle: 0.0683\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3008 - mae: 0.4221 - msle: 0.0461 - val_loss: 0.5086 - val_mae: 0.5537 - val_msle: 0.0772\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3011 - mae: 0.4187 - msle: 0.0454 - val_loss: 0.4799 - val_mae: 0.5397 - val_msle: 0.0698\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2846 - mae: 0.4083 - msle: 0.0419 - val_loss: 0.4444 - val_mae: 0.5237 - val_msle: 0.0651\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2850 - mae: 0.4075 - msle: 0.0387 - val_loss: 0.4704 - val_mae: 0.5310 - val_msle: 0.0695\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2875 - mae: 0.4058 - msle: 0.0411 - val_loss: 0.4793 - val_mae: 0.5440 - val_msle: 0.0716\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3009 - mae: 0.4215 - msle: 0.0452 - val_loss: 0.4642 - val_mae: 0.5387 - val_msle: 0.0681\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3051 - mae: 0.4289 - msle: 0.0442 - val_loss: 0.4667 - val_mae: 0.5350 - val_msle: 0.0696\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3063 - mae: 0.4362 - msle: 0.0463 - val_loss: 0.4922 - val_mae: 0.5555 - val_msle: 0.0747\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2788 - mae: 0.4135 - msle: 0.0405 - val_loss: 0.4943 - val_mae: 0.5542 - val_msle: 0.0749\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2992 - mae: 0.4127 - msle: 0.0446 - val_loss: 0.4748 - val_mae: 0.5539 - val_msle: 0.0714\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3126 - mae: 0.4251 - msle: 0.0448 - val_loss: 0.4351 - val_mae: 0.5204 - val_msle: 0.0646\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3004 - mae: 0.4268 - msle: 0.0445 - val_loss: 0.4827 - val_mae: 0.5490 - val_msle: 0.0716\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2895 - mae: 0.4160 - msle: 0.0390 - val_loss: 0.4702 - val_mae: 0.5405 - val_msle: 0.0709\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2872 - mae: 0.4229 - msle: 0.0399 - val_loss: 0.4544 - val_mae: 0.5297 - val_msle: 0.0679\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2942 - mae: 0.4166 - msle: 0.0428 - val_loss: 0.4684 - val_mae: 0.5415 - val_msle: 0.0707\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3116 - mae: 0.4269 - msle: 0.0471 - val_loss: 0.4608 - val_mae: 0.5389 - val_msle: 0.0692\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2833 - mae: 0.4120 - msle: 0.0422 - val_loss: 0.4863 - val_mae: 0.5569 - val_msle: 0.0731\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2876 - mae: 0.4176 - msle: 0.0412 - val_loss: 0.4569 - val_mae: 0.5416 - val_msle: 0.0681\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2803 - mae: 0.4114 - msle: 0.0396 - val_loss: 0.4513 - val_mae: 0.5366 - val_msle: 0.0658\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2832 - mae: 0.4127 - msle: 0.0409 - val_loss: 0.4997 - val_mae: 0.5618 - val_msle: 0.0756\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2932 - mae: 0.4171 - msle: 0.0435 - val_loss: 0.4837 - val_mae: 0.5454 - val_msle: 0.0717\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2958 - mae: 0.4104 - msle: 0.0421 - val_loss: 0.4657 - val_mae: 0.5396 - val_msle: 0.0698\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2992 - mae: 0.4280 - msle: 0.0423 - val_loss: 0.4705 - val_mae: 0.5366 - val_msle: 0.0715\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2761 - mae: 0.4085 - msle: 0.0408 - val_loss: 0.4470 - val_mae: 0.5373 - val_msle: 0.0667\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2932 - mae: 0.4155 - msle: 0.0408 - val_loss: 0.4405 - val_mae: 0.5248 - val_msle: 0.0663\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2876 - mae: 0.4057 - msle: 0.0413 - val_loss: 0.4624 - val_mae: 0.5356 - val_msle: 0.0690\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2825 - mae: 0.4101 - msle: 0.0409 - val_loss: 0.4413 - val_mae: 0.5168 - val_msle: 0.0640\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2941 - mae: 0.4046 - msle: 0.0410 - val_loss: 0.4525 - val_mae: 0.5354 - val_msle: 0.0652\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2973 - mae: 0.4196 - msle: 0.0439 - val_loss: 0.4584 - val_mae: 0.5388 - val_msle: 0.0669\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2890 - mae: 0.4203 - msle: 0.0415 - val_loss: 0.4594 - val_mae: 0.5319 - val_msle: 0.0689\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2852 - mae: 0.4109 - msle: 0.0423 - val_loss: 0.4497 - val_mae: 0.5315 - val_msle: 0.0675\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2866 - mae: 0.4138 - msle: 0.0432 - val_loss: 0.4637 - val_mae: 0.5401 - val_msle: 0.0715\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2873 - mae: 0.4095 - msle: 0.0430 - val_loss: 0.4722 - val_mae: 0.5405 - val_msle: 0.0732\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2743 - mae: 0.4071 - msle: 0.0360 - val_loss: 0.4660 - val_mae: 0.5411 - val_msle: 0.0709\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3082 - mae: 0.4288 - msle: 0.0430 - val_loss: 0.4397 - val_mae: 0.5189 - val_msle: 0.0660\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2797 - mae: 0.4090 - msle: 0.0411 - val_loss: 0.4428 - val_mae: 0.5228 - val_msle: 0.0655\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2784 - mae: 0.4114 - msle: 0.0428 - val_loss: 0.4599 - val_mae: 0.5371 - val_msle: 0.0699\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2821 - mae: 0.4112 - msle: 0.0418 - val_loss: 0.4702 - val_mae: 0.5403 - val_msle: 0.0714\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2919 - mae: 0.4204 - msle: 0.0423 - val_loss: 0.4837 - val_mae: 0.5386 - val_msle: 0.0732\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2988 - mae: 0.4204 - msle: 0.0428 - val_loss: 0.4769 - val_mae: 0.5409 - val_msle: 0.0703\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2921 - mae: 0.4165 - msle: 0.0397 - val_loss: 0.4634 - val_mae: 0.5366 - val_msle: 0.0670\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2814 - mae: 0.4054 - msle: 0.0393 - val_loss: 0.4426 - val_mae: 0.5220 - val_msle: 0.0638\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2809 - mae: 0.4065 - msle: 0.0396 - val_loss: 0.4778 - val_mae: 0.5436 - val_msle: 0.0707\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2713 - mae: 0.3986 - msle: 0.0377 - val_loss: 0.4636 - val_mae: 0.5321 - val_msle: 0.0657\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2866 - mae: 0.4097 - msle: 0.0398 - val_loss: 0.4595 - val_mae: 0.5310 - val_msle: 0.0653\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2893 - mae: 0.4179 - msle: 0.0421 - val_loss: 0.4711 - val_mae: 0.5356 - val_msle: 0.0682\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3065 - mae: 0.4259 - msle: 0.0454 - val_loss: 0.4647 - val_mae: 0.5337 - val_msle: 0.0687\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2886 - mae: 0.4178 - msle: 0.0422 - val_loss: 0.4527 - val_mae: 0.5227 - val_msle: 0.0653\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2912 - mae: 0.4177 - msle: 0.0423 - val_loss: 0.4696 - val_mae: 0.5364 - val_msle: 0.0676\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2844 - mae: 0.4039 - msle: 0.0414 - val_loss: 0.4466 - val_mae: 0.5394 - val_msle: 0.0649\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2796 - mae: 0.4080 - msle: 0.0399 - val_loss: 0.4380 - val_mae: 0.5302 - val_msle: 0.0637\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2715 - mae: 0.4037 - msle: 0.0388 - val_loss: 0.4361 - val_mae: 0.5230 - val_msle: 0.0626\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2908 - mae: 0.4065 - msle: 0.0402 - val_loss: 0.4496 - val_mae: 0.5314 - val_msle: 0.0649\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2618 - mae: 0.3974 - msle: 0.0386 - val_loss: 0.4346 - val_mae: 0.5178 - val_msle: 0.0620\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2783 - mae: 0.4053 - msle: 0.0408 - val_loss: 0.4517 - val_mae: 0.5329 - val_msle: 0.0657\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2770 - mae: 0.4115 - msle: 0.0379 - val_loss: 0.4489 - val_mae: 0.5287 - val_msle: 0.0673\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2824 - mae: 0.4072 - msle: 0.0419 - val_loss: 0.4473 - val_mae: 0.5291 - val_msle: 0.0656\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2746 - mae: 0.4036 - msle: 0.0398 - val_loss: 0.4555 - val_mae: 0.5338 - val_msle: 0.0664\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2925 - mae: 0.4095 - msle: 0.0407 - val_loss: 0.4341 - val_mae: 0.5239 - val_msle: 0.0633\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2995 - mae: 0.4220 - msle: 0.0434 - val_loss: 0.4508 - val_mae: 0.5293 - val_msle: 0.0651\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2628 - mae: 0.3952 - msle: 0.0363 - val_loss: 0.4534 - val_mae: 0.5287 - val_msle: 0.0664\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2582 - mae: 0.3991 - msle: 0.0356 - val_loss: 0.4461 - val_mae: 0.5328 - val_msle: 0.0649\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2666 - mae: 0.3961 - msle: 0.0361 - val_loss: 0.4506 - val_mae: 0.5291 - val_msle: 0.0664\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2708 - mae: 0.4001 - msle: 0.0397 - val_loss: 0.4426 - val_mae: 0.5296 - val_msle: 0.0640\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2676 - mae: 0.3984 - msle: 0.0371 - val_loss: 0.4405 - val_mae: 0.5244 - val_msle: 0.0632\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2965 - mae: 0.4170 - msle: 0.0451 - val_loss: 0.4374 - val_mae: 0.5167 - val_msle: 0.0610\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2736 - mae: 0.4065 - msle: 0.0399 - val_loss: 0.4363 - val_mae: 0.5257 - val_msle: 0.0619\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2829 - mae: 0.4116 - msle: 0.0403 - val_loss: 0.4337 - val_mae: 0.5283 - val_msle: 0.0626\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2568 - mae: 0.3894 - msle: 0.0365 - val_loss: 0.4473 - val_mae: 0.5314 - val_msle: 0.0642\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2512 - mae: 0.3825 - msle: 0.0343 - val_loss: 0.4501 - val_mae: 0.5224 - val_msle: 0.0658\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2794 - mae: 0.4009 - msle: 0.0392 - val_loss: 0.4409 - val_mae: 0.5309 - val_msle: 0.0640\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2677 - mae: 0.4010 - msle: 0.0385 - val_loss: 0.4545 - val_mae: 0.5292 - val_msle: 0.0671\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2488 - mae: 0.3866 - msle: 0.0375 - val_loss: 0.4730 - val_mae: 0.5344 - val_msle: 0.0678\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2875 - mae: 0.4126 - msle: 0.0414 - val_loss: 0.4514 - val_mae: 0.5219 - val_msle: 0.0660\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2650 - mae: 0.3918 - msle: 0.0385 - val_loss: 0.4506 - val_mae: 0.5289 - val_msle: 0.0664\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2821 - mae: 0.4116 - msle: 0.0379 - val_loss: 0.4568 - val_mae: 0.5337 - val_msle: 0.0682\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2853 - mae: 0.4071 - msle: 0.0409 - val_loss: 0.4286 - val_mae: 0.5220 - val_msle: 0.0642\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2810 - mae: 0.4085 - msle: 0.0371 - val_loss: 0.4675 - val_mae: 0.5415 - val_msle: 0.0682\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2936 - mae: 0.4113 - msle: 0.0432 - val_loss: 0.4468 - val_mae: 0.5268 - val_msle: 0.0638\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2733 - mae: 0.4012 - msle: 0.0380 - val_loss: 0.4549 - val_mae: 0.5375 - val_msle: 0.0646\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2628 - mae: 0.3934 - msle: 0.0382 - val_loss: 0.4646 - val_mae: 0.5417 - val_msle: 0.0679\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2655 - mae: 0.3956 - msle: 0.0370 - val_loss: 0.4240 - val_mae: 0.5185 - val_msle: 0.0614\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2690 - mae: 0.3943 - msle: 0.0403 - val_loss: 0.4681 - val_mae: 0.5385 - val_msle: 0.0695\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2819 - mae: 0.4072 - msle: 0.0429 - val_loss: 0.4238 - val_mae: 0.5190 - val_msle: 0.0615\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2722 - mae: 0.4062 - msle: 0.0418 - val_loss: 0.4926 - val_mae: 0.5548 - val_msle: 0.0756\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2632 - mae: 0.3921 - msle: 0.0371 - val_loss: 0.4876 - val_mae: 0.5507 - val_msle: 0.0723\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2629 - mae: 0.3952 - msle: 0.0361 - val_loss: 0.4489 - val_mae: 0.5255 - val_msle: 0.0643\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2686 - mae: 0.3959 - msle: 0.0416 - val_loss: 0.4621 - val_mae: 0.5338 - val_msle: 0.0679\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2722 - mae: 0.4053 - msle: 0.0386 - val_loss: 0.4674 - val_mae: 0.5355 - val_msle: 0.0685\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2735 - mae: 0.4017 - msle: 0.0404 - val_loss: 0.4606 - val_mae: 0.5341 - val_msle: 0.0688\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2652 - mae: 0.3929 - msle: 0.0364 - val_loss: 0.4284 - val_mae: 0.5234 - val_msle: 0.0624\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2503 - mae: 0.3826 - msle: 0.0393 - val_loss: 0.4343 - val_mae: 0.5188 - val_msle: 0.0616\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2704 - mae: 0.4080 - msle: 0.0402 - val_loss: 0.4601 - val_mae: 0.5289 - val_msle: 0.0668\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2566 - mae: 0.3940 - msle: 0.0360 - val_loss: 0.4250 - val_mae: 0.5094 - val_msle: 0.0621\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3024 - mae: 0.4178 - msle: 0.0428 - val_loss: 0.4365 - val_mae: 0.5153 - val_msle: 0.0612\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2592 - mae: 0.3945 - msle: 0.0367 - val_loss: 0.4512 - val_mae: 0.5288 - val_msle: 0.0645\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2606 - mae: 0.3871 - msle: 0.0387 - val_loss: 0.4685 - val_mae: 0.5386 - val_msle: 0.0686\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2565 - mae: 0.3893 - msle: 0.0363 - val_loss: 0.4414 - val_mae: 0.5300 - val_msle: 0.0640\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2615 - mae: 0.3956 - msle: 0.0383 - val_loss: 0.4219 - val_mae: 0.5108 - val_msle: 0.0600\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2613 - mae: 0.3941 - msle: 0.0404 - val_loss: 0.4766 - val_mae: 0.5342 - val_msle: 0.0697\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2684 - mae: 0.4043 - msle: 0.0395 - val_loss: 0.4364 - val_mae: 0.5221 - val_msle: 0.0639\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2700 - mae: 0.3997 - msle: 0.0403 - val_loss: 0.4454 - val_mae: 0.5266 - val_msle: 0.0642\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2570 - mae: 0.3877 - msle: 0.0371 - val_loss: 0.4610 - val_mae: 0.5330 - val_msle: 0.0662\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2814 - mae: 0.4000 - msle: 0.0427 - val_loss: 0.4427 - val_mae: 0.5353 - val_msle: 0.0617\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2744 - mae: 0.4071 - msle: 0.0389 - val_loss: 0.4507 - val_mae: 0.5246 - val_msle: 0.0675\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2937 - mae: 0.4083 - msle: 0.0411 - val_loss: 0.4384 - val_mae: 0.5167 - val_msle: 0.0633\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2933 - mae: 0.4152 - msle: 0.0448 - val_loss: 0.4499 - val_mae: 0.5283 - val_msle: 0.0646\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2738 - mae: 0.4008 - msle: 0.0405 - val_loss: 0.4480 - val_mae: 0.5194 - val_msle: 0.0643\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2626 - mae: 0.3907 - msle: 0.0379 - val_loss: 0.4259 - val_mae: 0.5260 - val_msle: 0.0600\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2696 - mae: 0.3990 - msle: 0.0381 - val_loss: 0.4360 - val_mae: 0.5194 - val_msle: 0.0611\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2597 - mae: 0.3907 - msle: 0.0393 - val_loss: 0.4444 - val_mae: 0.5190 - val_msle: 0.0633\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2753 - mae: 0.3880 - msle: 0.0410 - val_loss: 0.4500 - val_mae: 0.5283 - val_msle: 0.0653\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2728 - mae: 0.4019 - msle: 0.0399 - val_loss: 0.4308 - val_mae: 0.5196 - val_msle: 0.0630\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2706 - mae: 0.4007 - msle: 0.0438 - val_loss: 0.4379 - val_mae: 0.5277 - val_msle: 0.0648\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2673 - mae: 0.3998 - msle: 0.0392 - val_loss: 0.4315 - val_mae: 0.5163 - val_msle: 0.0615\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2739 - mae: 0.4033 - msle: 0.0389 - val_loss: 0.4653 - val_mae: 0.5321 - val_msle: 0.0667\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2588 - mae: 0.3905 - msle: 0.0360 - val_loss: 0.4323 - val_mae: 0.5162 - val_msle: 0.0624\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2463 - mae: 0.3863 - msle: 0.0338 - val_loss: 0.4558 - val_mae: 0.5350 - val_msle: 0.0663\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2573 - mae: 0.3867 - msle: 0.0346 - val_loss: 0.4545 - val_mae: 0.5326 - val_msle: 0.0664\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2749 - mae: 0.4023 - msle: 0.0391 - val_loss: 0.4471 - val_mae: 0.5292 - val_msle: 0.0671\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2748 - mae: 0.3986 - msle: 0.0408 - val_loss: 0.4526 - val_mae: 0.5253 - val_msle: 0.0687\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2506 - mae: 0.3861 - msle: 0.0353 - val_loss: 0.4327 - val_mae: 0.5168 - val_msle: 0.0646\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2461 - mae: 0.3776 - msle: 0.0351 - val_loss: 0.4387 - val_mae: 0.5146 - val_msle: 0.0648\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2610 - mae: 0.3898 - msle: 0.0373 - val_loss: 0.4352 - val_mae: 0.5164 - val_msle: 0.0649\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2686 - mae: 0.3982 - msle: 0.0397 - val_loss: 0.4335 - val_mae: 0.5208 - val_msle: 0.0645\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2724 - mae: 0.4003 - msle: 0.0408 - val_loss: 0.4613 - val_mae: 0.5371 - val_msle: 0.0682\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2489 - mae: 0.3795 - msle: 0.0367 - val_loss: 0.4321 - val_mae: 0.5125 - val_msle: 0.0615\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2397 - mae: 0.3772 - msle: 0.0343 - val_loss: 0.4444 - val_mae: 0.5223 - val_msle: 0.0643\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2399 - mae: 0.3751 - msle: 0.0348 - val_loss: 0.4406 - val_mae: 0.5202 - val_msle: 0.0649\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2615 - mae: 0.4008 - msle: 0.0379 - val_loss: 0.4541 - val_mae: 0.5287 - val_msle: 0.0677\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2364 - mae: 0.3764 - msle: 0.0357 - val_loss: 0.4782 - val_mae: 0.5303 - val_msle: 0.0731\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2703 - mae: 0.4015 - msle: 0.0389 - val_loss: 0.4640 - val_mae: 0.5397 - val_msle: 0.0692\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2576 - mae: 0.3939 - msle: 0.0363 - val_loss: 0.4389 - val_mae: 0.5264 - val_msle: 0.0652\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2341 - mae: 0.3775 - msle: 0.0333 - val_loss: 0.4602 - val_mae: 0.5309 - val_msle: 0.0678\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2444 - mae: 0.3753 - msle: 0.0359 - val_loss: 0.4222 - val_mae: 0.5204 - val_msle: 0.0622\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2640 - mae: 0.3914 - msle: 0.0381 - val_loss: 0.4359 - val_mae: 0.5222 - val_msle: 0.0642\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2539 - mae: 0.3857 - msle: 0.0329 - val_loss: 0.4481 - val_mae: 0.5244 - val_msle: 0.0639\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2382 - mae: 0.3764 - msle: 0.0345 - val_loss: 0.4504 - val_mae: 0.5228 - val_msle: 0.0650\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2570 - mae: 0.3896 - msle: 0.0358 - val_loss: 0.4540 - val_mae: 0.5328 - val_msle: 0.0659\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2465 - mae: 0.3880 - msle: 0.0353 - val_loss: 0.4384 - val_mae: 0.5237 - val_msle: 0.0617\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2298 - mae: 0.3659 - msle: 0.0307 - val_loss: 0.4651 - val_mae: 0.5349 - val_msle: 0.0673\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2573 - mae: 0.3927 - msle: 0.0366 - val_loss: 0.4701 - val_mae: 0.5385 - val_msle: 0.0685\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2457 - mae: 0.3831 - msle: 0.0355 - val_loss: 0.4328 - val_mae: 0.5152 - val_msle: 0.0615\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2437 - mae: 0.3824 - msle: 0.0342 - val_loss: 0.4478 - val_mae: 0.5227 - val_msle: 0.0646\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2259 - mae: 0.3630 - msle: 0.0333 - val_loss: 0.4593 - val_mae: 0.5318 - val_msle: 0.0665\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2459 - mae: 0.3734 - msle: 0.0358 - val_loss: 0.4625 - val_mae: 0.5334 - val_msle: 0.0664\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2484 - mae: 0.3844 - msle: 0.0350 - val_loss: 0.4870 - val_mae: 0.5438 - val_msle: 0.0706\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2574 - mae: 0.3918 - msle: 0.0377 - val_loss: 0.4643 - val_mae: 0.5382 - val_msle: 0.0669\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2688 - mae: 0.3987 - msle: 0.0399 - val_loss: 0.4594 - val_mae: 0.5260 - val_msle: 0.0674\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2574 - mae: 0.3862 - msle: 0.0375 - val_loss: 0.4765 - val_mae: 0.5476 - val_msle: 0.0701\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2581 - mae: 0.3877 - msle: 0.0333 - val_loss: 0.4334 - val_mae: 0.5252 - val_msle: 0.0649\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2597 - mae: 0.3918 - msle: 0.0377 - val_loss: 0.4643 - val_mae: 0.5242 - val_msle: 0.0680\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2520 - mae: 0.3850 - msle: 0.0369 - val_loss: 0.4473 - val_mae: 0.5318 - val_msle: 0.0632\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2571 - mae: 0.3961 - msle: 0.0354 - val_loss: 0.4457 - val_mae: 0.5261 - val_msle: 0.0657\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2539 - mae: 0.3870 - msle: 0.0382 - val_loss: 0.4516 - val_mae: 0.5291 - val_msle: 0.0664\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2346 - mae: 0.3775 - msle: 0.0362 - val_loss: 0.4267 - val_mae: 0.5223 - val_msle: 0.0633\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2807 - mae: 0.4044 - msle: 0.0418 - val_loss: 0.4412 - val_mae: 0.5194 - val_msle: 0.0647\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2492 - mae: 0.3795 - msle: 0.0383 - val_loss: 0.4257 - val_mae: 0.5198 - val_msle: 0.0633\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2543 - mae: 0.3943 - msle: 0.0380 - val_loss: 0.4491 - val_mae: 0.5266 - val_msle: 0.0655\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2640 - mae: 0.3943 - msle: 0.0374 - val_loss: 0.4873 - val_mae: 0.5515 - val_msle: 0.0718\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2506 - mae: 0.3838 - msle: 0.0357 - val_loss: 0.4551 - val_mae: 0.5323 - val_msle: 0.0657\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2296 - mae: 0.3774 - msle: 0.0337 - val_loss: 0.4560 - val_mae: 0.5352 - val_msle: 0.0690\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2409 - mae: 0.3771 - msle: 0.0336 - val_loss: 0.4818 - val_mae: 0.5439 - val_msle: 0.0721\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2324 - mae: 0.3779 - msle: 0.0347 - val_loss: 0.4894 - val_mae: 0.5436 - val_msle: 0.0711\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2374 - mae: 0.3780 - msle: 0.0316 - val_loss: 0.4568 - val_mae: 0.5293 - val_msle: 0.0649\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2321 - mae: 0.3762 - msle: 0.0325 - val_loss: 0.4398 - val_mae: 0.5242 - val_msle: 0.0634\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2587 - mae: 0.3863 - msle: 0.0349 - val_loss: 0.4636 - val_mae: 0.5263 - val_msle: 0.0681\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2420 - mae: 0.3787 - msle: 0.0338 - val_loss: 0.4705 - val_mae: 0.5340 - val_msle: 0.0692\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2497 - mae: 0.3798 - msle: 0.0351 - val_loss: 0.4825 - val_mae: 0.5410 - val_msle: 0.0714\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2341 - mae: 0.3750 - msle: 0.0330 - val_loss: 0.4505 - val_mae: 0.5294 - val_msle: 0.0661\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2288 - mae: 0.3650 - msle: 0.0314 - val_loss: 0.4784 - val_mae: 0.5450 - val_msle: 0.0748\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2617 - mae: 0.3951 - msle: 0.0392 - val_loss: 0.4731 - val_mae: 0.5331 - val_msle: 0.0693\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2567 - mae: 0.3873 - msle: 0.0378 - val_loss: 0.4740 - val_mae: 0.5391 - val_msle: 0.0691\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2458 - mae: 0.3813 - msle: 0.0373 - val_loss: 0.4347 - val_mae: 0.5332 - val_msle: 0.0641\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2355 - mae: 0.3701 - msle: 0.0391 - val_loss: 0.4401 - val_mae: 0.5209 - val_msle: 0.0655\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2363 - mae: 0.3794 - msle: 0.0315 - val_loss: 0.4655 - val_mae: 0.5340 - val_msle: 0.0683\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2524 - mae: 0.3801 - msle: 0.0375 - val_loss: 0.4543 - val_mae: 0.5257 - val_msle: 0.0660\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2353 - mae: 0.3715 - msle: 0.0365 - val_loss: 0.4668 - val_mae: 0.5254 - val_msle: 0.0669\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2385 - mae: 0.3766 - msle: 0.0353 - val_loss: 0.4380 - val_mae: 0.5167 - val_msle: 0.0623\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2463 - mae: 0.3796 - msle: 0.0358 - val_loss: 0.4339 - val_mae: 0.5204 - val_msle: 0.0645\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2644 - mae: 0.4024 - msle: 0.0410 - val_loss: 0.4585 - val_mae: 0.5193 - val_msle: 0.0647\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2312 - mae: 0.3703 - msle: 0.0340 - val_loss: 0.4793 - val_mae: 0.5362 - val_msle: 0.0709\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2464 - mae: 0.3771 - msle: 0.0362 - val_loss: 0.4365 - val_mae: 0.5179 - val_msle: 0.0624\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2562 - mae: 0.3857 - msle: 0.0372 - val_loss: 0.4833 - val_mae: 0.5436 - val_msle: 0.0708\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2588 - mae: 0.3882 - msle: 0.0355 - val_loss: 0.4563 - val_mae: 0.5337 - val_msle: 0.0668\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2660 - mae: 0.3967 - msle: 0.0395 - val_loss: 0.4508 - val_mae: 0.5202 - val_msle: 0.0656\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2397 - mae: 0.3752 - msle: 0.0351 - val_loss: 0.4698 - val_mae: 0.5269 - val_msle: 0.0677\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2425 - mae: 0.3747 - msle: 0.0350 - val_loss: 0.4520 - val_mae: 0.5184 - val_msle: 0.0643\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2528 - mae: 0.3855 - msle: 0.0375 - val_loss: 0.4789 - val_mae: 0.5371 - val_msle: 0.0693\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2433 - mae: 0.3774 - msle: 0.0351 - val_loss: 0.4578 - val_mae: 0.5246 - val_msle: 0.0662\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2502 - mae: 0.3884 - msle: 0.0390 - val_loss: 0.4707 - val_mae: 0.5332 - val_msle: 0.0718\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2655 - mae: 0.3880 - msle: 0.0388 - val_loss: 0.4433 - val_mae: 0.5179 - val_msle: 0.0687\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2503 - mae: 0.3812 - msle: 0.0373 - val_loss: 0.4635 - val_mae: 0.5311 - val_msle: 0.0684\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2548 - mae: 0.3806 - msle: 0.0365 - val_loss: 0.4587 - val_mae: 0.5259 - val_msle: 0.0670\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2450 - mae: 0.3842 - msle: 0.0349 - val_loss: 0.4895 - val_mae: 0.5443 - val_msle: 0.0754\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2423 - mae: 0.3768 - msle: 0.0373 - val_loss: 0.4587 - val_mae: 0.5326 - val_msle: 0.0671\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2308 - mae: 0.3626 - msle: 0.0295 - val_loss: 0.4603 - val_mae: 0.5358 - val_msle: 0.0709\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2253 - mae: 0.3700 - msle: 0.0331 - val_loss: 0.4376 - val_mae: 0.5247 - val_msle: 0.0627\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2393 - mae: 0.3770 - msle: 0.0321 - val_loss: 0.4369 - val_mae: 0.5175 - val_msle: 0.0623\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2288 - mae: 0.3707 - msle: 0.0312 - val_loss: 0.4404 - val_mae: 0.5258 - val_msle: 0.0649\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2285 - mae: 0.3696 - msle: 0.0332 - val_loss: 0.4276 - val_mae: 0.5203 - val_msle: 0.0624\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2275 - mae: 0.3606 - msle: 0.0331 - val_loss: 0.4159 - val_mae: 0.5096 - val_msle: 0.0611\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2408 - mae: 0.3783 - msle: 0.0320 - val_loss: 0.4055 - val_mae: 0.4936 - val_msle: 0.0586\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2508 - mae: 0.3730 - msle: 0.0362 - val_loss: 0.4524 - val_mae: 0.5143 - val_msle: 0.0652\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2427 - mae: 0.3801 - msle: 0.0384 - val_loss: 0.4278 - val_mae: 0.5137 - val_msle: 0.0621\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2300 - mae: 0.3711 - msle: 0.0300 - val_loss: 0.4380 - val_mae: 0.5138 - val_msle: 0.0655\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2324 - mae: 0.3710 - msle: 0.0329 - val_loss: 0.4509 - val_mae: 0.5271 - val_msle: 0.0667\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.3714 - msle: 0.0366 - val_loss: 0.4585 - val_mae: 0.5295 - val_msle: 0.0678\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2396 - mae: 0.3750 - msle: 0.0344 - val_loss: 0.4604 - val_mae: 0.5369 - val_msle: 0.0698\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2154 - mae: 0.3562 - msle: 0.0321 - val_loss: 0.4295 - val_mae: 0.5213 - val_msle: 0.0669\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2247 - mae: 0.3699 - msle: 0.0302 - val_loss: 0.4295 - val_mae: 0.5168 - val_msle: 0.0639\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2053 - mae: 0.3547 - msle: 0.0297 - val_loss: 0.4695 - val_mae: 0.5362 - val_msle: 0.0673\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2223 - mae: 0.3639 - msle: 0.0309 - val_loss: 0.4504 - val_mae: 0.5223 - val_msle: 0.0670\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2542 - mae: 0.3826 - msle: 0.0389 - val_loss: 0.4358 - val_mae: 0.5208 - val_msle: 0.0647\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2448 - mae: 0.3837 - msle: 0.0349 - val_loss: 0.4363 - val_mae: 0.5156 - val_msle: 0.0633\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2240 - mae: 0.3676 - msle: 0.0334 - val_loss: 0.4423 - val_mae: 0.5115 - val_msle: 0.0645\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2544 - mae: 0.3810 - msle: 0.0407 - val_loss: 0.4523 - val_mae: 0.5200 - val_msle: 0.0676\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2527 - mae: 0.3829 - msle: 0.0361 - val_loss: 0.4374 - val_mae: 0.5248 - val_msle: 0.0672\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2349 - mae: 0.3845 - msle: 0.0342 - val_loss: 0.4370 - val_mae: 0.5128 - val_msle: 0.0661\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2136 - mae: 0.3638 - msle: 0.0296 - val_loss: 0.4357 - val_mae: 0.5128 - val_msle: 0.0649\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2323 - mae: 0.3718 - msle: 0.0335 - val_loss: 0.4320 - val_mae: 0.5216 - val_msle: 0.0633\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2221 - mae: 0.3661 - msle: 0.0314 - val_loss: 0.4645 - val_mae: 0.5329 - val_msle: 0.0696\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2235 - mae: 0.3679 - msle: 0.0321 - val_loss: 0.4463 - val_mae: 0.5241 - val_msle: 0.0627\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2135 - mae: 0.3591 - msle: 0.0283 - val_loss: 0.4318 - val_mae: 0.5142 - val_msle: 0.0644\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2344 - mae: 0.3680 - msle: 0.0327 - val_loss: 0.4719 - val_mae: 0.5355 - val_msle: 0.0729\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2259 - mae: 0.3652 - msle: 0.0324 - val_loss: 0.4152 - val_mae: 0.5158 - val_msle: 0.0631\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2232 - mae: 0.3672 - msle: 0.0328 - val_loss: 0.4107 - val_mae: 0.5034 - val_msle: 0.0598\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2339 - mae: 0.3662 - msle: 0.0355 - val_loss: 0.4343 - val_mae: 0.5105 - val_msle: 0.0639\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2246 - mae: 0.3612 - msle: 0.0320 - val_loss: 0.4423 - val_mae: 0.5255 - val_msle: 0.0640\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2447 - mae: 0.3757 - msle: 0.0375 - val_loss: 0.4171 - val_mae: 0.5217 - val_msle: 0.0622\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2228 - mae: 0.3593 - msle: 0.0301 - val_loss: 0.4406 - val_mae: 0.5215 - val_msle: 0.0672\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2369 - mae: 0.3759 - msle: 0.0330 - val_loss: 0.4160 - val_mae: 0.5049 - val_msle: 0.0642\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2258 - mae: 0.3747 - msle: 0.0318 - val_loss: 0.4205 - val_mae: 0.5207 - val_msle: 0.0649\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2081 - mae: 0.3512 - msle: 0.0286 - val_loss: 0.4847 - val_mae: 0.5466 - val_msle: 0.0746\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2393 - mae: 0.3718 - msle: 0.0345 - val_loss: 0.5081 - val_mae: 0.5490 - val_msle: 0.0767\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2372 - mae: 0.3720 - msle: 0.0324 - val_loss: 0.4418 - val_mae: 0.5275 - val_msle: 0.0632\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2531 - mae: 0.3840 - msle: 0.0352 - val_loss: 0.4480 - val_mae: 0.5273 - val_msle: 0.0664\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2452 - mae: 0.3674 - msle: 0.0371 - val_loss: 0.4301 - val_mae: 0.5167 - val_msle: 0.0602\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2268 - mae: 0.3632 - msle: 0.0332 - val_loss: 0.4522 - val_mae: 0.5298 - val_msle: 0.0672\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2452 - mae: 0.3733 - msle: 0.0372 - val_loss: 0.4216 - val_mae: 0.5164 - val_msle: 0.0615\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2394 - mae: 0.3805 - msle: 0.0327 - val_loss: 0.4498 - val_mae: 0.5232 - val_msle: 0.0672\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2425 - mae: 0.3732 - msle: 0.0371 - val_loss: 0.4551 - val_mae: 0.5328 - val_msle: 0.0685\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2575 - mae: 0.3870 - msle: 0.0364 - val_loss: 0.4221 - val_mae: 0.5000 - val_msle: 0.0602\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2227 - mae: 0.3620 - msle: 0.0319 - val_loss: 0.4587 - val_mae: 0.5243 - val_msle: 0.0662\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2278 - mae: 0.3673 - msle: 0.0312 - val_loss: 0.4455 - val_mae: 0.5245 - val_msle: 0.0666\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2359 - mae: 0.3720 - msle: 0.0308 - val_loss: 0.4533 - val_mae: 0.5248 - val_msle: 0.0682\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2367 - mae: 0.3735 - msle: 0.0327 - val_loss: 0.4489 - val_mae: 0.5267 - val_msle: 0.0675\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2193 - mae: 0.3631 - msle: 0.0307 - val_loss: 0.4315 - val_mae: 0.5116 - val_msle: 0.0642\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2492 - mae: 0.3813 - msle: 0.0378 - val_loss: 0.4299 - val_mae: 0.5145 - val_msle: 0.0632\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2364 - mae: 0.3749 - msle: 0.0337 - val_loss: 0.4440 - val_mae: 0.5230 - val_msle: 0.0679\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2358 - mae: 0.3803 - msle: 0.0338 - val_loss: 0.4587 - val_mae: 0.5369 - val_msle: 0.0701\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2289 - mae: 0.3716 - msle: 0.0329 - val_loss: 0.4304 - val_mae: 0.5250 - val_msle: 0.0629\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2226 - mae: 0.3573 - msle: 0.0308 - val_loss: 0.4416 - val_mae: 0.5238 - val_msle: 0.0645\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2296 - mae: 0.3667 - msle: 0.0323 - val_loss: 0.4658 - val_mae: 0.5265 - val_msle: 0.0698\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2285 - mae: 0.3682 - msle: 0.0329 - val_loss: 0.4634 - val_mae: 0.5280 - val_msle: 0.0681\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2263 - mae: 0.3647 - msle: 0.0318 - val_loss: 0.4333 - val_mae: 0.5181 - val_msle: 0.0620\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2393 - mae: 0.3775 - msle: 0.0342 - val_loss: 0.4405 - val_mae: 0.5161 - val_msle: 0.0662\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2288 - mae: 0.3645 - msle: 0.0325 - val_loss: 0.4577 - val_mae: 0.5208 - val_msle: 0.0697\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2482 - mae: 0.3699 - msle: 0.0358 - val_loss: 0.4894 - val_mae: 0.5362 - val_msle: 0.0744\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2184 - mae: 0.3518 - msle: 0.0314 - val_loss: 0.4758 - val_mae: 0.5321 - val_msle: 0.0709\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2189 - mae: 0.3649 - msle: 0.0305 - val_loss: 0.4566 - val_mae: 0.5264 - val_msle: 0.0672\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2285 - mae: 0.3664 - msle: 0.0338 - val_loss: 0.4541 - val_mae: 0.5261 - val_msle: 0.0671\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2314 - mae: 0.3733 - msle: 0.0356 - val_loss: 0.4231 - val_mae: 0.5164 - val_msle: 0.0632\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2305 - mae: 0.3696 - msle: 0.0341 - val_loss: 0.4223 - val_mae: 0.5053 - val_msle: 0.0632\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2420 - mae: 0.3796 - msle: 0.0347 - val_loss: 0.4247 - val_mae: 0.5113 - val_msle: 0.0628\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2204 - mae: 0.3665 - msle: 0.0326 - val_loss: 0.4334 - val_mae: 0.5122 - val_msle: 0.0645\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2304 - mae: 0.3617 - msle: 0.0330 - val_loss: 0.4791 - val_mae: 0.5355 - val_msle: 0.0726\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2266 - mae: 0.3637 - msle: 0.0322 - val_loss: 0.4618 - val_mae: 0.5217 - val_msle: 0.0672\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2214 - mae: 0.3637 - msle: 0.0335 - val_loss: 0.4660 - val_mae: 0.5349 - val_msle: 0.0716\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2318 - mae: 0.3703 - msle: 0.0318 - val_loss: 0.5014 - val_mae: 0.5362 - val_msle: 0.0745\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2267 - mae: 0.3639 - msle: 0.0335 - val_loss: 0.4827 - val_mae: 0.5319 - val_msle: 0.0705\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2206 - mae: 0.3576 - msle: 0.0309 - val_loss: 0.4869 - val_mae: 0.5341 - val_msle: 0.0725\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2294 - mae: 0.3664 - msle: 0.0324 - val_loss: 0.4592 - val_mae: 0.5326 - val_msle: 0.0666\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2469 - mae: 0.3836 - msle: 0.0374 - val_loss: 0.4432 - val_mae: 0.5186 - val_msle: 0.0645\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2232 - mae: 0.3603 - msle: 0.0342 - val_loss: 0.4446 - val_mae: 0.5152 - val_msle: 0.0628\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2348 - mae: 0.3747 - msle: 0.0339 - val_loss: 0.4438 - val_mae: 0.5169 - val_msle: 0.0638\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2234 - mae: 0.3593 - msle: 0.0337 - val_loss: 0.4324 - val_mae: 0.5152 - val_msle: 0.0611\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2227 - mae: 0.3655 - msle: 0.0319 - val_loss: 0.4363 - val_mae: 0.5162 - val_msle: 0.0642\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2392 - mae: 0.3769 - msle: 0.0358 - val_loss: 0.4339 - val_mae: 0.5148 - val_msle: 0.0630\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2353 - mae: 0.3749 - msle: 0.0346 - val_loss: 0.4735 - val_mae: 0.5296 - val_msle: 0.0673\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2268 - mae: 0.3711 - msle: 0.0335 - val_loss: 0.4736 - val_mae: 0.5258 - val_msle: 0.0706\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2334 - mae: 0.3656 - msle: 0.0324 - val_loss: 0.4461 - val_mae: 0.5211 - val_msle: 0.0670\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2415 - mae: 0.3742 - msle: 0.0335 - val_loss: 0.4433 - val_mae: 0.5247 - val_msle: 0.0645\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1990 - mae: 0.3450 - msle: 0.0309 - val_loss: 0.4601 - val_mae: 0.5241 - val_msle: 0.0654\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2141 - mae: 0.3511 - msle: 0.0309 - val_loss: 0.4432 - val_mae: 0.5150 - val_msle: 0.0629\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2275 - mae: 0.3692 - msle: 0.0300 - val_loss: 0.4456 - val_mae: 0.5192 - val_msle: 0.0613\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2226 - mae: 0.3630 - msle: 0.0301 - val_loss: 0.4371 - val_mae: 0.5285 - val_msle: 0.0623\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2102 - mae: 0.3436 - msle: 0.0287 - val_loss: 0.4367 - val_mae: 0.5132 - val_msle: 0.0636\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2224 - mae: 0.3578 - msle: 0.0312 - val_loss: 0.4192 - val_mae: 0.5073 - val_msle: 0.0609\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2219 - mae: 0.3586 - msle: 0.0338 - val_loss: 0.4061 - val_mae: 0.5070 - val_msle: 0.0583\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2206 - mae: 0.3625 - msle: 0.0316 - val_loss: 0.4153 - val_mae: 0.5072 - val_msle: 0.0608\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2267 - mae: 0.3662 - msle: 0.0319 - val_loss: 0.4237 - val_mae: 0.5148 - val_msle: 0.0606\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2165 - mae: 0.3565 - msle: 0.0321 - val_loss: 0.4161 - val_mae: 0.5095 - val_msle: 0.0601\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2457 - mae: 0.3754 - msle: 0.0318 - val_loss: 0.4624 - val_mae: 0.5292 - val_msle: 0.0708\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2165 - mae: 0.3641 - msle: 0.0323 - val_loss: 0.4649 - val_mae: 0.5364 - val_msle: 0.0685\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2116 - mae: 0.3526 - msle: 0.0294 - val_loss: 0.4636 - val_mae: 0.5281 - val_msle: 0.0676\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2330 - mae: 0.3604 - msle: 0.0325 - val_loss: 0.4830 - val_mae: 0.5324 - val_msle: 0.0715\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2110 - mae: 0.3575 - msle: 0.0291 - val_loss: 0.4348 - val_mae: 0.5118 - val_msle: 0.0620\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2230 - mae: 0.3619 - msle: 0.0325 - val_loss: 0.4620 - val_mae: 0.5246 - val_msle: 0.0676\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2070 - mae: 0.3485 - msle: 0.0304 - val_loss: 0.4398 - val_mae: 0.5164 - val_msle: 0.0647\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2447 - mae: 0.3696 - msle: 0.0384 - val_loss: 0.4303 - val_mae: 0.5142 - val_msle: 0.0614\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2216 - mae: 0.3610 - msle: 0.0316 - val_loss: 0.4522 - val_mae: 0.5297 - val_msle: 0.0660\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2156 - mae: 0.3622 - msle: 0.0323 - val_loss: 0.4500 - val_mae: 0.5344 - val_msle: 0.0683\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2121 - mae: 0.3648 - msle: 0.0302 - val_loss: 0.4136 - val_mae: 0.5107 - val_msle: 0.0594\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2098 - mae: 0.3545 - msle: 0.0314 - val_loss: 0.4155 - val_mae: 0.5086 - val_msle: 0.0602\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2283 - mae: 0.3777 - msle: 0.0308 - val_loss: 0.4149 - val_mae: 0.5111 - val_msle: 0.0594\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2046 - mae: 0.3470 - msle: 0.0283 - val_loss: 0.4224 - val_mae: 0.5210 - val_msle: 0.0600\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2103 - mae: 0.3464 - msle: 0.0307 - val_loss: 0.4127 - val_mae: 0.5092 - val_msle: 0.0585\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2010 - mae: 0.3455 - msle: 0.0288 - val_loss: 0.4371 - val_mae: 0.5195 - val_msle: 0.0657\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2030 - mae: 0.3493 - msle: 0.0283 - val_loss: 0.4468 - val_mae: 0.5223 - val_msle: 0.0634\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2379 - mae: 0.3654 - msle: 0.0320 - val_loss: 0.4361 - val_mae: 0.5206 - val_msle: 0.0626\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2373 - mae: 0.3696 - msle: 0.0346 - val_loss: 0.4324 - val_mae: 0.5205 - val_msle: 0.0611\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2359 - mae: 0.3639 - msle: 0.0384 - val_loss: 0.4537 - val_mae: 0.5428 - val_msle: 0.0656\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2119 - mae: 0.3614 - msle: 0.0306 - val_loss: 0.4260 - val_mae: 0.5124 - val_msle: 0.0586\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2078 - mae: 0.3544 - msle: 0.0296 - val_loss: 0.4445 - val_mae: 0.5263 - val_msle: 0.0643\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2123 - mae: 0.3520 - msle: 0.0277 - val_loss: 0.4081 - val_mae: 0.5062 - val_msle: 0.0565\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2140 - mae: 0.3492 - msle: 0.0293 - val_loss: 0.4343 - val_mae: 0.5230 - val_msle: 0.0615\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2161 - mae: 0.3583 - msle: 0.0315 - val_loss: 0.4545 - val_mae: 0.5263 - val_msle: 0.0689\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2235 - mae: 0.3654 - msle: 0.0323 - val_loss: 0.4346 - val_mae: 0.5201 - val_msle: 0.0634\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2246 - mae: 0.3672 - msle: 0.0329 - val_loss: 0.4259 - val_mae: 0.5133 - val_msle: 0.0645\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2182 - mae: 0.3624 - msle: 0.0306 - val_loss: 0.3996 - val_mae: 0.5087 - val_msle: 0.0606\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2289 - mae: 0.3707 - msle: 0.0354 - val_loss: 0.4085 - val_mae: 0.5150 - val_msle: 0.0621\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2190 - mae: 0.3599 - msle: 0.0312 - val_loss: 0.4582 - val_mae: 0.5303 - val_msle: 0.0680\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2211 - mae: 0.3596 - msle: 0.0324 - val_loss: 0.3931 - val_mae: 0.5049 - val_msle: 0.0577\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2328 - mae: 0.3718 - msle: 0.0334 - val_loss: 0.4065 - val_mae: 0.5042 - val_msle: 0.0565\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2174 - mae: 0.3561 - msle: 0.0326 - val_loss: 0.4060 - val_mae: 0.5120 - val_msle: 0.0600\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2221 - mae: 0.3609 - msle: 0.0305 - val_loss: 0.4015 - val_mae: 0.5018 - val_msle: 0.0594\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2109 - mae: 0.3543 - msle: 0.0294 - val_loss: 0.4410 - val_mae: 0.5201 - val_msle: 0.0663\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2180 - mae: 0.3542 - msle: 0.0313 - val_loss: 0.4520 - val_mae: 0.5308 - val_msle: 0.0666\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2362 - mae: 0.3680 - msle: 0.0333 - val_loss: 0.4087 - val_mae: 0.5090 - val_msle: 0.0603\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2178 - mae: 0.3611 - msle: 0.0323 - val_loss: 0.4043 - val_mae: 0.5116 - val_msle: 0.0598\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2245 - mae: 0.3617 - msle: 0.0322 - val_loss: 0.4139 - val_mae: 0.5188 - val_msle: 0.0638\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2195 - mae: 0.3629 - msle: 0.0329 - val_loss: 0.4404 - val_mae: 0.5249 - val_msle: 0.0673\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2260 - mae: 0.3591 - msle: 0.0335 - val_loss: 0.4187 - val_mae: 0.5050 - val_msle: 0.0623\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2308 - mae: 0.3621 - msle: 0.0340 - val_loss: 0.4097 - val_mae: 0.5076 - val_msle: 0.0586\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2186 - mae: 0.3659 - msle: 0.0304 - val_loss: 0.4153 - val_mae: 0.5161 - val_msle: 0.0606\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.2037 - mae: 0.3523 - msle: 0.0287 - val_loss: 0.3965 - val_mae: 0.5049 - val_msle: 0.0589\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2177 - mae: 0.3608 - msle: 0.0301 - val_loss: 0.4231 - val_mae: 0.5146 - val_msle: 0.0639\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2126 - mae: 0.3520 - msle: 0.0322 - val_loss: 0.4493 - val_mae: 0.5399 - val_msle: 0.0719\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2102 - mae: 0.3551 - msle: 0.0293 - val_loss: 0.4199 - val_mae: 0.5174 - val_msle: 0.0631\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2247 - mae: 0.3526 - msle: 0.0319 - val_loss: 0.4386 - val_mae: 0.5240 - val_msle: 0.0686\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2159 - mae: 0.3527 - msle: 0.0302 - val_loss: 0.4287 - val_mae: 0.5241 - val_msle: 0.0632\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2173 - mae: 0.3596 - msle: 0.0293 - val_loss: 0.3945 - val_mae: 0.5000 - val_msle: 0.0562\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2074 - mae: 0.3569 - msle: 0.0305 - val_loss: 0.4137 - val_mae: 0.5079 - val_msle: 0.0621\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2264 - mae: 0.3707 - msle: 0.0316 - val_loss: 0.4258 - val_mae: 0.5096 - val_msle: 0.0637\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2141 - mae: 0.3599 - msle: 0.0309 - val_loss: 0.4565 - val_mae: 0.5284 - val_msle: 0.0696\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2185 - mae: 0.3530 - msle: 0.0331 - val_loss: 0.4603 - val_mae: 0.5354 - val_msle: 0.0689\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2263 - mae: 0.3663 - msle: 0.0331 - val_loss: 0.4335 - val_mae: 0.5231 - val_msle: 0.0636\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2195 - mae: 0.3550 - msle: 0.0324 - val_loss: 0.4378 - val_mae: 0.5231 - val_msle: 0.0660\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2169 - mae: 0.3597 - msle: 0.0314 - val_loss: 0.4197 - val_mae: 0.5128 - val_msle: 0.0626\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2193 - mae: 0.3569 - msle: 0.0308 - val_loss: 0.4146 - val_mae: 0.5155 - val_msle: 0.0623\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2258 - mae: 0.3590 - msle: 0.0327 - val_loss: 0.4137 - val_mae: 0.5171 - val_msle: 0.0585\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2199 - mae: 0.3553 - msle: 0.0326 - val_loss: 0.4250 - val_mae: 0.5268 - val_msle: 0.0611\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2249 - mae: 0.3676 - msle: 0.0330 - val_loss: 0.4160 - val_mae: 0.5217 - val_msle: 0.0606\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2324 - mae: 0.3563 - msle: 0.0306 - val_loss: 0.4106 - val_mae: 0.5171 - val_msle: 0.0583\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2117 - mae: 0.3565 - msle: 0.0307 - val_loss: 0.4182 - val_mae: 0.5133 - val_msle: 0.0618\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2463 - mae: 0.3677 - msle: 0.0343 - val_loss: 0.4287 - val_mae: 0.5189 - val_msle: 0.0631\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2230 - mae: 0.3650 - msle: 0.0323 - val_loss: 0.4202 - val_mae: 0.5134 - val_msle: 0.0606\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2149 - mae: 0.3511 - msle: 0.0311 - val_loss: 0.4194 - val_mae: 0.5215 - val_msle: 0.0627\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.2106 - mae: 0.3594 - msle: 0.0310 - val_loss: 0.4142 - val_mae: 0.5117 - val_msle: 0.0636\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2364 - mae: 0.3661 - msle: 0.0336 - val_loss: 0.4336 - val_mae: 0.5261 - val_msle: 0.0654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4e05b3040>"
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize and fit sequential model\n",
    "sequential_model_umap = create_sequential_model(df=X_train_umap)\n",
    "sequential_model_umap.fit(x=X_train_umap,\n",
    "    y=y_train_umap,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test_umap, y_test_umap),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "9bd43574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict out values\n",
    "y_pred_seq_umap = sequential_model_umap.predict(X_test_umap)\n",
    "\n",
    "# reverse scaling\n",
    "y_pred_seq_umap = np.round(target_scaler.inverse_transform(np.array(y_pred_seq_umap)))\n",
    "y_test_umap = np.round(target_scaler.inverse_transform(np.array(y_test_umap)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "id": "b4a13617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.,  5., 10., 17., 12., 17., 11.,  9.,  7., 11.,  3.,  9.,  4.,\n",
       "         0.,  2.,  2.,  0.,  2.,  1.,  1.]),\n",
       " array([ 3.  ,  5.35,  7.7 , 10.05, 12.4 , 14.75, 17.1 , 19.45, 21.8 ,\n",
       "        24.15, 26.5 , 28.85, 31.2 , 33.55, 35.9 , 38.25, 40.6 , 42.95,\n",
       "        45.3 , 47.65, 50.  ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAANjklEQVR4nO3df4yl1V3H8fdHfqSFYqByqRUYhxpKrATBjIriD0qLWV0C/UMTiBhUkkmMVmpacbGJRBOTrTa1JhrNBlZISmkIhZaUqGxoEU2QOktBoAu2qSvdguwQom01KWK//jGXOFx25969z3NnOHvfr2Qz9zn32Tnfe7L7ycm5z3OeVBWSpPZ8x1YXIEmajgEuSY0ywCWpUQa4JDXKAJekRh27mZ2deuqptbi4uJldSlLz9u7d+0JVDUbbNzXAFxcXWVlZ2cwuJal5Sf7tUO0uoUhSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqM29U7MebS4496p/+7+ndub61fS5nEGLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrU2ABPsjvJwSRPjLS/N8nTSZ5M8kezK1GSdCiTzMBvAbatb0jyTuAK4Lyq+gHgw/2XJknayNgAr6oHgRdHmn8N2FlV3xqec3AGtUmSNjDtGvjbgZ9M8nCSv0vyw4c7MclykpUkK6urq1N2J0kaNW2AHwucAlwI/DZwR5Ic6sSq2lVVS1W1NBgMpuxOkjRq2gA/ANxVaz4PfBs4tb+yJEnjTBvgnwIuAUjyduB44IWeapIkTWDsfuBJbgcuBk5NcgC4EdgN7B5eWvgScE1V1SwLlSS92tgAr6qrDvPW1T3XIkk6At6JKUmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqPGBniS3UkODh/eMPreB5JUEh+nJkmbbJIZ+C3AttHGJGcClwLP9FyTJGkCYwO8qh4EXjzEW38CXA/4KDVJ2gJTrYEnuRz4WlU9NsG5y0lWkqysrq5O050k6RCOOMCTnAB8EPi9Sc6vql1VtVRVS4PB4Ei7kyQdxjQz8O8DzgIeS7IfOAN4JMl391mYJGljY59KP6qqHgdOe+V4GOJLVfVCj3VJksaY5DLC24GHgHOSHEhy7ezLkiSNM3YGXlVXjXl/sbdqJEkT805MSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGjXJAx12JzmY5Il1bX+c5Kkk/5zk7iQnz7RKSdJrTDIDvwXYNtK2Bzi3qs4D/gW4oee6JEljjA3wqnoQeHGk7b6qenl4+I+sPdhYkrSJ+lgD/1Xgr3v4PZKkI3DET6VfL8kHgZeB2zY4ZxlYBlhYWOjS3dxZ3HHvVpcg6XVs6hl4kmuAy4BfrKo63HlVtauqlqpqaTAYTNudJGnEVDPwJNuA3wF+uqr+u9+SJEmTmOQywtuBh4BzkhxIci3wZ8BJwJ4kjyb5yxnXKUkaMXYGXlVXHaL55hnUIkk6At6JKUmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSozrthaKjU9c9WPbv3N5TJUemS91bVbPUhTNwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMmeSLP7iQHkzyxru3NSfYk+dLw5ymzLVOSNGqSGfgtwLaRth3A/VV1NnD/8FiStInGBnhVPQi8ONJ8BXDr8PWtwHv6LUuSNM60e6G8paqeA6iq55KcdrgTkywDywALCwtTdre1uu4NIkmzMPMvMatqV1UtVdXSYDCYdXeSNDemDfDnk7wVYPjzYH8lSZImMW2A3wNcM3x9DfDpfsqRJE1qkssIbwceAs5JciDJtcBO4NIkXwIuHR5LkjbR2C8xq+qqw7z1rp5rkSQdAe/ElKRGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY2adi8U6bC67B2zf+f2HivZPPP4mbX1nIFLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGtUpwJP8VpInkzyR5PYkb+irMEnSxqYO8CSnA78JLFXVucAxwJV9FSZJ2ljXJZRjgTcmORY4AXi2e0mSpElMHeBV9TXgw8AzwHPAf1bVfaPnJVlOspJkZXV1dfpKJUmv0mUJ5RTgCuAs4HuAE5NcPXpeVe2qqqWqWhoMBtNXKkl6lS5LKO8G/rWqVqvqf4C7gB/vpyxJ0jhdAvwZ4MIkJyQJa0+p39dPWZKkcbqsgT8M3Ak8Ajw+/F27eqpLkjRGpwc6VNWNwI091SJJOgLeiSlJjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqM6XQcu9W1xx71bXYLUDGfgktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEZ1CvAkJye5M8lTSfYl+bG+CpMkbazrnZh/CvxNVf18kuOBE3qoSZI0gakDPMl3Aj8F/DJAVb0EvNRPWZKkcbosobwNWAX+KskXktyU5MTRk5IsJ1lJsrK6utqhO0nSel0C/Fjgh4C/qKoLgP8CdoyeVFW7qmqpqpYGg0GH7iRJ63UJ8APAgap6eHh8J2uBLknaBFMHeFX9O/DVJOcMm94FfLGXqiRJY3W9CuW9wG3DK1C+AvxK95IkSZPoFOBV9Siw1E8pkqQj4Z2YktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVFdrwPfNIs77t3qEiTpdcUZuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRnQM8yTHDhxp/po+CJEmT6WMGfh2wr4ffI0k6Ap0CPMkZwHbgpn7KkSRNquteKB8FrgdOOtwJSZaBZYCFhYWO3UlHny77/Ozfub3HStSaqWfgSS4DDlbV3o3Oq6pdVbVUVUuDwWDa7iRJI7osoVwEXJ5kP/AJ4JIkH+ulKknSWFMHeFXdUFVnVNUicCXw2aq6urfKJEkb8jpwSWpULw90qKoHgAf6+F2SpMk4A5ekRhngktQoA1ySGmWAS1KjDHBJapQBLkmN6uUyQql1XfYjkbaKM3BJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSo7o8E/PMJJ9Lsi/Jk0mu67MwSdLGutyJ+TLw/qp6JMlJwN4ke6rqiz3VJknaQJdnYj5XVY8MX38D2Aec3ldhkqSN9bIXSpJF4ALg4UO8twwsAywsLPTRnaQebOX+L/t3bp/673apu0u/r0edv8RM8ibgk8D7qurro+9X1a6qWqqqpcFg0LU7SdJQpwBPchxr4X1bVd3VT0mSpEl0uQolwM3Avqr6SH8lSZIm0WUGfhHwS8AlSR4d/vm5nuqSJI0x9ZeYVfUPQHqsRZJ0BLwTU5IaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRvWymZUktaDVDbwOxxm4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVFdn4m5LcnTSb6cZEdfRUmSxuvyTMxjgD8HfhZ4B3BVknf0VZgkaWNdZuA/Any5qr5SVS8BnwCu6KcsSdI4XfZCOR346rrjA8CPjp6UZBlYHh5+M8nTHfpszanAC1tdxBZzDGY4BvnQLH7rTLxqDBqquzf5UKd/B997qMYuAX6oBxrXaxqqdgG7OvTTrCQrVbW01XVsJcfAMQDHAGYzBl2WUA4AZ647PgN4tls5kqRJdQnwfwLOTnJWkuOBK4F7+ilLkjTO1EsoVfVykt8A/hY4BthdVU/2VtnRYS6XjkY4Bo4BOAYwgzFI1WuWrSVJDfBOTElqlAEuSY0ywHuSZHeSg0meWNf25iR7knxp+POUraxx1pKcmeRzSfYleTLJdcP2uRiHJG9I8vkkjw0//+8P2+fi86+X5JgkX0jymeHxXI1Bkv1JHk/yaJKVYVvvY2CA9+cWYNtI2w7g/qo6G7h/eHw0exl4f1V9P3Ah8OvD7RXmZRy+BVxSVT8InA9sS3Ih8/P517sO2LfueB7H4J1Vdf66a797HwMDvCdV9SDw4kjzFcCtw9e3Au/ZzJo2W1U9V1WPDF9/g7X/wKczJ+NQa745PDxu+KeYk8//iiRnANuBm9Y1z9UYHEbvY2CAz9Zbquo5WAs34LQtrmfTJFkELgAeZo7GYbh08ChwENhTVXP1+Yc+ClwPfHtd27yNQQH3Jdk73E4EZjAGXW6llw4pyZuATwLvq6qvJ4fadeHoVFX/C5yf5GTg7iTnbnFJmyrJZcDBqtqb5OItLmcrXVRVzyY5DdiT5KlZdOIMfLaeT/JWgOHPg1tcz8wlOY618L6tqu4aNs/dOFTVfwAPsPa9yDx9/ouAy5PsZ22H0kuSfIz5GgOq6tnhz4PA3azt3tr7GBjgs3UPcM3w9TXAp7ewlpnL2lT7ZmBfVX1k3VtzMQ5JBsOZN0neCLwbeIo5+fwAVXVDVZ1RVYusba/x2aq6mjkagyQnJjnpldfAzwBPMIMx8E7MniS5HbiYtW0znwduBD4F3AEsAM8Av1BVo190HjWS/ATw98Dj/P/65++ytg5+1I9DkvNY+3LqGNYmR3dU1R8k+S7m4POPGi6hfKCqLpunMUjyNtZm3bC2TP3xqvrDWYyBAS5JjXIJRZIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRv0fCjJtxbb7qjYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(y_test_umap), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "d348aab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11., 19., 33., 13.,  8.,  6.,  3., 10.,  6.,  6.,  1.,  1.,  5.,\n",
       "         3.,  2.,  0.,  0.,  0.,  0.,  1.]),\n",
       " array([10.  , 11.75, 13.5 , 15.25, 17.  , 18.75, 20.5 , 22.25, 24.  ,\n",
       "        25.75, 27.5 , 29.25, 31.  , 32.75, 34.5 , 36.25, 38.  , 39.75,\n",
       "        41.5 , 43.25, 45.  ], dtype=float32),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 1023,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAANVElEQVR4nO3db4hl9X3H8fcnakloAlEcZfFPpwQpCQHXMlhBKDZ/yiYpVR8IFRr2gbB5EEEhULY+iXlmSjV9UkI3VVzaNEXQoGhou2wNIRBM12RjVjbBELapZtldK0F9kqJ++2DOJMM4d+7duffO3K++X3C55/zuuXs+/Jj9cObMueemqpAk9fOe3Q4gSdoeC1ySmrLAJakpC1ySmrLAJampC3dyZ5deemktLy/v5C4lqb1nn3325apa2ji+owW+vLzMsWPHdnKXktRekv/ebNxTKJLUlAUuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLU1I5+ErOr5YNPbfu9p+77zAyTSNJveQQuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLU1NgCT/LeJN9P8qMkzyf50jB+SZIjSV4Yni+ef1xJ0ppJjsB/DXysqq4F9gL7ktwAHASOVtU1wNFhXZK0Q8YWeK16fVi9aHgUcDNweBg/DNwyj4CSpM1NdA48yQVJjgNngSNV9QxweVWdBhieL5tbSknS20xU4FX1ZlXtBa4Erk/y0Ul3kORAkmNJjp07d26bMSVJG53XVShV9Svg28A+4EySPQDD89kR7zlUVStVtbK0tDRdWknSb0xyFcpSkg8Oy+8DPgH8BHgC2D9sth94fE4ZJUmbmORb6fcAh5NcwGrhP1JVTyb5HvBIkjuAXwC3zTGnJGmDsQVeVc8B120y/r/Ax+cRSpI0np/ElKSmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmxhZ4kquSPJ3kZJLnk9w1jN+b5KUkx4fHp+cfV5K05sIJtnkD+EJV/SDJB4BnkxwZXvtKVf3t/OJJkkYZW+BVdRo4PSy/luQkcMW8g0mStnZe58CTLAPXAc8MQ3cmeS7JQ0kuHvGeA0mOJTl27ty56dJKkn5j4gJP8n7gUeDuqnoV+CrwIWAvq0fo92/2vqo6VFUrVbWytLQ0fWJJEjBhgSe5iNXy/npVPQZQVWeq6s2qegv4GnD9/GJKkjaa5CqUAA8CJ6vqgXXje9ZtditwYvbxJEmjTHIVyo3AZ4EfJzk+jN0D3J5kL1DAKeBzc8gnSRphkqtQvgtkk5e+Nfs4kqRJ+UlMSWrKApekpixwSWrKApekpixwSWrKApekpixwSWrKApekpixwSWrKApekpixwSWrKApekpixwSWrKApekpixwSWrKApekpixwSWrKApekpixwSWrKApekpixwSWrKApekpsYWeJKrkjyd5GSS55PcNYxfkuRIkheG54vnH1eStGaSI/A3gC9U1YeBG4DPJ/kIcBA4WlXXAEeHdUnSDhlb4FV1uqp+MCy/BpwErgBuBg4Pmx0GbplTRknSJs7rHHiSZeA64Bng8qo6DaslD1w24j0HkhxLcuzcuXNTxpUkrZm4wJO8H3gUuLuqXp30fVV1qKpWqmplaWlpOxklSZuYqMCTXMRqeX+9qh4bhs8k2TO8vgc4O5+IkqTNTHIVSoAHgZNV9cC6l54A9g/L+4HHZx9PkjTKhRNscyPwWeDHSY4PY/cA9wGPJLkD+AVw21wSSpI2NbbAq+q7QEa8/PHZxpEkTcpPYkpSU5OcQmlv+eBTux1BkmbOI3BJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJampsgSd5KMnZJCfWjd2b5KUkx4fHp+cbU5K00SRH4A8D+zYZ/0pV7R0e35ptLEnSOGMLvKq+A7yyA1kkSedhmnPgdyZ5bjjFcvGojZIcSHIsybFz585NsTtJ0nrbLfCvAh8C9gKngftHbVhVh6pqpapWlpaWtrk7SdJG2yrwqjpTVW9W1VvA14DrZxtLkjTOtgo8yZ51q7cCJ0ZtK0majwvHbZDkG8BNwKVJXgS+CNyUZC9QwCngc/OLKEnazNgCr6rbNxl+cA5ZJEnnwU9iSlJTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNTX2MkJNZ/ngU9t+76n7PjPDJJLeaTwCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJaqrNzaymuSmUJL0TeQQuSU1Z4JLU1NgCT/JQkrNJTqwbuyTJkSQvDM8XzzemJGmjSY7AHwb2bRg7CBytqmuAo8O6JGkHjS3wqvoO8MqG4ZuBw8PyYeCW2caSJI2z3atQLq+q0wBVdTrJZaM2THIAOABw9dVXb3N36sSvkZN2xtz/iFlVh6pqpapWlpaW5r07SXrX2G6Bn0myB2B4Pju7SJKkSWy3wJ8A9g/L+4HHZxNHkjSpSS4j/AbwPeAPkryY5A7gPuCTSV4APjmsS5J20Ng/YlbV7SNe+viMs0iSzoOfxJSkpixwSWrKApekpixwSWrKApekpixwSWrKApekptp8pdq7kTeFkrQVj8AlqSkLXJKassAlqSkLXJKassAlqSkLXJKassAlqSkLXJKassAlqSkLXJKassAlqSnvhfIO1fU+KtPknob3jlFHHoFLUlMWuCQ1NdUplCSngNeAN4E3qmplFqEkSePN4hz4n1TVyzP4dyRJ58FTKJLU1LRH4AX8R5IC/qGqDm3cIMkB4ADA1VdfPeXupHeerlcMafdNewR+Y1X9IfAp4PNJ/njjBlV1qKpWqmplaWlpyt1JktZMVeBV9cvh+SzwTeD6WYSSJI237QJP8rtJPrC2DPwpcGJWwSRJW5vmHPjlwDeTrP07/1JV/zaTVJKksbZd4FX1c+DaGWaRJJ0HLyOUpKYscElqygKXpKYscElqygKXpKYscElqygKXpKb8SjW9zW59rZnOnzfCenfzCFySmrLAJakpC1ySmrLAJakpC1ySmvIqFOldyitY+vMIXJKassAlqSkLXJKassAlqSkLXJKassAlqSkvI5TwBl4ab9qfkXlceukRuCQ1ZYFLUlNTFXiSfUl+muRnSQ7OKpQkabxtF3iSC4C/Bz4FfAS4PclHZhVMkrS1aY7Arwd+VlU/r6r/A/4VuHk2sSRJ40xzFcoVwP+sW38R+KONGyU5ABwYVl9P8tNt7u9S4OVtvnc3dMrbKSv0ytspK0yYN1/egSTjtZrbfHmqvL+32eA0BZ5NxuptA1WHgENT7Gd1Z8mxqlqZ9t/ZKZ3ydsoKvfJ2ygq98nbKCvPJO80plBeBq9atXwn8cro4kqRJTVPg/wVck+T3k/wO8BfAE7OJJUkaZ9unUKrqjSR3Av8OXAA8VFXPzyzZ2019GmaHdcrbKSv0ytspK/TK2ykrzCFvqt522lqS1ICfxJSkpixwSWpqIQs8yUNJziY5sW7skiRHkrwwPF+8mxnXjMh6b5KXkhwfHp/ezYzrJbkqydNJTiZ5Psldw/jCze8WWRdufpO8N8n3k/xoyPqlYXzh5hW2zLtwc7smyQVJfpjkyWF9Ied2zSZ5Zz63C1ngwMPAvg1jB4GjVXUNcHRYXwQP8/asAF+pqr3D41s7nGkrbwBfqKoPAzcAnx9ugbCI8zsqKyze/P4a+FhVXQvsBfYluYHFnFcYnRcWb27X3AWcXLe+qHO7ZmNemPHcLmSBV9V3gFc2DN8MHB6WDwO37GSmUUZkXVhVdbqqfjAsv8bqD9gVLOD8bpF14dSq14fVi4ZHsYDzClvmXUhJrgQ+A/zjuuGFnFsYmXfmFrLAR7i8qk7D6n9s4LJdzjPOnUmeG06xLNSvdmuSLAPXAc+w4PO7ISss4PwOvzIfB84CR6pqoed1RF5YwLkF/g74K+CtdWMLO7dsnhdmPLedCryTrwIfYvVX09PA/buaZhNJ3g88CtxdVa/udp6tbJJ1Iee3qt6sqr2sfir5+iQf3eVIWxqRd+HmNsmfAWer6tndzjKJLfLOfG47FfiZJHsAhuezu5xnpKo6M/zneAv4Gqt3blwYSS5itRC/XlWPDcMLOb+bZV30+a2qXwHfZvVvIws5r+utz7ugc3sj8OdJTrF619OPJflnFnduN807j7ntVOBPAPuH5f3A47uYZUtrP1SDW4ETo7bdaUkCPAicrKoH1r20cPM7Kusizm+SpSQfHJbfB3wC+AkLOK8wOu8izm1V/XVVXVlVy6zesuM/q+ovWdC5HZV3HnO7kF9qnOQbwE3ApUleBL4I3Ac8kuQO4BfAbbuX8LdGZL0pyV5W/yh0CvjcbuXbxI3AZ4EfD+c/Ae5hMed3VNbbF3B+9wCHs/pFJ+8BHqmqJ5N8j8WbVxid958WcG5HWcSf2a38zazn1o/SS1JTnU6hSJLWscAlqSkLXJKassAlqSkLXJKassAlqSkLXJKa+n83OxxXOG0NtAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_seq_umap, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "id": "00035b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meld_predictions_umap = pd.concat([pd.DataFrame(data=np.array(X_test_umap), columns=X_umap.columns), pd.DataFrame(data=np.array(y_pred_seq_umap), columns=[\"MELD_Prediction_UMAP\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "54e0db1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.044444444444444446, 0.4074074074074074, 0.6, 1.0]"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_accuracy_umap = meld_acc(meld_predictions_umap, meld_column=\"MELD_Prediction_UMAP\")\n",
    "prediction_accuracy_umap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
