{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "3990848b-1984-4bf0-8e3b-ef3e4ada5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, ReLU, BatchNormalization,Add, AveragePooling1D, Flatten, Dense\n",
    "from tensorflow.keras.losses import mean_squared_error, binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import Tensor\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "7effb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv1D(kernel_size=kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Dropout(.6)(y)\n",
    "    y = Conv1D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "    if downsample:\n",
    "        x = Conv1D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    out = Dropout(.6)(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(X_train.shape[1],1))\n",
    "    num_filters = 64\n",
    "    \n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv1D(kernel_size=3,\n",
    "               strides=1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(inputs)\n",
    "    t = relu_bn(t)\n",
    "    t = Dropout(.6)(t)\n",
    "    \n",
    "    num_blocks_list = [2, 5, 5, 2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    t = AveragePooling1D(3)(t)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(64, activation=\"relu\", kernel_initializer=\"glorot_uniform\")(t)\n",
    "    f1 = Dense(32, activation=\"relu\")(t)\n",
    "    f2 = Dense(16, activation=\"relu\")(f1)\n",
    "    f3 = Dense(8, activation=\"relu\")(f2)\n",
    "    outputs = Dense(1, activation='sigmoid')(f3)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=10),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "73cfc6c2-5cd1-4c20-bd0e-0694b99aac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv(\"liverData/eldd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "e19e4300-cf4e-46a4-af7a-d3672a3110f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DaysAtRisk</th>\n",
       "      <th>Deceased</th>\n",
       "      <th>LTx</th>\n",
       "      <th>Cirrhosis</th>\n",
       "      <th>ALF</th>\n",
       "      <th>Ethyltoxic</th>\n",
       "      <th>HBV</th>\n",
       "      <th>HCV</th>\n",
       "      <th>AIH</th>\n",
       "      <th>PBC</th>\n",
       "      <th>PSC</th>\n",
       "      <th>NASH</th>\n",
       "      <th>Cryptogenic</th>\n",
       "      <th>Dialysis</th>\n",
       "      <th>GIB</th>\n",
       "      <th>HCC</th>\n",
       "      <th>SBP</th>\n",
       "      <th>ALAT_S</th>\n",
       "      <th>ALB_S</th>\n",
       "      <th>AP_S</th>\n",
       "      <th>ASAT_S</th>\n",
       "      <th>B_MPV_E</th>\n",
       "      <th>B_PLT_E</th>\n",
       "      <th>B_WBC_E</th>\n",
       "      <th>BILI_S</th>\n",
       "      <th>BILID_S</th>\n",
       "      <th>CA_S</th>\n",
       "      <th>CHE_S</th>\n",
       "      <th>CHOLG_S</th>\n",
       "      <th>CL_S</th>\n",
       "      <th>CRE_S</th>\n",
       "      <th>CRP_S</th>\n",
       "      <th>CYSC_S</th>\n",
       "      <th>GGT_S</th>\n",
       "      <th>IL6_S</th>\n",
       "      <th>INR_C</th>\n",
       "      <th>NA_S</th>\n",
       "      <th>P_S</th>\n",
       "      <th>PALB_S</th>\n",
       "      <th>PROT_S</th>\n",
       "      <th>PTH_S</th>\n",
       "      <th>VDT_OH_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>male</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.56</td>\n",
       "      <td>11.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.17</td>\n",
       "      <td>74.6</td>\n",
       "      <td>3.08</td>\n",
       "      <td>100.3</td>\n",
       "      <td>104</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.97</td>\n",
       "      <td>22.87</td>\n",
       "      <td>1.11</td>\n",
       "      <td>135.4</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.19</td>\n",
       "      <td>69.6</td>\n",
       "      <td>2.39</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>28.3</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>43.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.21</td>\n",
       "      <td>101.9</td>\n",
       "      <td>304</td>\n",
       "      <td>43.54</td>\n",
       "      <td>4.87</td>\n",
       "      <td>2.43</td>\n",
       "      <td>336.50</td>\n",
       "      <td>1.77</td>\n",
       "      <td>133.1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.05</td>\n",
       "      <td>62.5</td>\n",
       "      <td>19.39</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>female</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>41.7</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.33</td>\n",
       "      <td>59.5</td>\n",
       "      <td>5.02</td>\n",
       "      <td>93.8</td>\n",
       "      <td>95</td>\n",
       "      <td>9.88</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1.84</td>\n",
       "      <td>16.74</td>\n",
       "      <td>1.09</td>\n",
       "      <td>137.4</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.17</td>\n",
       "      <td>80.5</td>\n",
       "      <td>7.39</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>23.8</td>\n",
       "      <td>52.97</td>\n",
       "      <td>3.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.5</td>\n",
       "      <td>208.3</td>\n",
       "      <td>2.23</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.55</td>\n",
       "      <td>95.7</td>\n",
       "      <td>61</td>\n",
       "      <td>90.29</td>\n",
       "      <td>4.73</td>\n",
       "      <td>24.35</td>\n",
       "      <td>709.80</td>\n",
       "      <td>2.29</td>\n",
       "      <td>130.5</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.15</td>\n",
       "      <td>48.9</td>\n",
       "      <td>2.21</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>female</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>36.3</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1.33</td>\n",
       "      <td>13.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>37.2</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2.28</td>\n",
       "      <td>63.8</td>\n",
       "      <td>4.78</td>\n",
       "      <td>100.8</td>\n",
       "      <td>73</td>\n",
       "      <td>8.65</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.45</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.10</td>\n",
       "      <td>142.6</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>67.6</td>\n",
       "      <td>4.17</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex  DaysAtRisk  Deceased  LTx  Cirrhosis  ALF  Ethyltoxic  HBV  \\\n",
       "0   68    male         200         0    0        1.0    0           1    1   \n",
       "1   64    male           3         1    0        1.0    0           1    0   \n",
       "2   67  female         208         0    0        1.0    0           1    0   \n",
       "3   32  female          17         1    0        0.0    1           0    0   \n",
       "4   64  female         189         0    0        1.0    0           1    0   \n",
       "\n",
       "   HCV  AIH  PBC  PSC  NASH  Cryptogenic  Dialysis  GIB  HCC  SBP  ALAT_S  \\\n",
       "0    0    0    0    0     0            0       0.0    0    1  0.0    0.29   \n",
       "1    0    0    0    0     0            0       0.0    1    0  0.0    0.22   \n",
       "2    0    0    0    0     0            0       0.0    0    0  0.0    0.19   \n",
       "3    0    0    0    0     0            0       0.0    0    0  0.0    0.78   \n",
       "4    0    0    0    0     0            0       0.0    1    0  0.0    0.75   \n",
       "\n",
       "   ALB_S   AP_S  ASAT_S  B_MPV_E  B_PLT_E  B_WBC_E  BILI_S  BILID_S  CA_S  \\\n",
       "0   40.9   1.17    0.56     11.0    160.0      7.4     7.9      3.5  2.17   \n",
       "1   28.3   3.68    0.66      NaN     10.0      8.1    43.2     26.0  2.04   \n",
       "2   41.7   1.50    0.68     10.8    123.0      4.9    16.9      6.9  2.33   \n",
       "3   23.8  52.97    3.24      NaN      NaN      NaN   266.5    208.3  2.23   \n",
       "4   36.3   2.79    1.33     13.9     65.0      6.3    37.2     16.9  2.28   \n",
       "\n",
       "   CHE_S  CHOLG_S   CL_S  CRE_S  CRP_S  CYSC_S  GGT_S   IL6_S  INR_C   NA_S  \\\n",
       "0   74.6     3.08  100.3    104   8.20    1.79   1.97   22.87   1.11  135.4   \n",
       "1   14.7     2.21  101.9    304  43.54    4.87   2.43  336.50   1.77  133.1   \n",
       "2   59.5     5.02   93.8     95   9.88    2.23   1.84   16.74   1.09  137.4   \n",
       "3   15.4     4.55   95.7     61  90.29    4.73  24.35  709.80   2.29  130.5   \n",
       "4   63.8     4.78  100.8     73   8.65    1.51   2.45    7.90   1.10  142.6   \n",
       "\n",
       "    P_S  PALB_S  PROT_S  PTH_S  VDT_OH_S  \n",
       "0  1.49    0.19    69.6   2.39      12.7  \n",
       "1  0.96    0.05    62.5  19.39       5.5  \n",
       "2  1.14    0.17    80.5   7.39      18.8  \n",
       "3  1.71    0.15    48.9   2.21       4.5  \n",
       "4  1.07    0.11    67.6   4.17      34.1  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print length and show sample data\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "cbd85d5f-78bb-4eff-ba36-730dbfc760f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meld functions\n",
    "#https://www.mdcalc.com/calc/10437/model-end-stage-liver-disease-meld#evidence\n",
    "\n",
    "import math\n",
    "\n",
    "# TODO: check all SI values and see what needs conversion. Sodium did not, unknown after Bili but placeholder functions added\n",
    "#convert SI units to US units\n",
    "#creatinine umol/L to mg/dl\n",
    "def convertCreatinine(CRE_S):\n",
    "     return (CRE_S * 0.0230)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertBilirubin(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertCystatinC(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertIL_6(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertWBC(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "#bilirubin umol/L to mg/dl\n",
    "def convertProtien(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "def convertAlbumin(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "def convertALAT(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "def convertASAT(BILI_S):\n",
    "     return (BILI_S * 0.0585)\n",
    "\n",
    "#meld3\n",
    "#1.33*(Female) + 4.56*ln(Serum bilirubin) + 0.82*(137 - Sodium) – 0.24*(137 - Sodium)*ln(Serum bilirubin) + 9.09*ln(INR) + 11.14*ln(Serum creatinine) + 1.85*(3.5 – Serum albumin) – 1.83*(3.5 – Serum albumin)*ln(Serum creatinine) + 6,\n",
    "#rounded to the nearest integer\n",
    "#Serum bilirubin, INR, and serum creatinine values below 1.0 are set to 1.0.\n",
    "#Sodium is limited to a range of 125-137 mEq/L, and if outside of these bounds, is set to the nearest limit.\n",
    "#Serum albumin is limited to a range of 1.5-3.5 g/dL, and if outside of these bounds, is set to the nearest limit.\n",
    "#Maximum serum creatinine is 3.0 mg/dL, and if above this bound, is set to 3.0 mg/dL.\n",
    "\n",
    "def calm_meld(CRE_S, BILI_S, INR_C):\n",
    "    meld_score = (0.957*math.log(convertCreatinine(CRE_S)) + 0.378*math.log(convertBilirubin(BILI_S)) + 1.120*math.log(INR_C) + 0.643)*10\n",
    "    return int(round(meld_score))\n",
    "\n",
    "def calc_meld3(CRE_S, BILI_S, INR_C, NA_S, ALB_S, sex):\n",
    "    BILI_S = convertBilirubin(BILI_S)\n",
    "    CRE_S = convertCreatinine(CRE_S)\n",
    "    if BILI_S < 1:\n",
    "        BILI_S = 1\n",
    "    if INR_C < 1:\n",
    "        INR_C = 1\n",
    "    if CRE_S < 1:\n",
    "        CRE_S = 1\n",
    "    if CRE_S >= 3:\n",
    "        CRE_S = 3\n",
    "    if NA_S > 137:\n",
    "        NA_S = 137\n",
    "    if NA_S < 125:\n",
    "        NA_S = 125\n",
    "    if ALB_S > 3.5:\n",
    "        ALB_S = 3.5\n",
    "    if ALB_S < 1.5:\n",
    "        ALB_S = 1.5\n",
    "    if sex == 'female':\n",
    "        sex = 1\n",
    "    else:\n",
    "        sex = 0\n",
    "    \n",
    "    meld3_score = 1.33*(sex) + 4.56*math.log(BILI_S) + 0.82*(137 - NA_S) - 0.24*(137 - NA_S)*math.log(BILI_S) + 9.09*math.log(INR_C) + 11.14*math.log(CRE_S) + 1.85*(3.5 - ALB_S) - 1.83*(3.5 - ALB_S)*math.log(CRE_S) + 6\n",
    "    return int(round(meld3_score))\n",
    "\n",
    "#meld_na\n",
    "#MELD(i) = 0.957*ln(Creatinine) + 0.378*ln(Bilirubin) + 1.120*ln(INR) + 0.643\n",
    "#Then, round to the tenth decimal place and multiply by 10. \n",
    "#If MELD(i) > 11, perform additional MELD calculation as follows:\n",
    "#MELD = MELD(i) + 1.32*(137 – Na) –  [0.033*MELD(i)*(137 – Na)]\n",
    "\n",
    "def calc_meldNA(CRE_S, BILI_S, INR_C,NA_S):\n",
    "    meldNA_score = 0.957 * math.log(convertCreatinine(CRE_S)) + 0.378*math.log(convertBilirubin(BILI_S)) + 1.120*math.log(INR_C) + 0.643\n",
    "    meldNA_score = round(meldNA_score, 1) * 10\n",
    "    if meldNA_score > 11:\n",
    "        meldNA_score = meldNA_score + 1.32*(137-NA_S) - (0.033*meldNA_score*(137-NA_S))\n",
    "    return int(round(meldNA_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "77649f89-81b2-4368-84ff-decae26fe351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#drop NA rows to allow for meld scores. 654 down to 638\n",
    "df = df.dropna(subset=['INR_C','NA_S','ALB_S'])\n",
    "\n",
    "#TODO: convert SI to metric as necessary\n",
    "#US hospital labs are in metric is why we're converting here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6c59fbd9-01aa-4eb2-a0c3-635c89b3efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy(deep=True).reset_index(drop=True)\n",
    "df2['MELD'] = df2.apply(lambda row: calm_meld(row[\"CRE_S\"],row[\"BILI_S\"],row[\"INR_C\"]), axis =1)\n",
    "df2['MELD3'] = df2.apply(lambda row: calc_meld3(row[\"CRE_S\"],row[\"BILI_S\"],row[\"INR_C\"],row[\"NA_S\"],row[\"ALB_S\"],row[\"Sex\"]), axis =1)\n",
    "df2['MELDNA'] = df2.apply(lambda row: calc_meldNA(row[\"CRE_S\"],row[\"BILI_S\"],row[\"INR_C\"],row[\"NA_S\"]), axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "b87d1f1a-4956-40ff-ad7a-f1021c07b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode Sex\n",
    "col = pd.get_dummies(df2['Sex'])\n",
    "del df2['Sex']\n",
    "df2 = df2.join(col)\n",
    "\n",
    "# take out MELD score comparisons for final_df\n",
    "final_df = df2.copy(deep=True)\n",
    "del final_df[\"MELD\"]\n",
    "del final_df[\"MELD3\"]\n",
    "del final_df[\"MELDNA\"]\n",
    "\n",
    "final_df = final_df.replace(np.NaN, 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "non_binary_cols = [col for col in final_df.columns if len(final_df[col].unique()) > 2]\n",
    "binary_cols = [col for col in final_df.columns if len(final_df[col].unique()) <= 2]\n",
    "final_df_normalized = pd.DataFrame(scaler.fit_transform(final_df[non_binary_cols]), columns=non_binary_cols)\n",
    "final_df_normalized = pd.concat([final_df[binary_cols], final_df_normalized], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "74715a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e015c355-9cf7-4166-b8d5-8df54d6b13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Goal of improving on original meld for now. \n",
    "#Meld3 is used primarily for transplant, meldNA is used for Cirrhosis: #https://www.mdcalc.com/calc/10437/model-end-stage-liver-disease-meld#evidence\n",
    "y = final_df_normalized['Deceased'].copy(deep=True)\n",
    "\n",
    "#Trim columns to use for training\n",
    "#Removing days at risk, deceased, \n",
    "#fields = ['Age','Sex','Cirrhosis','ALF','Ethyltoxic','HBV','HCV','INR_C','NA_S','P_S','','','','']\n",
    "del final_df_normalized[\"Deceased\"]\n",
    "X = final_df_normalized.copy(deep=True)\n",
    "\n",
    "# under_sample = RandomUnderSampler(sampling_strategy = 1)\n",
    "# X_under, y_under = under_sample.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=7)\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "62744690-0834-4641-9a91-4c4c6b3d0708",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 91ms/step - loss: 14891133952.0000 - accuracy: 0.6812 - val_loss: 184.7558 - val_accuracy: 0.1473\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 35.8921 - accuracy: 0.6377 - val_loss: 5.2048 - val_accuracy: 0.1473\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 14.5827 - accuracy: 0.6860 - val_loss: 5.3037 - val_accuracy: 0.8527\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 7.3255 - accuracy: 0.7923 - val_loss: 18.6755 - val_accuracy: 0.1473\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 10.5805 - accuracy: 0.6570 - val_loss: 19.7209 - val_accuracy: 0.8527\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 17.3999 - accuracy: 0.7150 - val_loss: 15.9341 - val_accuracy: 0.8527\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 6.9896 - accuracy: 0.7343 - val_loss: 3.1529 - val_accuracy: 0.8527\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.8252 - accuracy: 0.6763 - val_loss: 14.8672 - val_accuracy: 0.8527\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 18.7687 - accuracy: 0.7246 - val_loss: 10.5140 - val_accuracy: 0.8527\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 11.1558 - accuracy: 0.7440 - val_loss: 8.7930 - val_accuracy: 0.8527\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 13.3863 - accuracy: 0.7391 - val_loss: 19.3944 - val_accuracy: 0.8527\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 10.7073 - accuracy: 0.7585 - val_loss: 10.9731 - val_accuracy: 0.8527\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 3.7379 - accuracy: 0.7391 - val_loss: 8.6733 - val_accuracy: 0.8527\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 6.1827 - accuracy: 0.7150 - val_loss: 7.6518 - val_accuracy: 0.8527\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 6.1521 - accuracy: 0.7101 - val_loss: 10.3747 - val_accuracy: 0.8527\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 13.8736 - accuracy: 0.7391 - val_loss: 17.3472 - val_accuracy: 0.8527\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 16.4313 - accuracy: 0.7295 - val_loss: 16.2418 - val_accuracy: 0.8527\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 11.0134 - accuracy: 0.7440 - val_loss: 2.2134 - val_accuracy: 0.8527\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.9271 - accuracy: 0.7198 - val_loss: 1.5224 - val_accuracy: 0.8527\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 16.0975 - accuracy: 0.7488 - val_loss: 1.2880 - val_accuracy: 0.8527\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 11.6174 - accuracy: 0.6812 - val_loss: 1.7857 - val_accuracy: 0.8527\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 6.0704 - accuracy: 0.7150 - val_loss: 2.5346 - val_accuracy: 0.8527\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 4.1191 - accuracy: 0.7440 - val_loss: 4.8204 - val_accuracy: 0.8527\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 4.7016 - accuracy: 0.7488 - val_loss: 7.8703 - val_accuracy: 0.8527\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 4.4924 - accuracy: 0.7488 - val_loss: 2.1324 - val_accuracy: 0.8527\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 4.1294 - accuracy: 0.6715 - val_loss: 3.1915 - val_accuracy: 0.8527\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 5.2539 - accuracy: 0.7681 - val_loss: 27.1160 - val_accuracy: 0.1473\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 14.2742 - accuracy: 0.7488 - val_loss: 28.6208 - val_accuracy: 0.1473\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 12.1655 - accuracy: 0.6763 - val_loss: 1.9158 - val_accuracy: 0.8527\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 6.1044 - accuracy: 0.7150 - val_loss: 1.3640 - val_accuracy: 0.8527\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.2766 - accuracy: 0.7198 - val_loss: 4.5127 - val_accuracy: 0.8527\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 16.1491 - accuracy: 0.7198 - val_loss: 27.8653 - val_accuracy: 0.8527\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 15.7391 - accuracy: 0.7585 - val_loss: 10.3505 - val_accuracy: 0.8527\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 13.7811 - accuracy: 0.7488 - val_loss: 17.4787 - val_accuracy: 0.8527\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 6.1993 - accuracy: 0.7440 - val_loss: 5.3725 - val_accuracy: 0.8527\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 4.1715 - accuracy: 0.7633 - val_loss: 3.8385 - val_accuracy: 0.8527\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 6.4027 - accuracy: 0.7246 - val_loss: 4.7810 - val_accuracy: 0.8527\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 5.4137 - accuracy: 0.7295 - val_loss: 4.1759 - val_accuracy: 0.8527\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 5.3269 - accuracy: 0.7198 - val_loss: 8.7311 - val_accuracy: 0.8527\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 5.1329 - accuracy: 0.7391 - val_loss: 5.6970 - val_accuracy: 0.8527\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 6.8850 - accuracy: 0.6715 - val_loss: 20.9195 - val_accuracy: 0.8527\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 20.5366 - accuracy: 0.7391 - val_loss: 11.5339 - val_accuracy: 0.8527\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 13.9730 - accuracy: 0.7343 - val_loss: 13.8676 - val_accuracy: 0.8527\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 8.7946 - accuracy: 0.7295 - val_loss: 5.8972 - val_accuracy: 0.8527\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 5.1879 - accuracy: 0.7246 - val_loss: 6.1707 - val_accuracy: 0.8527\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.5020 - accuracy: 0.7150 - val_loss: 0.5606 - val_accuracy: 0.8527\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 5.0982 - accuracy: 0.7246 - val_loss: 10.4850 - val_accuracy: 0.1473\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 5.6455 - accuracy: 0.6860 - val_loss: 13.4018 - val_accuracy: 0.8527\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 5.2499 - accuracy: 0.7343 - val_loss: 1.7408 - val_accuracy: 0.8527\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 5.2289 - accuracy: 0.7295 - val_loss: 7.6562 - val_accuracy: 0.1473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dc0b608ca0>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_res_net()\n",
    "model.fit(x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397adcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: custom accuracy metric. Not trying to match current meld value, but to prove our model is \n",
    "#      generating a better measure of short term survivability. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
