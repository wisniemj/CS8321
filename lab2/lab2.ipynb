{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem, ML\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.ML import Scoring\n",
    "from rdkit.ML.Scoring import Scoring\n",
    "from rdkit.ML.Scoring.Scoring import CalcAUC, CalcBEDROC, CalcEnrichment\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Give an overview of the dataset you have chosen to use.\n",
    ">\n",
    ">    - What is the classification task and what is the format of the feature data. Is this multi-task, multi-modal, or both? Explain.\n",
    ">    - Who collected the data? Why? When?\n",
    ">    - What evaluation criteria will you be using and why? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MySQL Query used to create the \"raw\" data from chemBL - note that we do filter to IC50 standard type and nM for our standard units as our only transformations prior to bringing this data into a Python Environment.  We do this to limit the size of the data ingested.  Additionally, we select on choice columns from our first table (Activities) as these columns we believed to be most important and all other columns to be irrelevant or redundant.\n",
    "```\n",
    "SELECT  a.activity_id,\n",
    "\t\ta.assay_id,\n",
    "        a.doc_id,\n",
    "        a.record_id,\n",
    "        a.molregno,\n",
    "        a.standard_relation,\n",
    "        a.standard_value,\n",
    "        a.standard_units,\n",
    "        a.standard_flag,\n",
    "        a.standard_type,\n",
    "        a.pchembl_value,\n",
    "        b.*,\n",
    "        c.*,\n",
    "        d.*,\n",
    "        e.canonical_smiles\n",
    "-- output data\n",
    "INTO OUTFILE 'C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/result.tsv'\n",
    "FIELDS TERMINATED BY '\\t' OPTIONALLY ENCLOSED BY '\"'\n",
    "LINES TERMINATED BY '\\n'\n",
    "FROM chembl.activities a\n",
    "\n",
    "-- Join on ligand table\n",
    "inner join chembl.ligand_eff b\n",
    "on a.activity_id = b.activity_id\n",
    "\n",
    "-- Join on Compound Properties\n",
    "inner join chembl.compound_properties c\n",
    "on a.molregno = c.molregno\n",
    "\n",
    "-- Join on Assays\n",
    "inner join chembl.assays d\n",
    "on a.assay_id = d.assay_id\n",
    "\n",
    "-- Join on Compound Properties for the Smiles\n",
    "inner join chembl.compound_structures e\n",
    "on a.molregno = e.molregno\n",
    "\n",
    "where a.standard_type = 'IC50' and a.standard_units = 'nM';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv(\"chemBL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_value</th>\n",
       "      <th>le</th>\n",
       "      <th>target_type</th>\n",
       "      <th>pref_name</th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>molecular_species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>Palmitoyl-CoA oxidase</td>\n",
       "      <td>Cc1nc2cc(OC[C@H](O)CN3CCN(CC(=O)NCCc4ccccc4)CC...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>Palmitoyl-CoA oxidase</td>\n",
       "      <td>Cc1nc2cc(OC[C@H](O)CN3CCN(CC(=O)Nc4cccc(-c5ccc...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.4</td>\n",
       "      <td>0.43</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>Beta-1 adrenergic receptor</td>\n",
       "      <td>CC(C)(C)NC[C@H](O)CON=C1c2ccccc2-c2ccccc21</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.8</td>\n",
       "      <td>0.43</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>Beta-2 adrenergic receptor</td>\n",
       "      <td>CC(C)(C)NC[C@H](O)CON=C1c2ccccc2-c2ccccc21</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>PROTEIN COMPLEX GROUP</td>\n",
       "      <td>GABA-A receptor; anion channel</td>\n",
       "      <td>CCOC(=O)c1cn2c(n1)sc1ccccc12</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   standard_value    le            target_type  \\\n",
       "0         17000.0  0.20         SINGLE PROTEIN   \n",
       "1           180.0  0.25         SINGLE PROTEIN   \n",
       "2            29.4  0.43         SINGLE PROTEIN   \n",
       "3            30.8  0.43         SINGLE PROTEIN   \n",
       "4           120.0  0.56  PROTEIN COMPLEX GROUP   \n",
       "\n",
       "                        pref_name  \\\n",
       "0           Palmitoyl-CoA oxidase   \n",
       "1           Palmitoyl-CoA oxidase   \n",
       "2      Beta-1 adrenergic receptor   \n",
       "3      Beta-2 adrenergic receptor   \n",
       "4  GABA-A receptor; anion channel   \n",
       "\n",
       "                                    canonical_smiles molecular_species  \n",
       "0  Cc1nc2cc(OC[C@H](O)CN3CCN(CC(=O)NCCc4ccccc4)CC...           NEUTRAL  \n",
       "1  Cc1nc2cc(OC[C@H](O)CN3CCN(CC(=O)Nc4cccc(-c5ccc...           NEUTRAL  \n",
       "2         CC(C)(C)NC[C@H](O)CON=C1c2ccccc2-c2ccccc21              BASE  \n",
       "3         CC(C)(C)NC[C@H](O)CON=C1c2ccccc2-c2ccccc21              BASE  \n",
       "4                       CCOC(=O)c1cn2c(n1)sc1ccccc12           NEUTRAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print length and show sample data\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize ligand values based on ranges <=300 nM and >=10000 nM (1 for active, 0 for inactive respectively)\n",
    "df.loc[df[\"standard_value\"] <= 300.0, \"standard_value_bin\"] = 1\n",
    "df.loc[df[\"standard_value\"] >= 10000.0, \"standard_value_bin\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out where molecular species is null as molecular species is either base, neutral, or acidic\n",
    "df = df[~df[\"molecular_species\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the assay count by target name\n",
    "targets = df.groupby(\"pref_name\")[[\"target_type\"]].agg({\"target_type\": \"count\"}).sort_values(by=\"target_type\", ascending=False)\n",
    "\n",
    "targets[\"cumulative_count\"] = targets[\"target_type\"].cumsum()\n",
    "\n",
    "targets[\"cumulative_perc\"] = targets[\"cumulative_count\"]/sum(targets[\"target_type\"])\n",
    "\n",
    "targets = targets[targets[\"cumulative_perc\"] <= 0.8]\n",
    "\n",
    "targets.iloc[:100]\n",
    "\n",
    "df = df[df[\"pref_name\"].isin(targets.iloc[:100].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHATGPT GENERATED CODE\n",
    "# Define a function to generate fingerprints\n",
    "def generate_fingerprint(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 3, nBits=2048)\n",
    "    features = np.zeros((1,))\n",
    "    Chem.DataStructs.ConvertToNumpyArray(fp, features)\n",
    "    return features\n",
    "\n",
    "# def generate_maccs(smiles):\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "#     features = list(fp.GetOnBits())\n",
    "#     return features\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "df['Fingerprint'] = df[\"canonical_smiles\"].apply(generate_fingerprint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">[1.0 points] How many tasks or modalities are there in the dataset and how do you define each task or modality? That is, explain if the task is within the same domain, cross domains, etc. If there are too many tasks or modalities to train the data reasonably, select a subset of the tasks for classification. For example, you might want to only train on 50 of the classification tasks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([33750., 26692., 26618., 19508., 21575., 30528., 26761., 22310.,\n",
       "        23085., 19142.]),\n",
       " array([ 0. ,  9.9, 19.8, 29.7, 39.6, 49.5, 59.4, 69.3, 79.2, 89.1, 99. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot out each set of tasks\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "axs[0].hist(df[\"target_type\"])\n",
    "axs[1].hist(df[\"pref_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_X_list = []\n",
    "task_y_list = []\n",
    "\n",
    "for s in df[\"pref_name\"].unique():\n",
    "    # example: neutral_X = np.array(df[df[\"molecular_species\"] == \"NEUTRAL\"][\"Fingerprint\"].tolist())\n",
    "    X = np.array(df[df[\"pref_name\"] == s][\"Fingerprint\"].tolist())\n",
    "    y = df[df[\"pref_name\"] == s][\"standard_value_bin\"].values\n",
    "\n",
    "    task_X_list.append((s, X))\n",
    "    task_y_list.append((s, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used in case want to concat other datapoints\n",
    "# np.concatenate((neutral_arr, df[df[\"molecular_species\"] == \"NEUTRAL\"][\"standard_value_bin\"].values.reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">[1.0 points] Split the data into training and testing. Be sure to explain how you performed this operation and why you think it is reasonable to split this particular dataset this way. For multi-task datasets, be sure to explain if it is appropriate to stratify within each task. If the dataset is already split for you, explain how the split was achieved and how it is stratified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset has ~250,000 records, we decided to split our data into 80% training, 20% testing. For the generalized model, we need to combine all of the tasks into a single task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in zip(task_X_list, task_y_list):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x[1], \n",
    "                                                        y[1], \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=7)\n",
    "    all_data = {\"data\": [], \"target\": [], \"data_test\": [], \"target_test\": []}\n",
    "    all_data[\"data\"].append(X_train)\n",
    "    all_data[\"target\"].append(y_train)        \n",
    "    all_data[\"data_test\"].append(X_test)\n",
    "    all_data[\"target_test\"].append(y_test)\n",
    "\n",
    "X_train_all = np.concatenate(all_data[\"data\"])\n",
    "y_train_all = np.concatenate(all_data[\"target\"])\n",
    "\n",
    "X_test_all = np.concatenate(all_data[\"data_test\"])\n",
    "y_test_all = np.concatenate(all_data[\"target_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">[3.0 points] Train a general model (or per task model) to perform the classification tasks. That is, a general model uses all modalities and all tasks should combined into a single classification task (if possible). Alternatively, if this is not possible, you could create a model for each specific task. For a task specific model, each task would be classified with its own feed-forward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as sk_mean_squared_error\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import precision_score, mean_squared_log_error\n",
    "\n",
    "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
    "    mean      = np.mean([data1, data2], axis=0)\n",
    "    diff      = data1 - data2                   # Difference between data1 and data2\n",
    "    md        = np.mean(diff)                   # Mean of the difference\n",
    "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.scatter(mean, diff, *args, **kwargs)\n",
    "    plt.axhline(md,           color='gray', linestyle='--')\n",
    "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
    "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')\n",
    "    plt.title(\"Bland Altman, MSE: \"+str(sk_mean_squared_error(data1,data2)))\n",
    "    plt.xlabel('Mean Score', fontsize=8)\n",
    "    plt.ylabel('Diff Score', fontsize=8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1203"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Run model through cv split - refer to lab6,7 for code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "38/38 [==============================] - 2s 19ms/step - loss: 0.5506 - accuracy: 0.8670 - auc: 0.4900 - val_loss: 0.4696 - val_accuracy: 0.9668 - val_auc: 0.5782\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4524 - accuracy: 0.9410 - auc: 0.5145 - val_loss: 0.3635 - val_accuracy: 0.9668 - val_auc: 0.6338\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3754 - accuracy: 0.9485 - auc: 0.5794 - val_loss: 0.2875 - val_accuracy: 0.9668 - val_auc: 0.6646\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3142 - accuracy: 0.9510 - auc: 0.6342 - val_loss: 0.2350 - val_accuracy: 0.9668 - val_auc: 0.6904\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2740 - accuracy: 0.9510 - auc: 0.6233 - val_loss: 0.2005 - val_accuracy: 0.9668 - val_auc: 0.7098\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2502 - accuracy: 0.9510 - auc: 0.5403 - val_loss: 0.1786 - val_accuracy: 0.9668 - val_auc: 0.7241\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2309 - accuracy: 0.9510 - auc: 0.6118 - val_loss: 0.1655 - val_accuracy: 0.9668 - val_auc: 0.7258\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2230 - accuracy: 0.9510 - auc: 0.5794 - val_loss: 0.1573 - val_accuracy: 0.9668 - val_auc: 0.7278\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2145 - accuracy: 0.9510 - auc: 0.5757 - val_loss: 0.1523 - val_accuracy: 0.9668 - val_auc: 0.7062\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2114 - accuracy: 0.9510 - auc: 0.5720 - val_loss: 0.1490 - val_accuracy: 0.9668 - val_auc: 0.7316\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1991 - accuracy: 0.9510 - auc: 0.6708 - val_loss: 0.1469 - val_accuracy: 0.9668 - val_auc: 0.7002\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2001 - accuracy: 0.9510 - auc: 0.6656 - val_loss: 0.1454 - val_accuracy: 0.9668 - val_auc: 0.7715\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2001 - accuracy: 0.9510 - auc: 0.6062 - val_loss: 0.1443 - val_accuracy: 0.9668 - val_auc: 0.6926\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1940 - accuracy: 0.9510 - auc: 0.6398 - val_loss: 0.1436 - val_accuracy: 0.9668 - val_auc: 0.7670\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1945 - accuracy: 0.9510 - auc: 0.6541 - val_loss: 0.1429 - val_accuracy: 0.9668 - val_auc: 0.7632\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1917 - accuracy: 0.9510 - auc: 0.6930 - val_loss: 0.1424 - val_accuracy: 0.9668 - val_auc: 0.6890\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1926 - accuracy: 0.9510 - auc: 0.6618 - val_loss: 0.1420 - val_accuracy: 0.9668 - val_auc: 0.7452\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1962 - accuracy: 0.9510 - auc: 0.5832 - val_loss: 0.1416 - val_accuracy: 0.9668 - val_auc: 0.7808\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1887 - accuracy: 0.9510 - auc: 0.6740 - val_loss: 0.1412 - val_accuracy: 0.9668 - val_auc: 0.7536\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1889 - accuracy: 0.9510 - auc: 0.6537 - val_loss: 0.1409 - val_accuracy: 0.9668 - val_auc: 0.7686\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1879 - accuracy: 0.9510 - auc: 0.6842 - val_loss: 0.1406 - val_accuracy: 0.9668 - val_auc: 0.6667\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1843 - accuracy: 0.9510 - auc: 0.7227 - val_loss: 0.1402 - val_accuracy: 0.9668 - val_auc: 0.7076\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1876 - accuracy: 0.9510 - auc: 0.6827 - val_loss: 0.1399 - val_accuracy: 0.9668 - val_auc: 0.7373\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1841 - accuracy: 0.9510 - auc: 0.7263 - val_loss: 0.1396 - val_accuracy: 0.9668 - val_auc: 0.7498\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1845 - accuracy: 0.9510 - auc: 0.6922 - val_loss: 0.1393 - val_accuracy: 0.9668 - val_auc: 0.7653\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1835 - accuracy: 0.9510 - auc: 0.7041 - val_loss: 0.1390 - val_accuracy: 0.9668 - val_auc: 0.7718\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1805 - accuracy: 0.9510 - auc: 0.7294 - val_loss: 0.1388 - val_accuracy: 0.9668 - val_auc: 0.7905\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1779 - accuracy: 0.9510 - auc: 0.7134 - val_loss: 0.1386 - val_accuracy: 0.9668 - val_auc: 0.7936\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1800 - accuracy: 0.9510 - auc: 0.7400 - val_loss: 0.1383 - val_accuracy: 0.9668 - val_auc: 0.7878\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1789 - accuracy: 0.9510 - auc: 0.7525 - val_loss: 0.1380 - val_accuracy: 0.9668 - val_auc: 0.7924\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1766 - accuracy: 0.9510 - auc: 0.7877 - val_loss: 0.1379 - val_accuracy: 0.9668 - val_auc: 0.7582\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1787 - accuracy: 0.9510 - auc: 0.7436 - val_loss: 0.1378 - val_accuracy: 0.9668 - val_auc: 0.7352\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1706 - accuracy: 0.9510 - auc: 0.8026 - val_loss: 0.1377 - val_accuracy: 0.9668 - val_auc: 0.7206\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.9510 - auc: 0.8228 - val_loss: 0.1376 - val_accuracy: 0.9668 - val_auc: 0.7443\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1685 - accuracy: 0.9510 - auc: 0.7986 - val_loss: 0.1376 - val_accuracy: 0.9668 - val_auc: 0.7574\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1685 - accuracy: 0.9510 - auc: 0.8070 - val_loss: 0.1375 - val_accuracy: 0.9668 - val_auc: 0.7674\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1644 - accuracy: 0.9510 - auc: 0.8250 - val_loss: 0.1375 - val_accuracy: 0.9668 - val_auc: 0.7754\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1629 - accuracy: 0.9510 - auc: 0.8162 - val_loss: 0.1376 - val_accuracy: 0.9668 - val_auc: 0.7821\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1648 - accuracy: 0.9510 - auc: 0.8069 - val_loss: 0.1377 - val_accuracy: 0.9668 - val_auc: 0.7739\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1671 - accuracy: 0.9510 - auc: 0.7770 - val_loss: 0.1378 - val_accuracy: 0.9668 - val_auc: 0.7777\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1610 - accuracy: 0.9510 - auc: 0.8241 - val_loss: 0.1379 - val_accuracy: 0.9668 - val_auc: 0.7744\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1633 - accuracy: 0.9510 - auc: 0.8052 - val_loss: 0.1380 - val_accuracy: 0.9668 - val_auc: 0.7777\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1647 - accuracy: 0.9510 - auc: 0.8092 - val_loss: 0.1381 - val_accuracy: 0.9668 - val_auc: 0.7899\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1566 - accuracy: 0.9510 - auc: 0.8332 - val_loss: 0.1383 - val_accuracy: 0.9668 - val_auc: 0.8007\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1592 - accuracy: 0.9510 - auc: 0.8184 - val_loss: 0.1384 - val_accuracy: 0.9668 - val_auc: 0.8160\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.9510 - auc: 0.8011 - val_loss: 0.1386 - val_accuracy: 0.9668 - val_auc: 0.7289\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1593 - accuracy: 0.9510 - auc: 0.7941 - val_loss: 0.1387 - val_accuracy: 0.9668 - val_auc: 0.7478\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1553 - accuracy: 0.9510 - auc: 0.7996 - val_loss: 0.1389 - val_accuracy: 0.9668 - val_auc: 0.7397\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1543 - accuracy: 0.9510 - auc: 0.8217 - val_loss: 0.1390 - val_accuracy: 0.9668 - val_auc: 0.7522\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.9510 - auc: 0.8120 - val_loss: 0.1391 - val_accuracy: 0.9668 - val_auc: 0.7608\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1533 - accuracy: 0.9510 - auc: 0.8094 - val_loss: 0.1392 - val_accuracy: 0.9668 - val_auc: 0.7682\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1485 - accuracy: 0.9510 - auc: 0.8478 - val_loss: 0.1393 - val_accuracy: 0.9668 - val_auc: 0.7773\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1536 - accuracy: 0.9510 - auc: 0.8302 - val_loss: 0.1392 - val_accuracy: 0.9668 - val_auc: 0.7787\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1465 - accuracy: 0.9510 - auc: 0.8836 - val_loss: 0.1393 - val_accuracy: 0.9668 - val_auc: 0.7763\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1496 - accuracy: 0.9510 - auc: 0.8323 - val_loss: 0.1394 - val_accuracy: 0.9668 - val_auc: 0.7813\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1485 - accuracy: 0.9510 - auc: 0.8489 - val_loss: 0.1394 - val_accuracy: 0.9668 - val_auc: 0.7837\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1498 - accuracy: 0.9510 - auc: 0.8241 - val_loss: 0.1394 - val_accuracy: 0.9668 - val_auc: 0.7943\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.9518 - auc: 0.8378 - val_loss: 0.1395 - val_accuracy: 0.9668 - val_auc: 0.7967\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1521 - accuracy: 0.9518 - auc: 0.8188 - val_loss: 0.1395 - val_accuracy: 0.9668 - val_auc: 0.7991\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1482 - accuracy: 0.9510 - auc: 0.8329 - val_loss: 0.1396 - val_accuracy: 0.9668 - val_auc: 0.8027\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1449 - accuracy: 0.9510 - auc: 0.8520 - val_loss: 0.1396 - val_accuracy: 0.9668 - val_auc: 0.7215\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1473 - accuracy: 0.9518 - auc: 0.8103 - val_loss: 0.1397 - val_accuracy: 0.9668 - val_auc: 0.7321\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1439 - accuracy: 0.9518 - auc: 0.8615 - val_loss: 0.1399 - val_accuracy: 0.9668 - val_auc: 0.7514\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1454 - accuracy: 0.9510 - auc: 0.8374 - val_loss: 0.1402 - val_accuracy: 0.9668 - val_auc: 0.7363\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1416 - accuracy: 0.9501 - auc: 0.8647 - val_loss: 0.1403 - val_accuracy: 0.9668 - val_auc: 0.7229\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1393 - accuracy: 0.9526 - auc: 0.8595 - val_loss: 0.1403 - val_accuracy: 0.9668 - val_auc: 0.7364\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1464 - accuracy: 0.9510 - auc: 0.8237 - val_loss: 0.1404 - val_accuracy: 0.9668 - val_auc: 0.7505\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1456 - accuracy: 0.9510 - auc: 0.8208 - val_loss: 0.1405 - val_accuracy: 0.9668 - val_auc: 0.7613\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1424 - accuracy: 0.9510 - auc: 0.8457 - val_loss: 0.1405 - val_accuracy: 0.9668 - val_auc: 0.7658\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1425 - accuracy: 0.9518 - auc: 0.8381 - val_loss: 0.1407 - val_accuracy: 0.9668 - val_auc: 0.7593\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1385 - accuracy: 0.9526 - auc: 0.8707 - val_loss: 0.1407 - val_accuracy: 0.9668 - val_auc: 0.7651\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1419 - accuracy: 0.9510 - auc: 0.8498 - val_loss: 0.1407 - val_accuracy: 0.9668 - val_auc: 0.7696\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1363 - accuracy: 0.9493 - auc: 0.8721 - val_loss: 0.1410 - val_accuracy: 0.9668 - val_auc: 0.7741\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1384 - accuracy: 0.9526 - auc: 0.8667 - val_loss: 0.1411 - val_accuracy: 0.9635 - val_auc: 0.7787\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1409 - accuracy: 0.9526 - auc: 0.8318 - val_loss: 0.1412 - val_accuracy: 0.9635 - val_auc: 0.7799\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1371 - accuracy: 0.9543 - auc: 0.8306 - val_loss: 0.1416 - val_accuracy: 0.9635 - val_auc: 0.7851\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1378 - accuracy: 0.9510 - auc: 0.8512 - val_loss: 0.1417 - val_accuracy: 0.9601 - val_auc: 0.7857\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.9551 - auc: 0.8334 - val_loss: 0.1420 - val_accuracy: 0.9601 - val_auc: 0.7918\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1345 - accuracy: 0.9510 - auc: 0.8647 - val_loss: 0.1421 - val_accuracy: 0.9568 - val_auc: 0.7926\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9534 - auc: 0.8567 - val_loss: 0.1422 - val_accuracy: 0.9568 - val_auc: 0.7945\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1360 - accuracy: 0.9518 - auc: 0.8227 - val_loss: 0.1425 - val_accuracy: 0.9568 - val_auc: 0.8043\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1328 - accuracy: 0.9551 - auc: 0.8753 - val_loss: 0.1431 - val_accuracy: 0.9568 - val_auc: 0.8098\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.9526 - auc: 0.8844 - val_loss: 0.1432 - val_accuracy: 0.9535 - val_auc: 0.7662\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1305 - accuracy: 0.9543 - auc: 0.8686 - val_loss: 0.1435 - val_accuracy: 0.9502 - val_auc: 0.7677\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.9534 - auc: 0.8739 - val_loss: 0.1440 - val_accuracy: 0.9502 - val_auc: 0.7242\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1300 - accuracy: 0.9534 - auc: 0.8551 - val_loss: 0.1446 - val_accuracy: 0.9468 - val_auc: 0.7246\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1306 - accuracy: 0.9501 - auc: 0.8988 - val_loss: 0.1447 - val_accuracy: 0.9468 - val_auc: 0.7246\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1271 - accuracy: 0.9543 - auc: 0.9134 - val_loss: 0.1452 - val_accuracy: 0.9468 - val_auc: 0.7251\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.9526 - auc: 0.8882 - val_loss: 0.1455 - val_accuracy: 0.9468 - val_auc: 0.7249\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1317 - accuracy: 0.9551 - auc: 0.8580 - val_loss: 0.1459 - val_accuracy: 0.9468 - val_auc: 0.7282\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1278 - accuracy: 0.9534 - auc: 0.8766 - val_loss: 0.1462 - val_accuracy: 0.9468 - val_auc: 0.7282\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1292 - accuracy: 0.9534 - auc: 0.8735 - val_loss: 0.1466 - val_accuracy: 0.9468 - val_auc: 0.7290\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1281 - accuracy: 0.9518 - auc: 0.8679 - val_loss: 0.1471 - val_accuracy: 0.9468 - val_auc: 0.7335\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1259 - accuracy: 0.9543 - auc: 0.8951 - val_loss: 0.1474 - val_accuracy: 0.9468 - val_auc: 0.7481\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1258 - accuracy: 0.9551 - auc: 0.8656 - val_loss: 0.1477 - val_accuracy: 0.9468 - val_auc: 0.7196\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1254 - accuracy: 0.9551 - auc: 0.8956 - val_loss: 0.1480 - val_accuracy: 0.9468 - val_auc: 0.7311\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1269 - accuracy: 0.9559 - auc: 0.8831 - val_loss: 0.1484 - val_accuracy: 0.9468 - val_auc: 0.7100\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1269 - accuracy: 0.9526 - auc: 0.8883 - val_loss: 0.1489 - val_accuracy: 0.9468 - val_auc: 0.7265\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1246 - accuracy: 0.9551 - auc: 0.8933 - val_loss: 0.1493 - val_accuracy: 0.9468 - val_auc: 0.7471\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1265 - accuracy: 0.9543 - auc: 0.8771 - val_loss: 0.1492 - val_accuracy: 0.9468 - val_auc: 0.7077\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1167 - accuracy: 0.9551 - auc: 0.9300 - val_loss: 0.1496 - val_accuracy: 0.9468 - val_auc: 0.7234\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1206 - accuracy: 0.9593 - auc: 0.8948 - val_loss: 0.1499 - val_accuracy: 0.9468 - val_auc: 0.7418\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1164 - accuracy: 0.9576 - auc: 0.9002 - val_loss: 0.1505 - val_accuracy: 0.9468 - val_auc: 0.7524\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1217 - accuracy: 0.9543 - auc: 0.8943 - val_loss: 0.1508 - val_accuracy: 0.9468 - val_auc: 0.7615\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1207 - accuracy: 0.9559 - auc: 0.8816 - val_loss: 0.1512 - val_accuracy: 0.9468 - val_auc: 0.7655\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1234 - accuracy: 0.9559 - auc: 0.8759 - val_loss: 0.1512 - val_accuracy: 0.9468 - val_auc: 0.7686\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1196 - accuracy: 0.9559 - auc: 0.8863 - val_loss: 0.1512 - val_accuracy: 0.9468 - val_auc: 0.7742\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1162 - accuracy: 0.9601 - auc: 0.9225 - val_loss: 0.1517 - val_accuracy: 0.9468 - val_auc: 0.7789\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1163 - accuracy: 0.9601 - auc: 0.8953 - val_loss: 0.1526 - val_accuracy: 0.9468 - val_auc: 0.7838\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1192 - accuracy: 0.9559 - auc: 0.9024 - val_loss: 0.1525 - val_accuracy: 0.9468 - val_auc: 0.7856\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1188 - accuracy: 0.9551 - auc: 0.9107 - val_loss: 0.1527 - val_accuracy: 0.9435 - val_auc: 0.7875\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1191 - accuracy: 0.9568 - auc: 0.9034 - val_loss: 0.1530 - val_accuracy: 0.9435 - val_auc: 0.7935\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1150 - accuracy: 0.9593 - auc: 0.9044 - val_loss: 0.1534 - val_accuracy: 0.9402 - val_auc: 0.7960\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1198 - accuracy: 0.9534 - auc: 0.8983 - val_loss: 0.1536 - val_accuracy: 0.9402 - val_auc: 0.7979\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1177 - accuracy: 0.9543 - auc: 0.9089 - val_loss: 0.1536 - val_accuracy: 0.9402 - val_auc: 0.7974\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1141 - accuracy: 0.9609 - auc: 0.9165 - val_loss: 0.1538 - val_accuracy: 0.9402 - val_auc: 0.7976\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1127 - accuracy: 0.9584 - auc: 0.9069 - val_loss: 0.1541 - val_accuracy: 0.9402 - val_auc: 0.7981\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1164 - accuracy: 0.9518 - auc: 0.9264 - val_loss: 0.1543 - val_accuracy: 0.9402 - val_auc: 0.8002\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1138 - accuracy: 0.9510 - auc: 0.9198 - val_loss: 0.1546 - val_accuracy: 0.9402 - val_auc: 0.8009\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1068 - accuracy: 0.9593 - auc: 0.9503 - val_loss: 0.1548 - val_accuracy: 0.9402 - val_auc: 0.8029\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1059 - accuracy: 0.9634 - auc: 0.9464 - val_loss: 0.1552 - val_accuracy: 0.9402 - val_auc: 0.8055\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1066 - accuracy: 0.9576 - auc: 0.9417 - val_loss: 0.1557 - val_accuracy: 0.9402 - val_auc: 0.8089\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1102 - accuracy: 0.9634 - auc: 0.9193 - val_loss: 0.1562 - val_accuracy: 0.9402 - val_auc: 0.8124\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.9643 - auc: 0.9446 - val_loss: 0.1564 - val_accuracy: 0.9402 - val_auc: 0.8132\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1047 - accuracy: 0.9593 - auc: 0.9448 - val_loss: 0.1565 - val_accuracy: 0.9402 - val_auc: 0.8132\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1056 - accuracy: 0.9643 - auc: 0.9458 - val_loss: 0.1567 - val_accuracy: 0.9402 - val_auc: 0.8151\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.9584 - auc: 0.9299 - val_loss: 0.1574 - val_accuracy: 0.9402 - val_auc: 0.8151\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9584 - auc: 0.9467 - val_loss: 0.1580 - val_accuracy: 0.9402 - val_auc: 0.8160\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0980 - accuracy: 0.9601 - auc: 0.9642 - val_loss: 0.1585 - val_accuracy: 0.9402 - val_auc: 0.8201\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1010 - accuracy: 0.9601 - auc: 0.9432 - val_loss: 0.1593 - val_accuracy: 0.9402 - val_auc: 0.7316\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0998 - accuracy: 0.9518 - auc: 0.9646 - val_loss: 0.1594 - val_accuracy: 0.9402 - val_auc: 0.7328\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9584 - auc: 0.9354 - val_loss: 0.1596 - val_accuracy: 0.9402 - val_auc: 0.7318\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0996 - accuracy: 0.9651 - auc: 0.9488 - val_loss: 0.1605 - val_accuracy: 0.9402 - val_auc: 0.7340\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0992 - accuracy: 0.9593 - auc: 0.9587 - val_loss: 0.1606 - val_accuracy: 0.9402 - val_auc: 0.7333\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0986 - accuracy: 0.9601 - auc: 0.9558 - val_loss: 0.1607 - val_accuracy: 0.9402 - val_auc: 0.7328\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0980 - accuracy: 0.9634 - auc: 0.9450 - val_loss: 0.1617 - val_accuracy: 0.9402 - val_auc: 0.7321\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0952 - accuracy: 0.9634 - auc: 0.9588 - val_loss: 0.1626 - val_accuracy: 0.9402 - val_auc: 0.7368\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0941 - accuracy: 0.9659 - auc: 0.9610 - val_loss: 0.1633 - val_accuracy: 0.9402 - val_auc: 0.7424\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0920 - accuracy: 0.9667 - auc: 0.9705 - val_loss: 0.1639 - val_accuracy: 0.9402 - val_auc: 0.7469\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0921 - accuracy: 0.9576 - auc: 0.9724 - val_loss: 0.1645 - val_accuracy: 0.9402 - val_auc: 0.7522\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0942 - accuracy: 0.9634 - auc: 0.9684 - val_loss: 0.1647 - val_accuracy: 0.9402 - val_auc: 0.7603\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9634 - auc: 0.9584 - val_loss: 0.1656 - val_accuracy: 0.9402 - val_auc: 0.7789\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0884 - accuracy: 0.9676 - auc: 0.9650 - val_loss: 0.1664 - val_accuracy: 0.9402 - val_auc: 0.7641\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0935 - accuracy: 0.9643 - auc: 0.9416 - val_loss: 0.1667 - val_accuracy: 0.9402 - val_auc: 0.7981\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0907 - accuracy: 0.9634 - auc: 0.9616 - val_loss: 0.1677 - val_accuracy: 0.9402 - val_auc: 0.7435\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0912 - accuracy: 0.9676 - auc: 0.9625 - val_loss: 0.1685 - val_accuracy: 0.9402 - val_auc: 0.7213\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0886 - accuracy: 0.9651 - auc: 0.9666 - val_loss: 0.1692 - val_accuracy: 0.9402 - val_auc: 0.7347\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0919 - accuracy: 0.9643 - auc: 0.9695 - val_loss: 0.1693 - val_accuracy: 0.9402 - val_auc: 0.7490\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0886 - accuracy: 0.9651 - auc: 0.9680 - val_loss: 0.1702 - val_accuracy: 0.9402 - val_auc: 0.7593\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0856 - accuracy: 0.9659 - auc: 0.9616 - val_loss: 0.1709 - val_accuracy: 0.9402 - val_auc: 0.7790\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.9643 - auc: 0.9758 - val_loss: 0.1717 - val_accuracy: 0.9402 - val_auc: 0.7887\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0838 - accuracy: 0.9659 - auc: 0.9624 - val_loss: 0.1725 - val_accuracy: 0.9402 - val_auc: 0.8012\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0844 - accuracy: 0.9717 - auc: 0.9630 - val_loss: 0.1728 - val_accuracy: 0.9402 - val_auc: 0.8021\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0852 - accuracy: 0.9634 - auc: 0.9723 - val_loss: 0.1736 - val_accuracy: 0.9402 - val_auc: 0.8187\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0871 - accuracy: 0.9651 - auc: 0.9683 - val_loss: 0.1739 - val_accuracy: 0.9402 - val_auc: 0.7811\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9676 - auc: 0.9648 - val_loss: 0.1746 - val_accuracy: 0.9402 - val_auc: 0.7759\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9676 - auc: 0.9677 - val_loss: 0.1750 - val_accuracy: 0.9402 - val_auc: 0.7771\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.9651 - auc: 0.9695 - val_loss: 0.1761 - val_accuracy: 0.9402 - val_auc: 0.7833\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.9626 - auc: 0.9768 - val_loss: 0.1764 - val_accuracy: 0.9402 - val_auc: 0.7883\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9634 - auc: 0.9732 - val_loss: 0.1766 - val_accuracy: 0.9402 - val_auc: 0.7907\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0786 - accuracy: 0.9701 - auc: 0.9787 - val_loss: 0.1775 - val_accuracy: 0.9402 - val_auc: 0.7541\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0815 - accuracy: 0.9659 - auc: 0.9789 - val_loss: 0.1786 - val_accuracy: 0.9402 - val_auc: 0.7629\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0765 - accuracy: 0.9667 - auc: 0.9764 - val_loss: 0.1791 - val_accuracy: 0.9402 - val_auc: 0.7625\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9659 - auc: 0.9770 - val_loss: 0.1798 - val_accuracy: 0.9402 - val_auc: 0.7651\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0810 - accuracy: 0.9651 - auc: 0.9739 - val_loss: 0.1802 - val_accuracy: 0.9402 - val_auc: 0.7665\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0797 - accuracy: 0.9667 - auc: 0.9651 - val_loss: 0.1811 - val_accuracy: 0.9402 - val_auc: 0.7689\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0818 - accuracy: 0.9643 - auc: 0.9793 - val_loss: 0.1816 - val_accuracy: 0.9402 - val_auc: 0.7699\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0756 - accuracy: 0.9667 - auc: 0.9852 - val_loss: 0.1816 - val_accuracy: 0.9402 - val_auc: 0.7689\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0751 - accuracy: 0.9742 - auc: 0.9678 - val_loss: 0.1824 - val_accuracy: 0.9402 - val_auc: 0.7258\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0807 - accuracy: 0.9626 - auc: 0.9622 - val_loss: 0.1827 - val_accuracy: 0.9402 - val_auc: 0.6792\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0763 - accuracy: 0.9651 - auc: 0.9832 - val_loss: 0.1831 - val_accuracy: 0.9402 - val_auc: 0.6832\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0788 - accuracy: 0.9659 - auc: 0.9724 - val_loss: 0.1837 - val_accuracy: 0.9402 - val_auc: 0.6878\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0781 - accuracy: 0.9692 - auc: 0.9701 - val_loss: 0.1842 - val_accuracy: 0.9402 - val_auc: 0.6902\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0736 - accuracy: 0.9709 - auc: 0.9795 - val_loss: 0.1848 - val_accuracy: 0.9402 - val_auc: 0.6952\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9643 - auc: 0.9750 - val_loss: 0.1853 - val_accuracy: 0.9402 - val_auc: 0.6945\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0759 - accuracy: 0.9659 - auc: 0.9665 - val_loss: 0.1857 - val_accuracy: 0.9402 - val_auc: 0.6476\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0725 - accuracy: 0.9684 - auc: 0.9800 - val_loss: 0.1859 - val_accuracy: 0.9402 - val_auc: 0.6471\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0765 - accuracy: 0.9676 - auc: 0.9689 - val_loss: 0.1865 - val_accuracy: 0.9402 - val_auc: 0.6488\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0747 - accuracy: 0.9701 - auc: 0.9732 - val_loss: 0.1873 - val_accuracy: 0.9402 - val_auc: 0.6493\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0762 - accuracy: 0.9701 - auc: 0.9807 - val_loss: 0.1875 - val_accuracy: 0.9402 - val_auc: 0.6505\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0757 - accuracy: 0.9667 - auc: 0.9766 - val_loss: 0.1877 - val_accuracy: 0.9402 - val_auc: 0.6495\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9667 - auc: 0.9806 - val_loss: 0.1883 - val_accuracy: 0.9402 - val_auc: 0.6500\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0701 - accuracy: 0.9734 - auc: 0.9859 - val_loss: 0.1886 - val_accuracy: 0.9402 - val_auc: 0.6498\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0714 - accuracy: 0.9692 - auc: 0.9795 - val_loss: 0.1892 - val_accuracy: 0.9402 - val_auc: 0.6503\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0733 - accuracy: 0.9667 - auc: 0.9798 - val_loss: 0.1896 - val_accuracy: 0.9402 - val_auc: 0.6503\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.9692 - auc: 0.9857 - val_loss: 0.1903 - val_accuracy: 0.9402 - val_auc: 0.6502\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0718 - accuracy: 0.9726 - auc: 0.9824 - val_loss: 0.1906 - val_accuracy: 0.9402 - val_auc: 0.6488\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0685 - accuracy: 0.9759 - auc: 0.9823 - val_loss: 0.1915 - val_accuracy: 0.9402 - val_auc: 0.6515\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0678 - accuracy: 0.9684 - auc: 0.9878 - val_loss: 0.1923 - val_accuracy: 0.9402 - val_auc: 0.6543\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9692 - auc: 0.9865 - val_loss: 0.1929 - val_accuracy: 0.9402 - val_auc: 0.6550\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.9651 - auc: 0.9744 - val_loss: 0.1931 - val_accuracy: 0.9402 - val_auc: 0.6543\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0716 - accuracy: 0.9676 - auc: 0.9841 - val_loss: 0.1935 - val_accuracy: 0.9402 - val_auc: 0.6543\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0685 - accuracy: 0.9709 - auc: 0.9772 - val_loss: 0.1938 - val_accuracy: 0.9402 - val_auc: 0.6522\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0670 - accuracy: 0.9684 - auc: 0.9833 - val_loss: 0.1944 - val_accuracy: 0.9402 - val_auc: 0.6522\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.9726 - auc: 0.9768 - val_loss: 0.1952 - val_accuracy: 0.9402 - val_auc: 0.6555\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0627 - accuracy: 0.9726 - auc: 0.9871 - val_loss: 0.1959 - val_accuracy: 0.9402 - val_auc: 0.6548\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0638 - accuracy: 0.9717 - auc: 0.9801 - val_loss: 0.1965 - val_accuracy: 0.9402 - val_auc: 0.6546\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0707 - accuracy: 0.9709 - auc: 0.9861 - val_loss: 0.1968 - val_accuracy: 0.9402 - val_auc: 0.6546\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0666 - accuracy: 0.9667 - auc: 0.9839 - val_loss: 0.1973 - val_accuracy: 0.9402 - val_auc: 0.6546\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0658 - accuracy: 0.9709 - auc: 0.9885 - val_loss: 0.1980 - val_accuracy: 0.9402 - val_auc: 0.6546\n"
     ]
    }
   ],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-5)\n",
    "\n",
    "generalized_mlp = Sequential()\n",
    "generalized_mlp.add(Dense(input_dim=X_train_all.shape[1], units=512, activation='relu', name='input_dense512'))\n",
    "generalized_mlp.add(Dropout(0.2))\n",
    "\n",
    "generalized_mlp.add(Dense(units=256, activation='relu', name='mid_dense256'))\n",
    "generalized_mlp.add(Dropout(0.2))\n",
    "\n",
    "generalized_mlp.add(Dense(units=256, activation='tanh', name='mid_dense2_216'))\n",
    "generalized_mlp.add(Dropout(0.2))\n",
    "\n",
    "generalized_mlp.add(Dense(units=128, activation='relu', name='mid_dense128'))\n",
    "generalized_mlp.add(Dropout(0.2))\n",
    "\n",
    "generalized_mlp.add(Dense(units=64, activation='tanh', name='mid_dense64'))\n",
    "generalized_mlp.add(Dropout(0.2))\n",
    "\n",
    "generalized_mlp.add(Dense(units=32, activation='relu', name='mid_dense32'))\n",
    "generalized_mlp.add(Dropout(0.2))\n",
    "\n",
    "generalized_mlp.add(Dense(units=16, activation='tanh', name='mid_dense16'))\n",
    "generalized_mlp.add(Dense(1, activation='sigmoid', name='output_layer'))\n",
    "\n",
    "generalized_mlp.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[\"accuracy\", \"AUC\"])\n",
    "\n",
    "generalized_mlp.fit(X_train_all, y_train_all, epochs=200, shuffle=False, verbose=1, validation_data=(X_test_all,y_test_all))\n",
    "y_hat_general = generalized_mlp.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat_converted = []\n",
    "# for i in y_hat_general:\n",
    "#     y_hat_converted.append(i[0])\n",
    "\n",
    "#don't think we need this anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775085910652921"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_test_all, y_hat_general)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "\n",
    "def roc_calc(model, X_test, y_test):\n",
    "    yhat = model.predict(X_test)\n",
    "    false_positive, true_positive, _ = mt.roc_curve(y_test.flatten(), yhat.flatten())\n",
    "    roc = mt.auc(false_positive, true_positive)\n",
    "    return false_positive, true_positive, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average AUC for all models\n",
    "generalized_mlp_fp, generalized_mlp_tp, generalized_mlp_roc = roc_calc(generalized_mlp, X_test_all, y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c24159e220>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot out all model AUC\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('ROC Comparisons')\n",
    "plt.plot(generalized_mlp_fp, generalized_mlp_tp)\n",
    "plt.plot([0, 1])\n",
    "plt.ylabel('False Positives')\n",
    "plt.xlabel('True Positives')\n",
    "plt.legend([f\"generalized_mlp with AUC: {generalized_mlp_roc}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "91345feaad893ab48aac0cad8417a20c820522900c47c62ac45091529d156e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
